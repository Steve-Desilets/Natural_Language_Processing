{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36bcc168",
   "metadata": {},
   "source": [
    "# Assignment 4 - Chatbots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad11a284",
   "metadata": {},
   "source": [
    "#### Steve Desilets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca0081da",
   "metadata": {},
   "source": [
    "#### August 26, 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "801e9c35",
   "metadata": {},
   "source": [
    "## 1) Chatbot 1 - Sentence-Based Transformer Chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4970ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from collections import Counter\n",
    "from dataclasses import dataclass\n",
    "from timeit import default_timer as timer\n",
    "import random\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize \n",
    "\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "\n",
    "from spacy.matcher import Matcher \n",
    "from spacy.tokens import Span \n",
    "\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "!pip install sentence_transformers\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "from typing import List, Callable, Dict, Tuple, Set\n",
    "\n",
    "pd.set_option('max_colwidth', 600)\n",
    "pd.set_option('display.max_rows', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107bdb38",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Sentence Transformer model optimized for  sentence cosine similarity calculations\n",
    "\n",
    "#The models below fully downloaded in Google Colab. This is the version of the google colab notebook but \n",
    "#it was open in anoconda to be saved as pdf and the download graphics did not transfer properly so \n",
    "#it seems like it didn't download. However, it did in the orignal google colab notebook, where all the\n",
    "#analysis was run.\n",
    "\n",
    "model = SentenceTransformer('multi-qa-MiniLM-L6-cos-v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e882d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3adf47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only run this once, they will be downloaded.\n",
    "nltk.download('stopwords',quiet=True)\n",
    "nltk.download('wordnet',quiet=True)\n",
    "nltk.download('punkt',quiet=True)\n",
    "nltk.download('omw-1.4',quiet=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b16ddf27",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/content/gdrive/My Drive/Colab Notebooks/MSDS_453/Chatbot/stocks_bonds_chatbot.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#read in data\u001b[39;00m\n\u001b[0;32m      2\u001b[0m CORPUS_PATH \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content/gdrive/My Drive/Colab Notebooks/MSDS_453/Chatbot/stocks_bonds_chatbot.txt\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 3\u001b[0m f\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mCORPUS_PATH\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mignore\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m raw\u001b[38;5;241m=\u001b[39mf\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m      5\u001b[0m raw\u001b[38;5;241m=\u001b[39mraw\u001b[38;5;241m.\u001b[39mlower()\u001b[38;5;66;03m# converts to lowercase\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/gdrive/My Drive/Colab Notebooks/MSDS_453/Chatbot/stocks_bonds_chatbot.txt'"
     ]
    }
   ],
   "source": [
    "#read in data\n",
    "CORPUS_PATH = '/content/gdrive/My Drive/Colab Notebooks/MSDS_453/Chatbot/stocks_bonds_chatbot.txt'\n",
    "f=open(CORPUS_PATH,'r',errors = 'ignore')\n",
    "raw=f.read()\n",
    "raw=raw.lower()# converts to lowercase\n",
    "\n",
    "#create list of sentences and words\n",
    "sent_tokens = nltk.sent_tokenize(raw)# converts to list of sentences \n",
    "word_tokens = nltk.word_tokenize(raw)# converts to list of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5121c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create greetings and greetings function\n",
    "\n",
    "GREETING_INPUTS = (\"hello\", \"hi\", \"greetings\", \"sup\", \"what's up\",\"hey\",)\n",
    "GREETING_RESPONSES = [\"Hello\"]\n",
    "\n",
    "\n",
    "# Checking for greetings\n",
    "def greeting(sentence):\n",
    "    \"\"\"If user's input is a greeting, return a greeting response\"\"\"\n",
    "    for word in sentence.split():\n",
    "        if word.lower() in GREETING_INPUTS:\n",
    "            return random.choice(GREETING_RESPONSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb82a0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Generating response function \n",
    "def response(user_response):\n",
    "    chatbot_response=''\n",
    "    sentence_encodings=model.encode(sent_tokens, convert_to_tensor=True)# generate sentence transformer embeddings\n",
    "    sentence_encodings=sentence_encodings.cpu()\n",
    "    vals = cosine_similarity(sentence_encodings[-1].reshape(1, -1), sentence_encodings) #the chatbot conversation code \n",
    "    #in the next cell adds the question as the last sentence of the sentence tokens, before calling this response function.\n",
    "    #The code takes the last sentence (which is the question) and gets cosine similarities vs all the sentences in the corpus,\n",
    "    #including itself\n",
    "    idx=vals.argsort()[0][-2] #gets the index of the second highest similarity (the first highest would be the question itself)\n",
    "    flat = vals.flatten()#reduces dimension of cosine similarity array to be able to sort\n",
    "    flat.sort() #sort the cosine similarity values\n",
    "    second_cos_sim_val = flat[-2] #get the second highest cosine similarity value.\n",
    "    if(second_cos_sim_val==0): #check the second highest cosine similarity value. If it's zero return the no match response,\n",
    "        #else return highest cosine similarity sentence.\n",
    "        chatbot_response=chatbot_response+\"Sorry, I do not have an answer to your question in my database\"\n",
    "        return chatbot_response\n",
    "    else:\n",
    "        chatbot_response = chatbot_response+sent_tokens[idx] #use index of highest cosine similarity to get original sentence\n",
    "        return chatbot_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022a57df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Chatbot interaction code\n",
    "\n",
    "flag=True\n",
    "print(\"Welcome to the Stock and Bond Concepts Information Chatbot. To end session please type exit\")\n",
    "print(\"\\n\")\n",
    "\n",
    "while(flag==True):\n",
    "    user_response = input()\n",
    "    user_response=user_response.lower()\n",
    "    if user_response!='exit':\n",
    "        if(user_response=='thanks' or user_response=='thank you' ):\n",
    "            flag=False\n",
    "            print(\"Answer: You are welcome!\")\n",
    "        else:\n",
    "            if(greeting(user_response)!=None):\n",
    "                print(\"Answer: \"+greeting(user_response))\n",
    "            else:\n",
    "                sent_tokens.append(user_response)\n",
    "                word_tokens=word_tokens+nltk.word_tokenize(user_response)\n",
    "                final_words=list(set(word_tokens))\n",
    "                print(\"Answer: \",end=\"\")\n",
    "                print(response(user_response))\n",
    "                print(\"\\n\")\n",
    "                sent_tokens.remove(user_response)\n",
    "    else:\n",
    "        flag=False\n",
    "        print(\"Thank you for using the Stock and Bond Concepts Information Chatbot. Good bye.\")    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785163be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e0438c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af03fbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1a9f7b2d",
   "metadata": {},
   "source": [
    "## 2) Chatbot 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5be6f9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad66c71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b6807d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ea2da138",
   "metadata": {},
   "source": [
    "## 3) Chatbot 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9e8093",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3871f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bea71f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d26fa7bd",
   "metadata": {},
   "source": [
    "## 4) Chatbot 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f570aaf0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
