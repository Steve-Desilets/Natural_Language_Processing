{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9bb957fc",
   "metadata": {},
   "source": [
    "# Assignment 4 - Chatbots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad11a284",
   "metadata": {},
   "source": [
    "#### Steve Desilets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e6ab72",
   "metadata": {},
   "source": [
    "#### August 26, 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c12390b",
   "metadata": {},
   "source": [
    "## 1) Chatbot 1 - Sentence-Based Transformer Chatbot That Leverages Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "061f2510",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\steve\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\steve\\anaconda3\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence-transformers in c:\\users\\steve\\anaconda3\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in c:\\users\\steve\\anaconda3\\lib\\site-packages (from sentence-transformers) (4.31.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\steve\\anaconda3\\lib\\site-packages (from sentence-transformers) (4.64.0)\n",
      "Requirement already satisfied: torch>=1.6.0 in c:\\users\\steve\\anaconda3\\lib\\site-packages (from sentence-transformers) (2.0.1)\n",
      "Requirement already satisfied: torchvision in c:\\users\\steve\\anaconda3\\lib\\site-packages (from sentence-transformers) (0.15.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\steve\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.22.4)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\steve\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.0.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\steve\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.7.3)\n",
      "Requirement already satisfied: nltk in c:\\users\\steve\\anaconda3\\lib\\site-packages (from sentence-transformers) (3.7)\n",
      "Requirement already satisfied: sentencepiece in c:\\users\\steve\\anaconda3\\lib\\site-packages (from sentence-transformers) (0.1.99)\n",
      "Requirement already satisfied: huggingface-hub>=0.4.0 in c:\\users\\steve\\anaconda3\\lib\\site-packages (from sentence-transformers) (0.16.4)\n",
      "Requirement already satisfied: filelock in c:\\users\\steve\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (3.6.0)\n",
      "Requirement already satisfied: fsspec in c:\\users\\steve\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2022.2.0)\n",
      "Requirement already satisfied: requests in c:\\users\\steve\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2.27.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\steve\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\steve\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (4.7.1)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\steve\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (21.3)\n",
      "Requirement already satisfied: sympy in c:\\users\\steve\\anaconda3\\lib\\site-packages (from torch>=1.6.0->sentence-transformers) (1.10.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\steve\\anaconda3\\lib\\site-packages (from torch>=1.6.0->sentence-transformers) (2.7.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\steve\\anaconda3\\lib\\site-packages (from torch>=1.6.0->sentence-transformers) (2.11.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\steve\\anaconda3\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\steve\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2022.3.15)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\users\\steve\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.13.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\steve\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.3.2)\n",
      "Requirement already satisfied: click in c:\\users\\steve\\anaconda3\\lib\\site-packages (from nltk->sentence-transformers) (8.0.4)\n",
      "Requirement already satisfied: joblib in c:\\users\\steve\\anaconda3\\lib\\site-packages (from nltk->sentence-transformers) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\steve\\anaconda3\\lib\\site-packages (from scikit-learn->sentence-transformers) (2.2.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\steve\\anaconda3\\lib\\site-packages (from torchvision->sentence-transformers) (9.0.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\steve\\anaconda3\\lib\\site-packages (from packaging>=20.9->huggingface-hub>=0.4.0->sentence-transformers) (3.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\steve\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.6.0->sentence-transformers) (2.0.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\steve\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\steve\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\steve\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\steve\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\steve\\anaconda3\\lib\\site-packages (from sympy->torch>=1.6.0->sentence-transformers) (1.2.1)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from collections import Counter\n",
    "from dataclasses import dataclass\n",
    "from timeit import default_timer as timer\n",
    "import random\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize \n",
    "\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "\n",
    "from spacy.matcher import Matcher \n",
    "from spacy.tokens import Span \n",
    "\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "!pip install sentence-transformers\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "from typing import List, Callable, Dict, Tuple, Set\n",
    "\n",
    "pd.set_option('max_colwidth', 600)\n",
    "pd.set_option('display.max_rows', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "20647b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Sentence Transformer model optimized for  sentence cosine similarity calculations\n",
    "\n",
    "#The models below fully downloaded in Google Colab. This is the version of the google colab notebook but \n",
    "#it was open in anoconda to be saved as pdf and the download graphics did not transfer properly so \n",
    "#it seems like it didn't download. However, it did in the orignal google colab notebook, where all the\n",
    "#analysis was run.\n",
    "\n",
    "model = SentenceTransformer('multi-qa-MiniLM-L6-cos-v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13966d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3b1ab571",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Only run this once, they will be downloaded.\n",
    "nltk.download('stopwords',quiet=True)\n",
    "nltk.download('wordnet',quiet=True)\n",
    "nltk.download('punkt',quiet=True)\n",
    "nltk.download('omw-1.4',quiet=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75a0da03",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in data\n",
    "CORPUS_PATH = 'C:/Users/steve/OneDrive/Desktop/Github/Natural_Language_Processing/Chatbot Assignment/coral_reef_fish.txt'\n",
    "f=open(CORPUS_PATH,'r',errors = 'ignore')\n",
    "raw=f.read()\n",
    "raw=raw.lower()# converts to lowercase\n",
    "\n",
    "#create list of sentences and words\n",
    "sent_tokens = nltk.sent_tokenize(raw)# converts to list of sentences \n",
    "word_tokens = nltk.word_tokenize(raw)# converts to list of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a27ac829",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create greetings and greetings function\n",
    "\n",
    "GREETING_INPUTS = (\"hello\", \"hi\", \"greetings\", \"sup\", \"what's up\",\"hey\",)\n",
    "GREETING_RESPONSES = [\"Hello\"]\n",
    "\n",
    "\n",
    "# Checking for greetings\n",
    "def greeting(sentence):\n",
    "    \"\"\"If user's input is a greeting, return a greeting response\"\"\"\n",
    "    for word in sentence.split():\n",
    "        if word.lower() in GREETING_INPUTS:\n",
    "            return random.choice(GREETING_RESPONSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c0eb55e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Generating response function \n",
    "def response(user_response):\n",
    "    chatbot_response=''\n",
    "    sentence_encodings=model.encode(sent_tokens, convert_to_tensor=True)# generate sentence transformer embeddings\n",
    "    sentence_encodings=sentence_encodings.cpu()\n",
    "    vals = cosine_similarity(sentence_encodings[-1].reshape(1, -1), sentence_encodings) #the chatbot conversation code \n",
    "    #in the next cell adds the question as the last sentence of the sentence tokens, before calling this response function.\n",
    "    #The code takes the last sentence (which is the question) and gets cosine similarities vs all the sentences in the corpus,\n",
    "    #including itself\n",
    "    idx=vals.argsort()[0][-2] #gets the index of the second highest similarity (the first highest would be the question itself)\n",
    "    flat = vals.flatten()#reduces dimension of cosine similarity array to be able to sort\n",
    "    flat.sort() #sort the cosine similarity values\n",
    "    second_cos_sim_val = flat[-2] #get the second highest cosine similarity value.\n",
    "    if(second_cos_sim_val==0): #check the second highest cosine similarity value. If it's zero return the no match response,\n",
    "        #else return highest cosine similarity sentence.\n",
    "        chatbot_response=chatbot_response+\"Sorry, I do not have an answer to your question in my database\"\n",
    "        return chatbot_response\n",
    "    else:\n",
    "        chatbot_response = chatbot_response+sent_tokens[idx] #use index of highest cosine similarity to get original sentence\n",
    "        return chatbot_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8de18951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to the Informational Chatbot About Coral Reef Fish. To end session please type exit.\n",
      "\n",
      "\n",
      "Which species is blue?\n",
      "Answer: the psychedelic synchiropus splendidus is one of only two animal species known to have blue colouring because of cellular pigment.\n",
      "\n",
      "\n",
      "What is the slowest species that lives in coral reefs?\n",
      "Answer: the slowest-moving fishes are the sea horses, often found in reefs.\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [63]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m(flag\u001b[38;5;241m==\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m----> 8\u001b[0m     user_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m     user_response\u001b[38;5;241m=\u001b[39muser_response\u001b[38;5;241m.\u001b[39mlower()\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m user_response\u001b[38;5;241m!=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexit\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py:1075\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[1;34m(self, prompt)\u001b[0m\n\u001b[0;32m   1071\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_allow_stdin:\n\u001b[0;32m   1072\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(\n\u001b[0;32m   1073\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1074\u001b[0m     )\n\u001b[1;32m-> 1075\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_input_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1076\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1077\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parent_ident\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1078\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_parent\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1079\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpassword\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1080\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py:1120\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[1;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[0;32m   1117\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m   1118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[0;32m   1119\u001b[0m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[1;32m-> 1120\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterrupted by user\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m   1121\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1122\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid Message:\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "#Chatbot interaction code\n",
    "\n",
    "flag=True\n",
    "print(\"Welcome to the Informational Chatbot About Coral Reef Fish. To end session please type exit.\")\n",
    "print(\"\\n\")\n",
    "\n",
    "while(flag==True):\n",
    "    user_response = input()\n",
    "    user_response=user_response.lower()\n",
    "    if user_response!='exit':\n",
    "        if(user_response=='thanks' or user_response=='thank you' ):\n",
    "            flag=False\n",
    "            print(\"Answer: You are welcome!\")\n",
    "        else:\n",
    "            if(greeting(user_response)!=None):\n",
    "                print(\"Answer: \"+greeting(user_response))\n",
    "            else:\n",
    "                sent_tokens.append(user_response)\n",
    "                word_tokens=word_tokens+nltk.word_tokenize(user_response)\n",
    "                final_words=list(set(word_tokens))\n",
    "                print(\"Answer: \",end=\"\")\n",
    "                print(response(user_response))\n",
    "                print(\"\\n\")\n",
    "                sent_tokens.remove(user_response)\n",
    "    else:\n",
    "        flag=False\n",
    "        print(\"Thank you for using the Informational Chatbot About Coral Reef Fish. Goodbye.\")    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "293aeedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "chatbot_models = []\n",
    "\n",
    "for i in range(20):\n",
    "    chatbot_models.append(1)\n",
    "    \n",
    "model_1_performance_list = [\"Incorrect\",\n",
    "                          \"Correct\",\n",
    "                          \"Correct\",\n",
    "                          \"Incorrect\",\n",
    "                          \"Incorrect\",\n",
    "                          \"Incorrect\",\n",
    "                          \"Correct\",\n",
    "                          \"Incorrect\",\n",
    "                          \"Incorrect\",\n",
    "                          \"Incorrect\",\n",
    "                          \"Partially Correct\",\n",
    "                          \"Correct\",\n",
    "                          \"Incorrect\",\n",
    "                          \"Incorrect\",\n",
    "                          \"Incorrect\",\n",
    "                          \"Incorrect\",\n",
    "                          \"Correct\",\n",
    "                          \"Incorrect\",\n",
    "                           \"Correct\",\n",
    "                           \"Correct\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64761b2f",
   "metadata": {},
   "source": [
    "## 2) Chatbot 2 - Fine-Tune GPT2 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1145fbcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\steve\\anaconda3\\lib\\site-packages (4.31.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\steve\\anaconda3\\lib\\site-packages (from transformers) (3.6.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in c:\\users\\steve\\anaconda3\\lib\\site-packages (from transformers) (0.16.4)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\steve\\anaconda3\\lib\\site-packages (from transformers) (1.22.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\steve\\anaconda3\\lib\\site-packages (from transformers) (21.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\steve\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\steve\\anaconda3\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\steve\\anaconda3\\lib\\site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\steve\\anaconda3\\lib\\site-packages (from transformers) (2022.3.15)\n",
      "Requirement already satisfied: requests in c:\\users\\steve\\anaconda3\\lib\\site-packages (from transformers) (2.27.1)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\users\\steve\\anaconda3\\lib\\site-packages (from transformers) (0.13.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\steve\\anaconda3\\lib\\site-packages (from transformers) (0.3.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\steve\\anaconda3\\lib\\site-packages (from transformers) (4.64.0)\n",
      "Requirement already satisfied: fsspec in c:\\users\\steve\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2022.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\steve\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.7.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\steve\\anaconda3\\lib\\site-packages (from packaging>=20.0->transformers) (3.0.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\steve\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\steve\\anaconda3\\lib\\site-packages (from requests->transformers) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\steve\\anaconda3\\lib\\site-packages (from requests->transformers) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\steve\\anaconda3\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\steve\\anaconda3\\lib\\site-packages (from requests->transformers) (3.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c59372a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer, AdamW\n",
    "\n",
    "# Load the GPT-2 model and tokenizer\n",
    "model_name = \"gpt2\"\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "# Define multiple question and answer pairs\n",
    "qa_pairs = [\n",
    "    (\"Which species are at the top of the food chain?\", \"sharks and giant moray. STOP\"),\n",
    "    (\"What fish eat coral?\", \"parrotfish and butterflyfish. STOP\"),\n",
    "    (\"Which coral reef fish has the shortest lifespan?\", \"seven-figure pygmy goby. STOP\"),\n",
    "    (\"What species can inflate themselves?\", \"puffers, striated frogfish, and porcupinefish. STOP\"),\n",
    "    (\"How do sea anemones protect themselves?\", \"the tentacles of sea anemones bristle with tiny harpoons (nematocysts) primed with toxins, and are an effective deterrent against most predators. STOP\"),\n",
    "    (\"What species commonly serves as a cleaner fish?\", \"bluestreak cleaner wrasse. STOP\"),\n",
    "    (\"What species eat sponges?\", \"emperor angelfish. STOP\"),\n",
    "    (\"What species eat stingrays?\", \"caribbean reef shark and great hammerheads. STOP\"),\n",
    "    (\"Which species are hermaphrodites\", \"grouper. STOP\"),\n",
    "    (\"What species is known to eat birds?\", \"blacktip reef shark. STOP\")\n",
    "]\n",
    "\n",
    "# Concatenate the question and answer pairs with appropriate formatting\n",
    "formatted_pairs = [f\"Q: {q}\\nA: {a}\\n\" for q, a in qa_pairs]\n",
    "qa_text = \"\\n\".join(formatted_pairs)\n",
    "\n",
    "# Fine-tune the GPT-2 model with the Q&A pairs\n",
    "inputs = tokenizer.encode(qa_text, return_tensors=\"pt\")\n",
    "model.train()\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = AdamW(model.parameters(), lr=1e-5)\n",
    "\n",
    "# Run the fine-tuning loop (example: 1 epoch)\n",
    "for j in range(120):\n",
    "    print (j)\n",
    "    outputs = model(inputs, labels=inputs)\n",
    "    loss = outputs.loss\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "# Save the fine-tuned model\n",
    "model.save_pretrained(\"fine-tuned-gpt2\")\n",
    "\n",
    "# Load the fine-tuned model\n",
    "fine_tuned_model = GPT2LMHeadModel.from_pretrained(\"fine-tuned-gpt2\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0cd5e171",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated completion for the test question:\n",
      "['Q: How many species of fish live in coral reefs?', 'A: About 1,000 species of coral reef fish live in the United States. These fish are an important food source for many species of birds and other marine life. However, coral reef fish are an invasive species and are an invasive species throughout the United States. What species are at the top of the food chain?']\n"
     ]
    }
   ],
   "source": [
    "# Test the fine-tuned model with a question\n",
    "test_question = \"Q: How many species of fish live in coral reefs?\"\n",
    "\n",
    "# Generate a completion for the test question\n",
    "input_ids = tokenizer.encode(test_question, return_tensors=\"pt\")\n",
    "output = fine_tuned_model.generate(input_ids, max_length=100)\n",
    "completion = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "print(\"Generated completion for the test question:\")\n",
    "print(completion.split(\"STOP\")[0].splitlines()[0:2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "28502853",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated completion for the test question:\n",
      "['Q: What is the most venomous fish?', 'A: parrotfish and butterflyfish. Parrotfish are the most venomous fish in the world, and are the most venomous fish in the world. Butterflyfish are the most venomous fish in the world, and are the most venomous fish in the world.']\n"
     ]
    }
   ],
   "source": [
    "# Test the fine-tuned model with a question\n",
    "test_question = \"Q: What is the most venomous fish?\"\n",
    "\n",
    "# Generate a completion for the test question\n",
    "input_ids = tokenizer.encode(test_question, return_tensors=\"pt\")\n",
    "output = fine_tuned_model.generate(input_ids, max_length=100)\n",
    "completion = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "print(\"Generated completion for the test question:\")\n",
    "print(completion.split(\"STOP\")[0].splitlines()[0:2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "18c021ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated completion for the test question:\n",
      "['Q: What sharks live in coral reefs?', 'A: sharks and giant moray. ']\n"
     ]
    }
   ],
   "source": [
    "# Test the fine-tuned model with a question\n",
    "test_question = \"Q: What sharks live in coral reefs?\"\n",
    "\n",
    "# Generate a completion for the test question\n",
    "input_ids = tokenizer.encode(test_question, return_tensors=\"pt\")\n",
    "output = fine_tuned_model.generate(input_ids, max_length=100)\n",
    "completion = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "print(\"Generated completion for the test question:\")\n",
    "print(completion.split(\"STOP\")[0].splitlines()[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5939cefb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated completion for the test question:\n",
      "['Q: What fish are poisonous?', 'A: sharks and giant moray. ']\n"
     ]
    }
   ],
   "source": [
    "# Test the fine-tuned model with a question\n",
    "test_question = \"Q: What fish are poisonous?\"\n",
    "\n",
    "# Generate a completion for the test question\n",
    "input_ids = tokenizer.encode(test_question, return_tensors=\"pt\")\n",
    "output = fine_tuned_model.generate(input_ids, max_length=100)\n",
    "completion = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "print(\"Generated completion for the test question:\")\n",
    "print(completion.split(\"STOP\")[0].splitlines()[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d34030f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated completion for the test question:\n",
      "['Q: What fish can electrocute you?', 'A: sharks and giant moray. ']\n"
     ]
    }
   ],
   "source": [
    "# Test the fine-tuned model with a question\n",
    "test_question = \"Q: What fish can electrocute you?\"\n",
    "\n",
    "# Generate a completion for the test question\n",
    "input_ids = tokenizer.encode(test_question, return_tensors=\"pt\")\n",
    "output = fine_tuned_model.generate(input_ids, max_length=100)\n",
    "completion = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "print(\"Generated completion for the test question:\")\n",
    "print(completion.split(\"STOP\")[0].splitlines()[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a90edc58",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated completion for the test question:\n",
      "['Q: What species can sting you?', 'A: sharks and giant moray. ']\n"
     ]
    }
   ],
   "source": [
    "# Test the fine-tuned model with a question\n",
    "test_question = \"Q: What species can sting you?\"\n",
    "\n",
    "# Generate a completion for the test question\n",
    "input_ids = tokenizer.encode(test_question, return_tensors=\"pt\")\n",
    "output = fine_tuned_model.generate(input_ids, max_length=100)\n",
    "completion = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "print(\"Generated completion for the test question:\")\n",
    "print(completion.split(\"STOP\")[0].splitlines()[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "99cedfc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated completion for the test question:\n",
      "['Q: What species are parasitic?', 'A: sharks and giant moray. ']\n"
     ]
    }
   ],
   "source": [
    "# Test the fine-tuned model with a question\n",
    "test_question = \"Q: What species are parasitic?\"\n",
    "\n",
    "# Generate a completion for the test question\n",
    "input_ids = tokenizer.encode(test_question, return_tensors=\"pt\")\n",
    "output = fine_tuned_model.generate(input_ids, max_length=100)\n",
    "completion = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "print(\"Generated completion for the test question:\")\n",
    "print(completion.split(\"STOP\")[0].splitlines()[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7d5a151a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated completion for the test question:\n",
      "['Q: What species are venomous?', 'A: sharks and giant moray. ']\n"
     ]
    }
   ],
   "source": [
    "# Test the fine-tuned model with a question\n",
    "test_question = \"Q: What species are venomous?\"\n",
    "\n",
    "# Generate a completion for the test question\n",
    "input_ids = tokenizer.encode(test_question, return_tensors=\"pt\")\n",
    "output = fine_tuned_model.generate(input_ids, max_length=100)\n",
    "completion = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "print(\"Generated completion for the test question:\")\n",
    "print(completion.split(\"STOP\")[0].splitlines()[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a7ee6ee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated completion for the test question:\n",
      "['Q: What species are known for attacking scuba divers?', 'A: sharks and giant moray. ']\n"
     ]
    }
   ],
   "source": [
    "# Test the fine-tuned model with a question\n",
    "test_question = \"Q: What species are known for attacking scuba divers?\"\n",
    "\n",
    "# Generate a completion for the test question\n",
    "input_ids = tokenizer.encode(test_question, return_tensors=\"pt\")\n",
    "output = fine_tuned_model.generate(input_ids, max_length=100)\n",
    "completion = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "print(\"Generated completion for the test question:\")\n",
    "print(completion.split(\"STOP\")[0].splitlines()[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5e5a100b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated completion for the test question:\n",
      "['Q: What are common herbivorous fish?', 'A: puffers, striated frogfish, and porcupinefish. They are great at eating invertebrates, and are an excellent source of vitamin A. They are an excellent source of calcium, and are an excellent source of iron.']\n"
     ]
    }
   ],
   "source": [
    "# Test the fine-tuned model with a question\n",
    "test_question = \"Q: What are common herbivorous fish?\"\n",
    "\n",
    "# Generate a completion for the test question\n",
    "input_ids = tokenizer.encode(test_question, return_tensors=\"pt\")\n",
    "output = fine_tuned_model.generate(input_ids, max_length=100)\n",
    "completion = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "print(\"Generated completion for the test question:\")\n",
    "print(completion.split(\"STOP\")[0].splitlines()[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9d7b9b52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated completion for the test question:\n",
      "['Q: Why do fish camouflage themselves?', 'A: Because fish camouflage themselves. They are the most effective predators on land. They are the most effective predators on fish. They are the most effective predators on birds. They are the most effective predators on fish. They are the most effective predators on fish. They are the most effective predators on fish. They are the most effective predators on fish. They are the most effective predators on fish. They are the most effective predators on fish. They are the']\n"
     ]
    }
   ],
   "source": [
    "# Test the fine-tuned model with a question\n",
    "test_question = \"Q: Why do fish camouflage themselves?\"\n",
    "\n",
    "# Generate a completion for the test question\n",
    "input_ids = tokenizer.encode(test_question, return_tensors=\"pt\")\n",
    "output = fine_tuned_model.generate(input_ids, max_length=100)\n",
    "completion = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "print(\"Generated completion for the test question:\")\n",
    "print(completion.split(\"STOP\")[0].splitlines()[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "59c68605",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated completion for the test question:\n",
      "['Q: How do fish get rid of their parasites?', 'A: Fish eat parasites, and fish eat fish. Fish eat parasites because fish eat parasites. Fish eat fish because fish eat parasites. Fish eat fish because fish eat parasites. Fish eat fish because fish eat parasites. Fish eat fish because fish eat parasites. Fish eat fish because fish eat parasites. Fish eat fish because fish eat parasites. Fish eat fish because fish eat parasites. Fish eat fish because fish eat parasites. Fish eat fish because fish']\n"
     ]
    }
   ],
   "source": [
    "# Test the fine-tuned model with a question\n",
    "test_question = \"Q: How do fish get rid of their parasites?\"\n",
    "\n",
    "# Generate a completion for the test question\n",
    "input_ids = tokenizer.encode(test_question, return_tensors=\"pt\")\n",
    "output = fine_tuned_model.generate(input_ids, max_length=100)\n",
    "completion = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "print(\"Generated completion for the test question:\")\n",
    "print(completion.split(\"STOP\")[0].splitlines()[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "de190098",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated completion for the test question:\n",
      "['Q: What species have a mutualistic relationship?', 'A: sharks and giant moray. ']\n"
     ]
    }
   ],
   "source": [
    "# Test the fine-tuned model with a question\n",
    "test_question = \"Q: What species have a mutualistic relationship?\"\n",
    "\n",
    "# Generate a completion for the test question\n",
    "input_ids = tokenizer.encode(test_question, return_tensors=\"pt\")\n",
    "output = fine_tuned_model.generate(input_ids, max_length=100)\n",
    "completion = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "print(\"Generated completion for the test question:\")\n",
    "print(completion.split(\"STOP\")[0].splitlines()[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cc8587c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated completion for the test question:\n",
      "['Q: What species have a commensalistic relationship?', 'A: sharks and giant moray. ']\n"
     ]
    }
   ],
   "source": [
    "# Test the fine-tuned model with a question\n",
    "test_question = \"Q: What species have a commensalistic relationship?\"\n",
    "\n",
    "# Generate a completion for the test question\n",
    "input_ids = tokenizer.encode(test_question, return_tensors=\"pt\")\n",
    "output = fine_tuned_model.generate(input_ids, max_length=100)\n",
    "completion = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "print(\"Generated completion for the test question:\")\n",
    "print(completion.split(\"STOP\")[0].splitlines()[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1480fd38",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated completion for the test question:\n",
      "['Q: Where in the world are coral reefs found?', 'A: Coral reefs are the largest coral reef in the world. They are the largest coral reef in the world because of their size and because of their ability to withstand the elements. They are the most abundant coral reef fish in the world. They are an important food source for birds, and are an important food source for sea anemones. They are an excellent predator for fish and are an excellent finisher for reef fish.']\n"
     ]
    }
   ],
   "source": [
    "# Test the fine-tuned model with a question\n",
    "test_question = \"Q: Where in the world are coral reefs found?\"\n",
    "\n",
    "# Generate a completion for the test question\n",
    "input_ids = tokenizer.encode(test_question, return_tensors=\"pt\")\n",
    "output = fine_tuned_model.generate(input_ids, max_length=100)\n",
    "completion = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "print(\"Generated completion for the test question:\")\n",
    "print(completion.split(\"STOP\")[0].splitlines()[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "602e43fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated completion for the test question:\n",
      "['Q: What species engage in schooling?', 'A: sharks and giant moray. ']\n"
     ]
    }
   ],
   "source": [
    "# Test the fine-tuned model with a question\n",
    "test_question = \"Q: What species engage in schooling?\"\n",
    "\n",
    "# Generate a completion for the test question\n",
    "input_ids = tokenizer.encode(test_question, return_tensors=\"pt\")\n",
    "output = fine_tuned_model.generate(input_ids, max_length=100)\n",
    "completion = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "print(\"Generated completion for the test question:\")\n",
    "print(completion.split(\"STOP\")[0].splitlines()[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "68a09451",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated completion for the test question:\n",
      "['Q: What species are ambush predators?', 'A: sharks and giant moray. ']\n"
     ]
    }
   ],
   "source": [
    "# Test the fine-tuned model with a question\n",
    "test_question = \"Q: What species are ambush predators?\"\n",
    "\n",
    "# Generate a completion for the test question\n",
    "input_ids = tokenizer.encode(test_question, return_tensors=\"pt\")\n",
    "output = fine_tuned_model.generate(input_ids, max_length=100)\n",
    "completion = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "print(\"Generated completion for the test question:\")\n",
    "print(completion.split(\"STOP\")[0].splitlines()[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2d4926ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated completion for the test question:\n",
      "['Q: Which species are ambush predators?', 'A: sharks and giant moray. ']\n"
     ]
    }
   ],
   "source": [
    "# Test the fine-tuned model with a question\n",
    "test_question = \"Q: Which species are ambush predators?\"\n",
    "\n",
    "# Generate a completion for the test question\n",
    "input_ids = tokenizer.encode(test_question, return_tensors=\"pt\")\n",
    "output = fine_tuned_model.generate(input_ids, max_length=100)\n",
    "completion = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "print(\"Generated completion for the test question:\")\n",
    "print(completion.split(\"STOP\")[0].splitlines()[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0d405fe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated completion for the test question:\n",
      "['Q: Why are some coral reef fish colorful?', 'A: Coral reef fish are known to eat fish, and are an effective deterrent against most predators. However, coral reef fish are also known to eat stingrays, which are an effective deterrent against most predators.']\n"
     ]
    }
   ],
   "source": [
    "# Test the fine-tuned model with a question\n",
    "test_question = \"Q: Why are some coral reef fish colorful?\"\n",
    "\n",
    "# Generate a completion for the test question\n",
    "input_ids = tokenizer.encode(test_question, return_tensors=\"pt\")\n",
    "output = fine_tuned_model.generate(input_ids, max_length=100)\n",
    "completion = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "print(\"Generated completion for the test question:\")\n",
    "print(completion.split(\"STOP\")[0].splitlines()[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "301f292f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated completion for the test question:\n",
      "['Q: Which species is blue?', 'A: sharks and giant moray. ']\n"
     ]
    }
   ],
   "source": [
    "# Test the fine-tuned model with a question\n",
    "test_question = \"Q: Which species is blue?\"\n",
    "\n",
    "# Generate a completion for the test question\n",
    "input_ids = tokenizer.encode(test_question, return_tensors=\"pt\")\n",
    "output = fine_tuned_model.generate(input_ids, max_length=100)\n",
    "completion = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "print(\"Generated completion for the test question:\")\n",
    "print(completion.split(\"STOP\")[0].splitlines()[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9ba1e607",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated completion for the test question:\n",
      "['Q: What is the slowest species that lives in coral reefs?', 'A: sharks and giant moray. ']\n"
     ]
    }
   ],
   "source": [
    "# Test the fine-tuned model with a question\n",
    "test_question = \"Q: What is the slowest species that lives in coral reefs?\"\n",
    "\n",
    "# Generate a completion for the test question\n",
    "input_ids = tokenizer.encode(test_question, return_tensors=\"pt\")\n",
    "output = fine_tuned_model.generate(input_ids, max_length=100)\n",
    "completion = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "print(\"Generated completion for the test question:\")\n",
    "print(completion.split(\"STOP\")[0].splitlines()[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "f3e7a4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(20):\n",
    "    chatbot_models.append(2)\n",
    "    \n",
    "    \n",
    "model_2_performance_list = [\"Partially Correct\",\n",
    "                          \"Incorrect\",\n",
    "                          \"Incorrect\",\n",
    "                          \"Partially Correct\",\n",
    "                          \"Incorrect\", \n",
    "                          \"Incorrect\",\n",
    "                          \"Incorrect\",\n",
    "                          \"Incorrect\",\n",
    "                          \"Partially Correct\",\n",
    "                          \"Incorrect\",\n",
    "                          \"Incorrect\",\n",
    "                          \"Partially Correct\",\n",
    "                          \"Incorrect\",\n",
    "                          \"Incorrect\",\n",
    "                          \"Incorrect\",\n",
    "                          \"Incorrect\",\n",
    "                          \"Incorrect\",\n",
    "                          \"Incorrect\",\n",
    "                          \"Incorrect\",\n",
    "                           \"Incorrect\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd3fafe",
   "metadata": {},
   "source": [
    "## 3) Chatbot 3 - Chatbot Emphasizing Cosine Similarity of TF-IDF Representations of Sententces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "72628a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import random\n",
    "import string # to process standard python strings\n",
    "import warnings\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ff400af3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('popular', quiet=True) # for downloading packages\n",
    "#nltk.download('punkt') # first-time use only\n",
    "#nltk.download('wordnet') # first-time use only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f8b54d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "CORPUS_PATH = 'C:/Users/steve/OneDrive/Desktop/Github/Natural_Language_Processing/Chatbot Assignment/coral_reef_fish.txt'\n",
    "f=open(CORPUS_PATH,'r',errors = 'ignore')\n",
    "raw=f.read()\n",
    "raw = raw.lower()# converts to lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cd876b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_tokens = nltk.sent_tokenize(raw)# converts to list of sentences \n",
    "word_tokens = nltk.word_tokenize(raw)# converts to list of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0c3be15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmer = nltk.stem.WordNetLemmatizer()\n",
    "#WordNet is a semantically-oriented dictionary of English included in NLTK.\n",
    "def LemTokens(tokens):\n",
    "    return [lemmer.lemmatize(token) for token in tokens]\n",
    "remove_punct_dict = dict((ord(punct), None) for punct in string.punctuation)\n",
    "\n",
    "def LemNormalize(text):\n",
    "    return LemTokens(nltk.word_tokenize(text.lower().translate(remove_punct_dict)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fd25bc1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "GREETING_INPUTS = (\"hello\", \"hi\", \"greetings\", \"sup\", \"what's up\",\"hey\",)\n",
    "GREETING_RESPONSES = [\"Hi\", \"Hey\", \"*nods*\", \"Hi there\", \"Hello\", \"I am glad! You are talking to me\"]\n",
    "def greeting(sentence):\n",
    " \n",
    "    for word in sentence.split():\n",
    "        if word.lower() in GREETING_INPUTS:\n",
    "            return random.choice(GREETING_RESPONSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "075fbb64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def response(user_response):\n",
    "    robo_response=''\n",
    "    sent_tokens.append(user_response)\n",
    "    TfidfVec = TfidfVectorizer(tokenizer=LemNormalize, stop_words='english')\n",
    "    tfidf = TfidfVec.fit_transform(sent_tokens)\n",
    "    vals = cosine_similarity(tfidf[-1], tfidf)\n",
    "    idx=vals.argsort()[0][-2]\n",
    "    flat = vals.flatten()\n",
    "    flat.sort()\n",
    "    req_tfidf = flat[-2]\n",
    "    if(req_tfidf==0):\n",
    "        robo_response=robo_response+\"I am sorry! I don't understand you\"\n",
    "        return robo_response\n",
    "    else:\n",
    "        robo_response = robo_response+sent_tokens[idx]\n",
    "        return robo_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c0f86069",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, I am the Third Coral Reef Chatbot! I will answer your queries related to coral reef fish. If you want to exit, type Bye!\n",
      "How many species of fish live in coral reefs?\n",
      " coral reef fish are fish which live amongst or in close relation to coral reefs.\n",
      "What is the most venomous fish?\n",
      " there is a distinction between poisonous fish and venomous fish.\n",
      "What sharks live in coral reefs?\n",
      " coral reef fish are fish which live amongst or in close relation to coral reefs.\n",
      "What fish are poisonous?\n",
      " there is a distinction between poisonous fish and venomous fish.\n",
      "What fish can electrocute you?\n",
      " as with all fish, coral reef fish harbour parasites.\n",
      "What species can sting you?\n",
      " in return, the anemones provide the clownfish protection from their predators, who are not immune to anemone stings.\n",
      "What species are venomous?\n",
      " the most venomous known fish is the reef stonefish.\n",
      "What species are parasitic?\n",
      " parasites of coral reef fish include nematodes, platyhelminthes (cestodes, digeneans, and monogeneans), leeches, parasitic crustaceans such as isopods and copepods, and various microorganisms such as myxosporidia and microsporidia.\n",
      "What species are known for attacking scuba divers?\n",
      " lionfish can aggressively dart at scuba divers and attempt to puncture the facemask with their venomous spines.\n",
      "What are common herbivorous fish?\n",
      " sea anemones are common on reefs.\n",
      "Why do fish camouflage themselves?\n",
      " sometimes they camouflage the fish when the fish rests in places with the right background.\n",
      "How do fish get rid of their parasites?\n",
      " as with all fish, coral reef fish harbour parasites.\n",
      "What species have mutualistic relationships?\n",
      " there is a mutualistic relationship between sea anemones and clownfish.\n",
      "What species have commensalistic relationships?\n",
      " the relationship can be mutualistic, when both species benefit from the relationship, commensalistic, when one species benefits and the other is unaffected, and parasitistic, when one species benefits, and the other is harmed.\n",
      "Where in the world are coral reefs found?\n",
      " coral reefs contain the most diverse fish assemblages to be found anywhere on earth, with perhaps as many as 6,0008,000 species dwelling within coral reef ecosystems of the world's oceans.\n",
      "What species engage in schooling?\n",
      " they have evolved to find protection by schooling, sometimes with other species like shoaling rabbitfish.\n",
      "What species are ambush predators?\n",
      " the well camouflaged striated frogfish, a species of anglerfish, is an ambush predator.\n",
      "Why are some coral reef fish colorful?\n",
      " coral reef fish are fish which live amongst or in close relation to coral reefs.\n",
      "What species is blue?\n",
      " the psychedelic synchiropus splendidus is one of only two animal species known to have blue colouring because of cellular pigment.\n",
      "What is the slowest species that lives in coral reefs?\n",
      " some of these fish parasites have heteroxenous life cycles (i.e.\n",
      "exit\n",
      " after dusk, a group of sharks may target the same prey item, covering every exit route from a particular coral head.\n",
      "bye\n",
      "Bye! take care..\n"
     ]
    }
   ],
   "source": [
    "flag=True\n",
    "print(\"Hello, I am the Third Coral Reef Chatbot! I will answer your queries related to coral reef fish. If you want to exit, type Bye!\")\n",
    "while(flag==True):\n",
    "    user_response = input()\n",
    "    user_response=user_response.lower()\n",
    "    if(user_response!='bye'):\n",
    "        if(user_response=='thanks' or user_response=='thank you' ):\n",
    "            flag=False\n",
    "            print(\"You are welcome.\")\n",
    "        else:\n",
    "            if(greeting(user_response)!=None):\n",
    "                print(greeting(user_response))\n",
    "            else:\n",
    "                print(\"\",end=\"\")\n",
    "                print(response(user_response))\n",
    "                sent_tokens.remove(user_response)\n",
    "    else:\n",
    "        flag=False\n",
    "        print(\"Bye! take care..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "cb7b3f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in range(20):\n",
    "    chatbot_models.append(3)\n",
    "\n",
    "model_3_performance_list = [\"Incorrect\",\n",
    "                          \"Incorrect\", \n",
    "                          \"Incorrect\",\n",
    "                          \"Incorrect\",\n",
    "                          \"Incorrect\",\n",
    "                          \"Correct\",\n",
    "                          \"Correct\",\n",
    "                          \"Correct\",\n",
    "                          \"Correct\",\n",
    "                          \"Incorrect\",\n",
    "                          \"Partially Correct\",\n",
    "                          \"Incorrect\",\n",
    "                          \"Correct\",\n",
    "                          \"Incorrect\",\n",
    "                          \"Partially Correct\",\n",
    "                          \"Correct\",\n",
    "                          \"Correct\",\n",
    "                          \"Incorrect\",\n",
    "                           \"Correct\",\n",
    "                           \"Incorrect\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7800bd6e",
   "metadata": {},
   "source": [
    "## 4) Chatbot 4 - Distillbert"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28efcc5a",
   "metadata": {},
   "source": [
    "Source: https://huggingface.co/distilbert-base-cased-distilled-squad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "885d5eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in data\n",
    "CORPUS_PATH = 'C:/Users/steve/OneDrive/Desktop/Github/Natural_Language_Processing/Chatbot Assignment/coral_reef_fish.txt'\n",
    "f=open(CORPUS_PATH,'r',errors = 'ignore')\n",
    "raw=f.read()\n",
    "raw=raw.lower()# converts to lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7eda8054",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c335709050cc41408cf0b259dfb30250",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading ()lve/main/config.json:   0%|          | 0.00/473 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\anaconda3\\lib\\site-packages\\huggingface_hub\\file_download.py:133: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\steve\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3481820acaf44108aece05bf0c72f90a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/261M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02121f45eb2c4dfdaecf5c2628b412ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading ()okenizer_config.json:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "891b970f38ec41c690252989b8b3bad2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading ()solve/main/vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6968b58d491146be997f831b71cd2160",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading ()/main/tokenizer.json:   0%|          | 0.00/436k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: 'the great hammerhead uses its hammer', score: 0.0377, start: 34598, end: 34634\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "question_answerer = pipeline(\"question-answering\", model='distilbert-base-cased-distilled-squad')\n",
    "\n",
    "#context = r\"\"\"\n",
    "#Extractive Question Answering is the task of extracting an answer from a text given a question. An example     of a\n",
    "#question answering dataset is the SQuAD dataset, which is entirely based on that task. If you would like to fine-tune\n",
    "#a model on a SQuAD task, you may leverage the examples/pytorch/question-answering/run_squad.py script.\n",
    "#\"\"\"\n",
    "\n",
    "result = question_answerer(question=\"What is a good example of a question answering dataset?\",     context=raw)\n",
    "print(f\"Answer: '{result['answer']}', score: {round(result['score'], 4)}, start: {result['start']}, end: {result['end']}\")\n",
    "\n",
    "#Answer: 'SQuAD dataset', score: 0.5152, start: 147, end: 160"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "62b23153",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: 'four', score: 0.6391, start: 17258, end: 17262\n"
     ]
    }
   ],
   "source": [
    "result = question_answerer(question=\"How many species of fish live in coral reefs?\",     context=raw)\n",
    "print(f\"Answer: '{result['answer']}', score: {round(result['score'], 4)}, start: {result['start']}, end: {result['end']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cb615187",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: 'reef stonefish', score: 0.8257, start: 24899, end: 24913\n"
     ]
    }
   ],
   "source": [
    "result = question_answerer(question=\"What is the most venomous fish?\", context=raw)\n",
    "print(f\"Answer: '{result['answer']}', score: {round(result['score'], 4)}, start: {result['start']}, end: {result['end']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9ea93923",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: 'whitetip reef shark', score: 0.8656, start: 34283, end: 34302\n"
     ]
    }
   ],
   "source": [
    "result = question_answerer(question=\"What sharks live in coral reefs?\",     context=raw)\n",
    "print(f\"Answer: '{result['answer']}', score: {round(result['score'], 4)}, start: {result['start']}, end: {result['end']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ee83ab02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: 'coral reef fish', score: 0.8148, start: 0, end: 15\n"
     ]
    }
   ],
   "source": [
    "result = question_answerer(question=\"What fish are poisonous?\",     context=raw)\n",
    "print(f\"Answer: '{result['answer']}', score: {round(result['score'], 4)}, start: {result['start']}, end: {result['end']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d5f676f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: 'snapper', score: 0.3421, start: 11139, end: 11146\n"
     ]
    }
   ],
   "source": [
    "result = question_answerer(question=\"What fish can electrocute you?\",     context=raw)\n",
    "print(f\"Answer: '{result['answer']}', score: {round(result['score'], 4)}, start: {result['start']}, end: {result['end']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fb01cfef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: 'yellow stingrays', score: 0.6958, start: 34108, end: 34124\n"
     ]
    }
   ],
   "source": [
    "result = question_answerer(question=\"What species can sting you?\",     context=raw)\n",
    "print(f\"Answer: '{result['answer']}', score: {round(result['score'], 4)}, start: {result['start']}, end: {result['end']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5f9a7d8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: 'coral reef fish', score: 0.5431, start: 0, end: 15\n"
     ]
    }
   ],
   "source": [
    "result = question_answerer(question=\"What species are parasitic?\", context=raw)\n",
    "print(f\"Answer: '{result['answer']}', score: {round(result['score'], 4)}, start: {result['start']}, end: {result['end']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5a24c228",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: 'spinefoot rabbitfish', score: 0.9286, start: 18449, end: 18469\n"
     ]
    }
   ],
   "source": [
    "result = question_answerer(question=\"What species are venomous?\", context=raw)\n",
    "print(f\"Answer: '{result['answer']}', score: {round(result['score'], 4)}, start: {result['start']}, end: {result['end']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "59ecdb10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: 'lionfish', score: 0.9109, start: 26369, end: 26377\n"
     ]
    }
   ],
   "source": [
    "result = question_answerer(question=\"What species are known for attacking scuba divers?\", context=raw)\n",
    "print(f\"Answer: '{result['answer']}', score: {round(result['score'], 4)}, start: {result['start']}, end: {result['end']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "45c8ffd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: 'yellow tang', score: 0.5247, start: 2116, end: 2127\n"
     ]
    }
   ],
   "source": [
    "result = question_answerer(question=\"What are common herbivorous fish?\", context=raw)\n",
    "print(f\"Answer: '{result['answer']}', score: {round(result['score'], 4)}, start: {result['start']}, end: {result['end']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a10cb49a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: 'when the fish rests in places with the right background', score: 0.7476, start: 6715, end: 6770\n"
     ]
    }
   ],
   "source": [
    "result = question_answerer(question=\"Why do fish camouflage themselves?\", context=raw)\n",
    "print(f\"Answer: '{result['answer']}', score: {round(result['score'], 4)}, start: {result['start']}, end: {result['end']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8db81c6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: 'by biting, stinging, or stabbing', score: 0.4523, start: 23987, end: 24019\n"
     ]
    }
   ],
   "source": [
    "result = question_answerer(question=\"How do fish get rid of their parasites?\", context=raw)\n",
    "print(f\"Answer: '{result['answer']}', score: {round(result['score'], 4)}, start: {result['start']}, end: {result['end']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cb119fae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: 'sea anemones and clownfish', score: 0.8657, start: 21835, end: 21861\n"
     ]
    }
   ],
   "source": [
    "result = question_answerer(question=\"What species have mutualistic relationships?\", context=raw)\n",
    "print(f\"Answer: '{result['answer']}', score: {round(result['score'], 4)}, start: {result['start']}, end: {result['end']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d7b29222",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: 'sea anemones and clownfish', score: 0.6863, start: 21835, end: 21861\n"
     ]
    }
   ],
   "source": [
    "result = question_answerer(question=\"What species have commensalistic relationships?\", context=raw)\n",
    "print(f\"Answer: '{result['answer']}', score: {round(result['score'], 4)}, start: {result['start']}, end: {result['end']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "08bdb70f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: 'top predators', score: 0.8029, start: 26812, end: 26825\n"
     ]
    }
   ],
   "source": [
    "result = question_answerer(question=\"Where in the world are coral reefs found?\", context=raw)\n",
    "print(f\"Answer: '{result['answer']}', score: {round(result['score'], 4)}, start: {result['start']}, end: {result['end']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bc507af6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: 'spinefoot rabbitfish', score: 0.6337, start: 19619, end: 19639\n"
     ]
    }
   ],
   "source": [
    "result = question_answerer(question=\"What species engage in schooling?\", context=raw)\n",
    "print(f\"Answer: '{result['answer']}', score: {round(result['score'], 4)}, start: {result['start']}, end: {result['end']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0f8df765",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: 'frogfish', score: 0.5638, start: 9688, end: 9696\n"
     ]
    }
   ],
   "source": [
    "result = question_answerer(question=\"Which species are ambush predators?\", context=raw)\n",
    "print(f\"Answer: '{result['answer']}', score: {round(result['score'], 4)}, start: {result['start']}, end: {result['end']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8e23e842",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: 'high biodiversity', score: 0.7926, start: 22542, end: 22559\n"
     ]
    }
   ],
   "source": [
    "result = question_answerer(question=\"Why are some coral reef fish colorful?\", context=raw)\n",
    "print(f\"Answer: '{result['answer']}', score: {round(result['score'], 4)}, start: {result['start']}, end: {result['end']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "eb6c9400",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: 'bluestripe snapper', score: 0.6375, start: 12029, end: 12047\n"
     ]
    }
   ],
   "source": [
    "result = question_answerer(question=\"Which species is blue?\", context=raw)\n",
    "print(f\"Answer: '{result['answer']}', score: {round(result['score'], 4)}, start: {result['start']}, end: {result['end']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d9a8220a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: 'dwarf seahorse', score: 0.4608, start: 4939, end: 4953\n"
     ]
    }
   ],
   "source": [
    "result = question_answerer(question=\"What is the slowest species that lives in coral reefs?\", context=raw)\n",
    "print(f\"Answer: '{result['answer']}', score: {round(result['score'], 4)}, start: {result['start']}, end: {result['end']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "07b0c26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in range(20):\n",
    "    chatbot_models.append(4)\n",
    "\n",
    "model_4_performance_list = [\"Incorrect\",\n",
    "                          \"Correct\",\n",
    "                           \"Correct\",\n",
    "                           \"Incorrect\",\n",
    "                           \"Incorrect\",\n",
    "                           \"Correct\",\n",
    "                           \"Incorrect\",\n",
    "                           \"Correct\",\n",
    "                           \"Correct\",\n",
    "                           \"Correct\",\n",
    "                           \"Incorrect\",\n",
    "                           \"Incorrect\",\n",
    "                           \"Correct\",\n",
    "                           \"Incorrect\",\n",
    "                           \"Incorrect\",\n",
    "                           \"Correct\",\n",
    "                           \"Correct\",\n",
    "                           \"Incorrect\",\n",
    "                           \"Partially Correct\",\n",
    "                           \"Correct\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ca2aa3",
   "metadata": {},
   "source": [
    "## 5) Chatbot 5 - Roberta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d71f998b",
   "metadata": {},
   "source": [
    "https://huggingface.co/deepset/roberta-base-squad2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6c15be58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForQuestionAnswering, AutoTokenizer, pipeline, RobertaTokenizer, RobertaModel, TFRobertaModel\n",
    "from transformers import optimization\n",
    "\n",
    "batch_size = 96\n",
    "n_epochs = 2\n",
    "base_LM_model = \"roberta-base\"\n",
    "max_seq_len = 386\n",
    "learning_rate = 3e-5\n",
    "#lr_schedule = optimization.LinearWarmup\n",
    "warmup_proportion = 0.2\n",
    "doc_stride=128\n",
    "max_query_length=64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0d9d0774",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting farm-haystack[inference]\n",
      "  Obtaining dependency information for farm-haystack[inference] from https://files.pythonhosted.org/packages/df/ef/485cd648ee02afafd5c014b609c214299507112c246b75303f91fd2c139f/farm_haystack-1.19.0-py3-none-any.whl.metadata\n",
      "  Downloading farm_haystack-1.19.0-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting boilerpy3 (from farm-haystack[inference])\n",
      "  Downloading boilerpy3-1.0.6-py3-none-any.whl (22 kB)\n",
      "Collecting canals==0.3.2 (from farm-haystack[inference])\n",
      "  Obtaining dependency information for canals==0.3.2 from https://files.pythonhosted.org/packages/b8/f6/6d2071a20400129a72390f021b46603f694d29553df0725152864c3c40f3/canals-0.3.2-py3-none-any.whl.metadata\n",
      "  Downloading canals-0.3.2-py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting events (from farm-haystack[inference])\n",
      "  Obtaining dependency information for events from https://files.pythonhosted.org/packages/25/ed/e47dec0626edd468c84c04d97769e7ab4ea6457b7f54dcb3f72b17fcd876/Events-0.5-py3-none-any.whl.metadata\n",
      "  Downloading Events-0.5-py3-none-any.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: jsonschema in c:\\users\\steve\\anaconda3\\lib\\site-packages (from farm-haystack[inference]) (4.4.0)\n",
      "Collecting lazy-imports==0.3.1 (from farm-haystack[inference])\n",
      "  Downloading lazy_imports-0.3.1-py3-none-any.whl (12 kB)\n",
      "Collecting more-itertools (from farm-haystack[inference])\n",
      "  Obtaining dependency information for more-itertools from https://files.pythonhosted.org/packages/5a/cb/6dce742ea14e47d6f565589e859ad225f2a5de576d7696e0623b784e226b/more_itertools-10.1.0-py3-none-any.whl.metadata\n",
      "  Downloading more_itertools-10.1.0-py3-none-any.whl.metadata (33 kB)\n",
      "Requirement already satisfied: networkx in c:\\users\\steve\\anaconda3\\lib\\site-packages (from farm-haystack[inference]) (2.7.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\steve\\anaconda3\\lib\\site-packages (from farm-haystack[inference]) (1.4.2)\n",
      "Requirement already satisfied: pillow in c:\\users\\steve\\anaconda3\\lib\\site-packages (from farm-haystack[inference]) (9.0.1)\n",
      "Collecting platformdirs (from farm-haystack[inference])\n",
      "  Obtaining dependency information for platformdirs from https://files.pythonhosted.org/packages/14/51/fe5a0d6ea589f0d4a1b97824fb518962ad48b27cd346dcdfa2405187997a/platformdirs-3.10.0-py3-none-any.whl.metadata\n",
      "  Downloading platformdirs-3.10.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting posthog (from farm-haystack[inference])\n",
      "  Obtaining dependency information for posthog from https://files.pythonhosted.org/packages/a7/73/35758818228c70348be4c3c66a76653c62e894e0e3c3461453c5341ca926/posthog-3.0.2-py2.py3-none-any.whl.metadata\n",
      "  Downloading posthog-3.0.2-py2.py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting prompthub-py==4.0.0 (from farm-haystack[inference])\n",
      "  Obtaining dependency information for prompthub-py==4.0.0 from https://files.pythonhosted.org/packages/27/5f/8c4939e290ff93af79364b88ffe3902d29c234f94e8227cf0b7fce3c887f/prompthub_py-4.0.0-py3-none-any.whl.metadata\n",
      "  Downloading prompthub_py-4.0.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: pydantic<2 in c:\\users\\steve\\anaconda3\\lib\\site-packages (from farm-haystack[inference]) (1.10.12)\n",
      "Collecting quantulum3 (from farm-haystack[inference])\n",
      "  Downloading quantulum3-0.9.0-py3-none-any.whl (10.7 MB)\n",
      "     --------------------------------------- 10.7/10.7 MB 11.1 MB/s eta 0:00:00\n",
      "Collecting rank-bm25 (from farm-haystack[inference])\n",
      "  Downloading rank_bm25-0.2.2-py3-none-any.whl (8.6 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\steve\\anaconda3\\lib\\site-packages (from farm-haystack[inference]) (2.27.1)\n",
      "Collecting requests-cache<1.0.0 (from farm-haystack[inference])\n",
      "  Downloading requests_cache-0.9.8-py3-none-any.whl (48 kB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\steve\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\steve\\anaconda3\\lib\\site-packages)\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "conda-repo-cli 1.0.4 requires pathlib, which is not installed.\n",
      "spyder 5.1.5 requires pyqt5<5.13, which is not installed.\n",
      "spyder 5.1.5 requires pyqtwebengine<5.13, which is not installed.\n",
      "google-api-core 1.25.1 requires google-auth<2.0dev,>=1.21.1, but you have google-auth 2.18.1 which is incompatible.\n",
      "google-cloud-core 1.7.1 requires google-auth<2.0dev,>=1.24.0, but you have google-auth 2.18.1 which is incompatible.\n",
      "google-cloud-storage 1.31.0 requires google-auth<2.0dev,>=1.11.0, but you have google-auth 2.18.1 which is incompatible.\n",
      "tensorboard 2.12.3 requires tensorboard-data-server<0.8.0,>=0.7.0, but you have tensorboard-data-server 0.6.1 which is incompatible.\n",
      "tensorflow-intel 2.12.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 4.21.0 which is incompatible.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     ---------------------------------------- 48.7/48.7 kB ? eta 0:00:00\n",
      "Collecting scikit-learn>=1.3.0 (from farm-haystack[inference])\n",
      "  Obtaining dependency information for scikit-learn>=1.3.0 from https://files.pythonhosted.org/packages/2d/30/3afb8bcb785653254eb646ff2680ec4d637b40b06f4b046aca17b5e086b0/scikit_learn-1.3.0-cp39-cp39-win_amd64.whl.metadata\n",
      "  Downloading scikit_learn-1.3.0-cp39-cp39-win_amd64.whl.metadata (11 kB)\n",
      "Collecting sseclient-py (from farm-haystack[inference])\n",
      "  Downloading sseclient_py-1.7.2-py2.py3-none-any.whl (8.4 kB)\n",
      "Requirement already satisfied: tenacity in c:\\users\\steve\\anaconda3\\lib\\site-packages (from farm-haystack[inference]) (8.0.1)\n",
      "Collecting tiktoken>=0.3.2 (from farm-haystack[inference])\n",
      "  Downloading tiktoken-0.4.0-cp39-cp39-win_amd64.whl (635 kB)\n",
      "     -------------------------------------- 635.6/635.6 kB 8.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: tqdm in c:\\users\\steve\\anaconda3\\lib\\site-packages (from farm-haystack[inference]) (4.64.0)\n",
      "Requirement already satisfied: transformers==4.31.0 in c:\\users\\steve\\anaconda3\\lib\\site-packages (from farm-haystack[inference]) (4.31.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.5.0 in c:\\users\\steve\\anaconda3\\lib\\site-packages (from farm-haystack[inference]) (0.16.4)\n",
      "Requirement already satisfied: sentence-transformers>=2.2.0 in c:\\users\\steve\\anaconda3\\lib\\site-packages (from farm-haystack[inference]) (2.2.2)\n",
      "Requirement already satisfied: pyyaml<7.0,>=6.0 in c:\\users\\steve\\anaconda3\\lib\\site-packages (from prompthub-py==4.0.0->farm-haystack[inference]) (6.0)\n",
      "Collecting requests (from farm-haystack[inference])\n",
      "  Obtaining dependency information for requests from https://files.pythonhosted.org/packages/70/8e/0e2d847013cb52cd35b38c009bb167a1a26b2ce6cd6965bf26b47bc0bf44/requests-2.31.0-py3-none-any.whl.metadata\n",
      "  Downloading requests-2.31.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\steve\\anaconda3\\lib\\site-packages (from transformers==4.31.0->farm-haystack[inference]) (3.6.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\steve\\anaconda3\\lib\\site-packages (from transformers==4.31.0->farm-haystack[inference]) (1.22.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\steve\\anaconda3\\lib\\site-packages (from transformers==4.31.0->farm-haystack[inference]) (21.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\steve\\anaconda3\\lib\\site-packages (from transformers==4.31.0->farm-haystack[inference]) (2022.3.15)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\users\\steve\\anaconda3\\lib\\site-packages (from transformers==4.31.0->farm-haystack[inference]) (0.13.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\steve\\anaconda3\\lib\\site-packages (from transformers==4.31.0->farm-haystack[inference]) (0.3.2)\n",
      "Requirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in c:\\users\\steve\\anaconda3\\lib\\site-packages (from transformers==4.31.0->farm-haystack[inference]) (0.1.99)\n",
      "Requirement already satisfied: protobuf in c:\\users\\steve\\anaconda3\\lib\\site-packages (from transformers==4.31.0->farm-haystack[inference]) (4.21.0)\n",
      "Requirement already satisfied: torch!=1.12.0,>=1.9 in c:\\users\\steve\\anaconda3\\lib\\site-packages (from transformers==4.31.0->farm-haystack[inference]) (2.0.1)\n",
      "Collecting accelerate>=0.20.3 (from transformers==4.31.0->farm-haystack[inference])\n",
      "  Obtaining dependency information for accelerate>=0.20.3 from https://files.pythonhosted.org/packages/4d/a7/05c67003d659a0035f2b3a8cf389c1d9645865aee84a73ce99ddab16682f/accelerate-0.22.0-py3-none-any.whl.metadata\n",
      "  Downloading accelerate-0.22.0-py3-none-any.whl.metadata (17 kB)\n",
      "Requirement already satisfied: fsspec in c:\\users\\steve\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.5.0->farm-haystack[inference]) (2022.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\steve\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.5.0->farm-haystack[inference]) (4.7.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\steve\\anaconda3\\lib\\site-packages (from requests->farm-haystack[inference]) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\steve\\anaconda3\\lib\\site-packages (from requests->farm-haystack[inference]) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\steve\\anaconda3\\lib\\site-packages (from requests->farm-haystack[inference]) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\steve\\anaconda3\\lib\\site-packages (from requests->farm-haystack[inference]) (2021.10.8)\n",
      "Requirement already satisfied: appdirs>=1.4.4 in c:\\users\\steve\\anaconda3\\lib\\site-packages (from requests-cache<1.0.0->farm-haystack[inference]) (1.4.4)\n",
      "Requirement already satisfied: attrs>=21.2 in c:\\users\\steve\\anaconda3\\lib\\site-packages (from requests-cache<1.0.0->farm-haystack[inference]) (21.4.0)\n",
      "Collecting cattrs>=22.2 (from requests-cache<1.0.0->farm-haystack[inference])\n",
      "  Obtaining dependency information for cattrs>=22.2 from https://files.pythonhosted.org/packages/3a/ba/05df14efaa0624fac6b1510e87f5ce446208d2f6ce50270a89b6268aebfe/cattrs-23.1.2-py3-none-any.whl.metadata\n",
      "  Downloading cattrs-23.1.2-py3-none-any.whl.metadata (9.3 kB)\n",
      "Collecting url-normalize>=1.4 (from requests-cache<1.0.0->farm-haystack[inference])\n",
      "  Downloading url_normalize-1.4.3-py2.py3-none-any.whl (6.8 kB)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\steve\\anaconda3\\lib\\site-packages (from scikit-learn>=1.3.0->farm-haystack[inference]) (1.7.3)\n",
      "Collecting joblib>=1.1.1 (from scikit-learn>=1.3.0->farm-haystack[inference])\n",
      "  Obtaining dependency information for joblib>=1.1.1 from https://files.pythonhosted.org/packages/10/40/d551139c85db202f1f384ba8bcf96aca2f329440a844f924c8a0040b6d02/joblib-1.3.2-py3-none-any.whl.metadata\n",
      "  Downloading joblib-1.3.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\steve\\anaconda3\\lib\\site-packages (from scikit-learn>=1.3.0->farm-haystack[inference]) (2.2.0)\n",
      "Requirement already satisfied: torchvision in c:\\users\\steve\\anaconda3\\lib\\site-packages (from sentence-transformers>=2.2.0->farm-haystack[inference]) (0.15.2)\n",
      "Requirement already satisfied: nltk in c:\\users\\steve\\anaconda3\\lib\\site-packages (from sentence-transformers>=2.2.0->farm-haystack[inference]) (3.7)\n",
      "Requirement already satisfied: colorama in c:\\users\\steve\\anaconda3\\lib\\site-packages (from tqdm->farm-haystack[inference]) (0.4.6)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in c:\\users\\steve\\anaconda3\\lib\\site-packages (from jsonschema->farm-haystack[inference]) (0.18.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\steve\\anaconda3\\lib\\site-packages (from pandas->farm-haystack[inference]) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\steve\\anaconda3\\lib\\site-packages (from pandas->farm-haystack[inference]) (2021.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\steve\\anaconda3\\lib\\site-packages (from posthog->farm-haystack[inference]) (1.16.0)\n",
      "Collecting monotonic>=1.5 (from posthog->farm-haystack[inference])\n",
      "  Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
      "Collecting backoff>=1.10.0 (from posthog->farm-haystack[inference])\n",
      "  Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Collecting inflect (from quantulum3->farm-haystack[inference])\n",
      "  Obtaining dependency information for inflect from https://files.pythonhosted.org/packages/fb/c6/d9feb758be584f729424390af24687d3a4363d968164f94079f83cd536b4/inflect-7.0.0-py3-none-any.whl.metadata\n",
      "  Downloading inflect-7.0.0-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting num2words (from quantulum3->farm-haystack[inference])\n",
      "  Downloading num2words-0.5.12-py3-none-any.whl (125 kB)\n",
      "     ---------------------------------------- 125.2/125.2 kB ? eta 0:00:00\n",
      "Requirement already satisfied: psutil in c:\\users\\steve\\anaconda3\\lib\\site-packages (from accelerate>=0.20.3->transformers==4.31.0->farm-haystack[inference]) (5.8.0)\n",
      "Collecting exceptiongroup (from cattrs>=22.2->requests-cache<1.0.0->farm-haystack[inference])\n",
      "  Obtaining dependency information for exceptiongroup from https://files.pythonhosted.org/packages/ad/83/b71e58666f156a39fb29417e4c8ca4bc7400c0dd4ed9e8842ab54dc8c344/exceptiongroup-1.1.3-py3-none-any.whl.metadata\n",
      "  Downloading exceptiongroup-1.1.3-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\steve\\anaconda3\\lib\\site-packages (from packaging>=20.0->transformers==4.31.0->farm-haystack[inference]) (3.0.4)\n",
      "Requirement already satisfied: sympy in c:\\users\\steve\\anaconda3\\lib\\site-packages (from torch!=1.12.0,>=1.9->transformers==4.31.0->farm-haystack[inference]) (1.10.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\steve\\anaconda3\\lib\\site-packages (from torch!=1.12.0,>=1.9->transformers==4.31.0->farm-haystack[inference]) (2.11.3)\n",
      "Requirement already satisfied: click in c:\\users\\steve\\anaconda3\\lib\\site-packages (from nltk->sentence-transformers>=2.2.0->farm-haystack[inference]) (8.0.4)\n",
      "Collecting docopt>=0.6.2 (from num2words->quantulum3->farm-haystack[inference])\n",
      "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\steve\\anaconda3\\lib\\site-packages (from jinja2->torch!=1.12.0,>=1.9->transformers==4.31.0->farm-haystack[inference]) (2.0.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\steve\\anaconda3\\lib\\site-packages (from sympy->torch!=1.12.0,>=1.9->transformers==4.31.0->farm-haystack[inference]) (1.2.1)\n",
      "Downloading canals-0.3.2-py3-none-any.whl (34 kB)\n",
      "Downloading prompthub_py-4.0.0-py3-none-any.whl (6.9 kB)\n",
      "Downloading requests-2.31.0-py3-none-any.whl (62 kB)\n",
      "   ---------------------------------------- 62.6/62.6 kB 3.3 MB/s eta 0:00:00\n",
      "Downloading scikit_learn-1.3.0-cp39-cp39-win_amd64.whl (9.3 MB)\n",
      "   ---------------------------------------- 9.3/9.3 MB 35.0 MB/s eta 0:00:00\n",
      "Downloading Events-0.5-py3-none-any.whl (6.8 kB)\n",
      "Downloading farm_haystack-1.19.0-py3-none-any.whl (764 kB)\n",
      "   --------------------------------------- 764.0/764.0 kB 24.3 MB/s eta 0:00:00\n",
      "Downloading more_itertools-10.1.0-py3-none-any.whl (55 kB)\n",
      "   ---------------------------------------- 55.8/55.8 kB ? eta 0:00:00\n",
      "Downloading platformdirs-3.10.0-py3-none-any.whl (17 kB)\n",
      "Downloading posthog-3.0.2-py2.py3-none-any.whl (37 kB)\n",
      "Downloading accelerate-0.22.0-py3-none-any.whl (251 kB)\n",
      "   --------------------------------------- 251.2/251.2 kB 15.1 MB/s eta 0:00:00\n",
      "Downloading cattrs-23.1.2-py3-none-any.whl (50 kB)\n",
      "   ---------------------------------------- 50.8/50.8 kB 2.5 MB/s eta 0:00:00\n",
      "Downloading joblib-1.3.2-py3-none-any.whl (302 kB)\n",
      "   ---------------------------------------- 302.2/302.2 kB ? eta 0:00:00\n",
      "Downloading inflect-7.0.0-py3-none-any.whl (34 kB)\n",
      "Downloading exceptiongroup-1.1.3-py3-none-any.whl (14 kB)\n",
      "Building wheels for collected packages: docopt\n",
      "  Building wheel for docopt (setup.py): started\n",
      "  Building wheel for docopt (setup.py): finished with status 'done'\n",
      "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13772 sha256=e7591dff937a2a44bcd8e82296981b7447835be4674b3f66afcadeea0b727fb9\n",
      "  Stored in directory: c:\\users\\steve\\appdata\\local\\pip\\cache\\wheels\\70\\4a\\46\\1309fc853b8d395e60bafaf1b6df7845bdd82c95fd59dd8d2b\n",
      "Successfully built docopt\n",
      "Installing collected packages: sseclient-py, monotonic, events, docopt, url-normalize, requests, rank-bm25, platformdirs, num2words, more-itertools, lazy-imports, joblib, exceptiongroup, canals, boilerpy3, backoff, tiktoken, scikit-learn, prompthub-py, posthog, inflect, cattrs, requests-cache, quantulum3, accelerate, farm-haystack\n",
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.27.1\n",
      "    Uninstalling requests-2.27.1:\n",
      "      Successfully uninstalled requests-2.27.1\n",
      "  Attempting uninstall: joblib\n",
      "    Found existing installation: joblib 1.1.0\n",
      "    Uninstalling joblib-1.1.0:\n",
      "      Successfully uninstalled joblib-1.1.0\n",
      "  Attempting uninstall: scikit-learn\n",
      "    Found existing installation: scikit-learn 1.0.2\n",
      "    Uninstalling scikit-learn-1.0.2:\n",
      "      Successfully uninstalled scikit-learn-1.0.2\n",
      "Successfully installed accelerate-0.22.0 backoff-2.2.1 boilerpy3-1.0.6 canals-0.3.2 cattrs-23.1.2 docopt-0.6.2 events-0.5 exceptiongroup-1.1.3 farm-haystack-1.19.0 inflect-7.0.0 joblib-1.3.2 lazy-imports-0.3.1 monotonic-1.6 more-itertools-10.1.0 num2words-0.5.12 platformdirs-3.10.0 posthog-3.0.2 prompthub-py-4.0.0 quantulum3-0.9.0 rank-bm25-0.2.2 requests-2.31.0 requests-cache-0.9.8 scikit-learn-1.3.0 sseclient-py-1.7.2 tiktoken-0.4.0 url-normalize-1.4.3\n"
     ]
    }
   ],
   "source": [
    "#!pip install farm-haystack[inference]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6e97ea5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 0.28468453884124756,\n",
       " 'start': 3244,\n",
       " 'end': 3257,\n",
       " 'answer': '6,0008,000'}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#from haystack.reader.farm import FARMReader\n",
    "\n",
    "#reader = TransformersReader(model_name_or_path=\"deepset/roberta-base-squad2\",tokenizer=\"deepset/roberta-base-squad2\")\n",
    "\n",
    "model_name = \"deepset/roberta-base-squad2\"\n",
    "\n",
    "# a) Get predictions\n",
    "nlp = pipeline('question-answering', model=model_name, tokenizer=model_name)\n",
    "QA_input = {\n",
    "    'question': 'How many species of fish live in coral reefs?',\n",
    "    'context': raw\n",
    "}\n",
    "res = nlp(QA_input)\n",
    "\n",
    "# b) Load model & tokenizer\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c25da7cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 0.612525463104248,\n",
       " 'start': 24899,\n",
       " 'end': 24913,\n",
       " 'answer': 'reef stonefish'}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a) Get predictions\n",
    "QA_input = {\n",
    "    'question': 'What is the most venomous fish?',\n",
    "    'context': raw\n",
    "}\n",
    "res = nlp(QA_input)\n",
    "\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "94d6abce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 0.1773730218410492,\n",
       " 'start': 28108,\n",
       " 'end': 28128,\n",
       " 'answer': 'caribbean reef shark'}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a) Get predictions\n",
    "QA_input = {\n",
    "    'question': 'What sharks live in coral reefs?',\n",
    "    'context': raw\n",
    "}\n",
    "res = nlp(QA_input)\n",
    "\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1a6e687b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 0.5669053196907043,\n",
       " 'start': 23682,\n",
       " 'end': 23696,\n",
       " 'answer': 'many reef fish'}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a) Get predictions\n",
    "QA_input = {\n",
    "    'question': 'What fish are poisonous?',\n",
    "    'context': raw\n",
    "}\n",
    "res = nlp(QA_input)\n",
    "\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3fc5ed56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 0.010173969902098179,\n",
       " 'start': 9045,\n",
       " 'end': 9062,\n",
       " 'answer': 'clown triggerfish'}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a) Get predictions\n",
    "QA_input = {\n",
    "    'question': 'What fish can electrocute you?',\n",
    "    'context': raw\n",
    "}\n",
    "res = nlp(QA_input)\n",
    "\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4a5def93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 0.5866654515266418,\n",
       " 'start': 27273,\n",
       " 'end': 27286,\n",
       " 'answer': 'the stargazer'}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a) Get predictions\n",
    "QA_input = {\n",
    "    'question': 'What species can sting you?',\n",
    "    'context': raw\n",
    "}\n",
    "res = nlp(QA_input)\n",
    "\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e2b2ca70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 0.06776570528745651,\n",
       " 'start': 17341,\n",
       " 'end': 17353,\n",
       " 'answer': 'damselfishes'}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a) Get predictions\n",
    "QA_input = {\n",
    "    'question': 'What species are parasitic?',\n",
    "    'context': raw\n",
    "}\n",
    "res = nlp(QA_input)\n",
    "\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9b7e7b92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 0.3828498125076294,\n",
       " 'start': 27273,\n",
       " 'end': 27286,\n",
       " 'answer': 'the stargazer'}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a) Get predictions\n",
    "QA_input = {\n",
    "    'question': 'What species are venomous?',\n",
    "    'context': raw\n",
    "}\n",
    "res = nlp(QA_input)\n",
    "\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "23642dae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 0.005669948644936085,\n",
       " 'start': 26369,\n",
       " 'end': 26377,\n",
       " 'answer': 'lionfish'}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a) Get predictions\n",
    "QA_input = {\n",
    "    'question': 'What species are known for attacking scuba divers?',\n",
    "    'context': raw\n",
    "}\n",
    "res = nlp(QA_input)\n",
    "\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "743c4f74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 0.33974504470825195,\n",
       " 'start': 2116,\n",
       " 'end': 2127,\n",
       " 'answer': 'yellow tang'}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a) Get predictions\n",
    "QA_input = {\n",
    "    'question': 'What are common herbivorous fish?',\n",
    "    'context': raw\n",
    "}\n",
    "res = nlp(QA_input)\n",
    "\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b8894df3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 0.33112961053848267,\n",
       " 'start': 8282,\n",
       " 'end': 8309,\n",
       " 'answer': 'lets them ambush their prey'}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a) Get predictions\n",
    "QA_input = {\n",
    "    'question': 'Why do fish camouflage themselves?',\n",
    "    'context': raw\n",
    "}\n",
    "res = nlp(QA_input)\n",
    "\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "09519ca3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 0.2778742015361786,\n",
       " 'start': 16126,\n",
       " 'end': 16153,\n",
       " 'answer': 'establish cleaning stations'}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a) Get predictions\n",
    "QA_input = {\n",
    "    'question': 'How do fish get rid of their parasites?',\n",
    "    'context': raw\n",
    "}\n",
    "res = nlp(QA_input)\n",
    "\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "dfc80300",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 0.19288134574890137,\n",
       " 'start': 21835,\n",
       " 'end': 21861,\n",
       " 'answer': 'sea anemones and clownfish'}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a) Get predictions\n",
    "QA_input = {\n",
    "    'question': 'What species have mutualistic relationships?',\n",
    "    'context': raw\n",
    "}\n",
    "res = nlp(QA_input)\n",
    "\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "38e1954a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 0.1290857344865799,\n",
       " 'start': 0,\n",
       " 'end': 15,\n",
       " 'answer': 'coral reef fish'}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a) Get predictions\n",
    "QA_input = {\n",
    "    'question': 'What species have commensalistic relationships?',\n",
    "    'context': raw\n",
    "}\n",
    "res = nlp(QA_input)\n",
    "\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e6a76a0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 0.11980749666690826,\n",
       " 'start': 28031,\n",
       " 'end': 28043,\n",
       " 'answer': 'indo-pacific'}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a) Get predictions\n",
    "QA_input = {\n",
    "    'question': 'Where in the world are coral reefs found?',\n",
    "    'context': raw\n",
    "}\n",
    "res = nlp(QA_input)\n",
    "\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "4e869ee8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 0.235614612698555,\n",
       " 'start': 27273,\n",
       " 'end': 27286,\n",
       " 'answer': 'the stargazer'}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a) Get predictions\n",
    "QA_input = {\n",
    "    'question': 'What species engage in schooling?',\n",
    "    'context': raw\n",
    "}\n",
    "res = nlp(QA_input)\n",
    "\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "bd44b9c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 0.5129007697105408,\n",
       " 'start': 24899,\n",
       " 'end': 24913,\n",
       " 'answer': 'reef stonefish'}"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a) Get predictions\n",
    "QA_input = {\n",
    "    'question': 'What species are ambush predators?',\n",
    "    'context': raw\n",
    "}\n",
    "res = nlp(QA_input)\n",
    "\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "ff92c14c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 0.09240982681512833,\n",
       " 'start': 81,\n",
       " 'end': 145,\n",
       " 'answer': 'coral reefs form complex ecosystems with tremendous biodiversity'}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a) Get predictions\n",
    "QA_input = {\n",
    "    'question': 'Why are some coral reef fish colorful?',\n",
    "    'context': raw\n",
    "}\n",
    "res = nlp(QA_input)\n",
    "\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "daf2bd50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 0.4031549096107483,\n",
       " 'start': 12029,\n",
       " 'end': 12047,\n",
       " 'answer': 'bluestripe snapper'}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a) Get predictions\n",
    "QA_input = {\n",
    "    'question': 'Which species is blue?',\n",
    "    'context': raw\n",
    "}\n",
    "res = nlp(QA_input)\n",
    "\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "0d24578f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 0.6155030727386475,\n",
       " 'start': 4939,\n",
       " 'end': 4953,\n",
       " 'answer': 'dwarf seahorse'}"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a) Get predictions\n",
    "QA_input = {\n",
    "    'question': 'What is the slowest species that lives in coral reefs?',\n",
    "    'context': raw\n",
    "}\n",
    "res = nlp(QA_input)\n",
    "\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "c694b91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in range(20):\n",
    "    chatbot_models.append(5)\n",
    "\n",
    "model_5_performance_list = [\"Correct\",\n",
    "                           \"Correct\",\n",
    "                           \"Correct\",\n",
    "                           \"Partially Correct\",\n",
    "                           \"Incorrect\",\n",
    "                           \"Partially Correct\",\n",
    "                           \"Partially Correct\",\n",
    "                           \"Correct\",\n",
    "                           \"Correct\",\n",
    "                           \"Correct\",\n",
    "                           \"Correct\",\n",
    "                           \"Correct\",\n",
    "                           \"Correct\",\n",
    "                           \"Incorrect\",\n",
    "                           \"Correct\",\n",
    "                           \"Incorrect\",\n",
    "                           \"Correct\",\n",
    "                           \"Incorrect\",\n",
    "                           \"Partially Correct\",\n",
    "                           \"Correct\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81376376",
   "metadata": {},
   "source": [
    "## 5) Evaluation of Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "1ef6a379",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "chatbot_performance_df = pd.DataFrame({'Correct': [100 * model_1_performance_list.count(\"Correct\")/len(model_1_performance_list),\n",
    "                               100 * model_2_performance_list.count(\"Correct\")/len(model_2_performance_list),\n",
    "                               100 * model_3_performance_list.count(\"Correct\")/len(model_3_performance_list),\n",
    "                               100 * model_4_performance_list.count(\"Correct\")/len(model_4_performance_list),\n",
    "                               100 * model_5_performance_list.count(\"Correct\")/len(model_5_performance_list)],\n",
    "                    'Partially Correct': [100 * model_1_performance_list.count(\"Partially Correct\")/len(model_1_performance_list),\n",
    "                               100 * model_2_performance_list.count(\"Partially Correct\")/len(model_2_performance_list),\n",
    "                               100 * model_3_performance_list.count(\"Partially Correct\")/len(model_3_performance_list),\n",
    "                               100 * model_4_performance_list.count(\"Partially Correct\")/len(model_4_performance_list),\n",
    "                               100 * model_5_performance_list.count(\"Partially Correct\")/len(model_5_performance_list)],\n",
    "                   'Incorrect': [100 * model_1_performance_list.count(\"Incorrect\")/len(model_1_performance_list),\n",
    "                               100 * model_2_performance_list.count(\"Incorrect\")/len(model_2_performance_list),\n",
    "                               100 * model_3_performance_list.count(\"Incorrect\")/len(model_3_performance_list),\n",
    "                               100 * model_4_performance_list.count(\"Incorrect\")/len(model_4_performance_list),\n",
    "                               100 * model_5_performance_list.count(\"Incorrect\")/len(model_5_performance_list)]},\n",
    "                  index=['1', '2', '3', '4', '5'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "cdb0a268",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Correct</th>\n",
       "      <th>Partially Correct</th>\n",
       "      <th>Incorrect</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>60.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Correct  Partially Correct  Incorrect\n",
       "1     35.0                5.0       60.0\n",
       "2      0.0               20.0       80.0\n",
       "3     40.0               10.0       50.0\n",
       "4     50.0                5.0       45.0\n",
       "5     60.0               20.0       20.0"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatbot_performance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "c800bc17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3UAAALYCAYAAADb+9ukAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAACioklEQVR4nOzddXgU1//28XvjBAkEghRpgyQU10JxgkugSItDKVD0i9PSFgqFYsW9eIuV4u7uVrTF3SVICBBCZJ8/+mTLNrswgSwhv75f18V1kZnZmXt3z8pnZ845JrPZbBYAAAAAIEFyiu8AAAAAAIDXR1EHAAAAAAkYRR0AAAAAJGAUdQAAAACQgFHUAQAAAEACRlEHAAAAAAkYRd0rbNq0Sa1bt9bHH3+sXLlyqUSJEmrbtq02bdpkc/s7d+5o0aJFDs/VpEkT+fv769GjRw4/1qNHj+Tv768mTZoYzvXiv+zZs6tIkSJq2rSp1q1b5/C8RvTs2VP+/v46efLka+9j5cqVunr1qqFtw8PDNXPmTNWrV0+FChVSnjx5VK5cOX3zzTc6derUa2f4v2bfvn3y9/fXgAEDYn3bgIAAFSpUyAGpjBk7dmyMtu/v76+cOXOqSJEiatKkiZYtW+aw42/btk2BgYHKnTu3ihQpor179zrsWP91N2/e1ODBg1W9enXlz59fhQsXVq1atTR27FjdvXvX5m0iIiI0ZMgQFS9eXLlz51ZgYKChY+3fv1/dunVThQoVlDt3bhUuXFhNmzbV8uXL9S7MSBTd7jdu3PjS7a5du2bz9RH9GilatKiaNGmipUuXvp3g/9/ixYtVsWJF5cqVS8WKFdOlS5dsbhf93vSqf7/88ovV9q/zXhaXn+/h4eFasWKFWrRoodKlS1u+x3Tq1EmHDh2Ksb3R5/N1hIWFafr06VbLHPld5m19HwPeFS7xHeBd1r9/f82ePVvp06dXuXLllCJFCt2+fVvbtm3T5s2b9dlnn6l///6W7e/du6fKlSuraNGiqlOnTjwmj39NmzZVsmTJJP39ofLgwQNt27ZNHTt21LfffqtmzZrFc8I3M3ToUE2dOtXQF5CnT5/q888/19GjR5U3b17VqFFDHh4eunz5spYvX65ly5ZpwIABqlWrluODv+PSp0+vDh06KG/evLG+bdOmTfX8+XMHpIqdcuXK6cMPP7T8HRERofv372vNmjX66quvdOHCBXXp0iVOjxkcHKxOnTopMjJStWvXVuLEiZUlS5Y4PQb+tnLlSn333Xd69uyZChUqpJIlSyo8PFx//vmnxo0bp19++UVDhw5VQECA1e0WLlyo6dOny9fXV7Vq1VLKlClfepznz5+rX79+WrBggRInTqzSpUurYsWKun//vjZv3qwePXpo69atGjZsmJycEs7vs+nTp4/xXhcWFqbz589r69at2r9/v+7cuaMvv/zS4VnOnz+v7777TkmSJFHDhg3l5OSk995776W3yZ49u8qXL293fb58+SS92XtZXLl165Y6deqkI0eOKH369CpWrJi8vb115coVbdq0SevWrVPv3r3VqFGjt5KncePGunjxor744guHH4vvY/gvoqizY9++fZo9e7YqVaqkESNGyMXln4cqJCRETZs21fz581W6dGnLG3xoaKiePHkSX5HfKc2aNVOGDBmslj169EiBgYEaNWqU6tSpoyRJksRTujd37949w9tOmzZNR48e1TfffKPPP//cat3Zs2dVv3599enTRyVLllSqVKniOGnCkiFDBv3vf/97rdv++7GNL+XLl1ft2rVjLG/RooVq1aqlKVOm6LPPPlP69Onj7JgXLlxQaGioAgMD9cMPP8TZfmFty5Yt6t69u1KnTq0ZM2aoQIECVuv37NmjTp06qV27dpo2bZqKFy9uWXfixAlJ0vfff69ixYq98lg//PCDFi5cqICAAA0aNEjJkye3rHv8+LHat2+vVatWKV26dOrRo0fc3MG3IH369HZf47t379YXX3yhCRMmqH79+pYfBh3l5MmTioqKUsOGDQ3/0PLhhx8aeo96k/eyuBAWFqaWLVvq7Nmz+t///qfWrVvL1dXVsv7ixYtq2rSp+vfvrwwZMqh06dIOzxSbz803xfcx/BclnJ/33rKtW7dKkho1amRV0ElS0qRJ1a1bN0nShg0b3na0BCtZsmSqUKGCnj59qj///DO+47w1W7ZskYuLi81fQ7Nly6ZGjRopLCxM27Zti4d0eFs++OADlStXTpGRkdq5c2ec7jv6DGWKFCnidL/4R1hYmHr16iVXV1dNmTIlRkEnSR9//LEmTJggs9msXr16KSwszLIuNs/R3r17tXDhQmXLlk2jR4+2KugkKUmSJBo9erQ8PT01Z84cPXjw4M3u3DuiWLFiKlSokEJDQ3X48GGHH+//8utm0qRJOnv2rD777DN16NDBqqCTJF9fXw0aNEhms1njx4+Pp5QA4hJFnR3h4eGSpDNnzthcX6hQIY0aNcpydmDx4sUqV66cpL/74fn7+2vx4sWW7bds2aKWLVuqaNGilv4D7dq1s9mn69q1a/ruu+9UqlQp5c2bV9WqVdP06dMtmezZtWuXcuXKpTJlyujatWuW5Y8fP9awYcNUvnx55cqVSyVLllSfPn1s/mp27do1de/eXcWKFVP+/PnVoUMH3bhx4+UPViw4OztLktzc3KyW379/X0OGDFGVKlWUN29ey/3++eefFRERYdlu8eLF8vf315o1a9SiRQvlzp1bZcuW1dWrVy395O7du6cePXqoUKFC+uijj9SuXTudPXvWUL5du3apefPmKlCggPLkyaNatWppzpw5ioqKsmwTEBCgJUuWSJI++eSTGJdZ/VtERIQiIiJ04cIFm+s/++wzjR8/Xh9//LFlmb1+BtH9Utq1a2dZFt0H4tKlS/rpp59UokQJ5c2bV/Xr19fx48cVFRWlKVOmKCAgQPny5VPdunW1b98+q/02adJEFSpU0PXr19WpUycVKlRIhQoVUseOHXX//n09evRIvXv3VpEiRfTRRx+pTZs2Vm0s2tKlS9WkSRMVLlzY0nejW7duMfoe+vv7q2fPnvr5558tx/rll19i9EOJfr5f9i86x7/71EXfds+ePZo2bZoqVqyo3Llzq3z58po4caIiIyNjPE+TJk1SpUqVlCdPHlWtWlULFy7UhAkTrI7zJtKkSSNJevjwodXyNWvWqH79+sqfP78KFCigZs2axegTF/3YzJ07V127dlWePHlUokQJ5cyZU02bNpUkzZw50/LYRjt27JjatWunIkWKKHfu3Kpatap+/vnnGJeqBgQEqEmTJlq0aJHl9T948GBLm5swYYLWr1+vWrVqKU+ePAoICNCMGTMkSX/88YcaNmyofPnyKSAgQGPHjrV63UrGX+PR93Px4sVauHChpZ9gqVKlNGTIEIWGhsZ4XDdu3KgmTZqoUKFCKlKkiD7//HMdOHAgxnZ79uxR8+bNVbBgQeXLl0/16tXT2rVrX/W0SZJWrVqloKAgValSRf7+/na3K1SokMqWLasbN25o69atlsfvxfcMf3//GK/BFy1cuFCS1LJlyxjvldGSJ0+uvn37asCAAVZf2KOiojR37lx98sknypMnjwoWLKjmzZtr165dVre3157++OMPSdL169fVp08flS9fXrlz51b+/PlVu3Zt/fbbb4Yer9fl7e0tSTE+7y5fvmz5bMqVK5eqVKmiSZMm2fxcvHv3rvr27atSpUopV65cCggI0NChQ/X48WPLNgEBAfrmm28kSYMGDZK/v7/Gjh0bZ/fDVp+6J0+eaODAgapcubJy586tjz/+WB06dNBff/1lcx+3b9/WV199pSJFiihfvnxq0KCB9uzZ88pjm81my/ePNm3a2N0u+v25Q4cOMfpnhoWFadSoUQoICFDu3LlVpUoVzZ07N8Y+njx5ovHjx6tmzZrKnz+/cufOrYoVK+qnn37S06dPJf3zuXX9+nWFhITEeI+SpBs3bqh9+/bKnz+/ihQpYvNzQ/r7SqmffvrJ8n2mWLFi6tatmy5evGjZ5mXfx4KCgvTtt99a+qiWKFFCPXr00OXLl1/5uALvOi6/tKN48eKaNWuWhgwZokuXLql69erKkyePpSjx8PBQlSpVLNt/+OGHatq0qWbOnClfX19Vq1bN0q9m9uzZ6t+/vzJlyqTq1avL1dVVx48f16ZNm7R3716tXbtWqVOnlvR3EdmkSRMFBwerTJky8vX11f79+zVkyBCdPn1aQ4YMsZn3yJEj6tChg1KkSKFff/3VculjSEiIGjZsqDNnzujjjz9WxYoVde3aNc2fP187duzQvHnzLMe+deuW6tevr6CgIAUEBOi9997Tjh071LJlyzh5TENCQrRhwwalS5dOefLksVr+2Wef6ebNmwoICFD58uV1//59bdiwQSNHjlRwcLC+/vprq339+OOPSp06tZo0aaJr164pY8aMlnWtWrXS3bt3VadOHd26dUsbNmzQ/v37NXv2bGXPnt1uvlmzZunHH39U0qRJVaFCBXl6emrHjh3q16+fDh48qBEjRshkMqlp06ZasmSJTp06pXr16ilz5swvvd/FixfX6dOn1bx5czVt2lQVK1a0uk2GDBliXKr6Ojp37qzg4GBVq1ZNN2/e1Lp169SyZUsFBARo69atqlSpksLCwrR8+XK1adNGa9eutRQZ0t/Ff4MGDZQ2bVp99tln+uOPP7Ru3To9ePBAT58+VVhYmGrVqqWzZ89qy5Ytlk7oJpNJkjRkyBBNnz5d2bNnV61atWQymXTgwAGtXLlSf/zxh9auXSsPDw/L8Xbs2KENGzaoVq1aCgoKUt68eWMUGh9++KE6dOgQ476ePXtW69atU6ZMmV7ZN2no0KG6ePGiKleurGTJkmnVqlUaNWqUzGazVXHcuXNnbdiwQf7+/mrYsKGuXLmi7777zqptvakrV65IktXjPnr0aE2YMMHS18hkMmnt2rVq3ry5Bg8erJo1a1rtY/z48fL09FTjxo117tw5lS5dWsePH9eSJUuUN29elSxZ0vLes3HjRnXq1ElOTk4qX768UqVKpb1792rkyJHasWOHZsyYYVU0nD17Vv369VPNmjUVHh5u6R8kSevXr9eECRNUuXJlFSpUSMuXL9fgwYN1/fp1/f777ypVqpQaNGigtWvXaty4cUqWLJml7+zrvMZnz56tM2fOqGLFiipZsqQ2bNig6dOn69GjR1ZflCdNmqQRI0YoZcqUqlSpktzd3bVy5Up9/vnnmjRpkkqUKCFJWrBggXr37i1vb29VrVpVnp6e2rRpkzp16qQuXbq89Muv9PelgZJUqlSpVz7PFStW1JYtW7Rx40bLF/eNGzda3jN8fHxeevntjh07JMmS3Z5/t42oqCh16dJFa9euVcaMGVWnTh09ffpUmzZtUosWLWz2n/p3e8qRI4euXbumunXrKjQ0VBUqVFC6dOl0+/ZtrVu3Tn379lVkZKQaN278yschtkJDQ3Xw4EFJsiqc//rrLzVr1kzPnj1TxYoV9d5771nekw8cOKBJkyZZPptv3LihBg0a6Pbt2ypbtqyyZMmikydPaurUqdq9e7fmzJkjT09PNW3aVPv379emTZtUokQJ5cuXTx999FGc36cXde7cWdu3b1fZsmVVvnx5BQUFafXq1dq5c6cWL14c47OkWbNmSp48uWrXrq07d+5YfsxcsGCBcubMafc4Z86c0c2bN5U5c+ZXXuZtr+/igAEDFBUVpcqVK8vJyUkrV67UDz/8oIiICMuPSBEREWrevLmOHTumEiVKqESJEnry5Ik2b96sadOm6dq1axozZoySJUumDh066Ndff1VYWJi+/PJLq37H0t8/YCRJkkT169fXxYsXtXLlSu3Zs0cLFy609HN88OCBGjRooIsXLypfvnwqV66crl69qtWrV2vr1q2aPn268ubNa/f7WFhYmFq1aqUzZ86oQoUKqly5sq5cuaJVq1Zp586dWrNmTYyz4kCCYoZdffr0Mfv5+Vn+FShQwNyqVSvzjBkzzDdv3oyx/dWrV81+fn7mtm3bWpaFhYWZCxQoYK5YsaL5yZMnNvc/b948y7KGDRua/f39zevWrbMsi4qKMn/xxRdmPz8/859//mk2m83mxo0bm/38/MzBwcHmU6dOmQsXLmwuVqyY+dy5c1bH6Nu3r9nPz888e/Zsq+UbN240+/n5mTt27GhZ9tVXX5n9/PzMixcvtix78uSJ5ViNGzd+5WMWve2PP/5oHjNmjHnMmDHmkSNHmvv06WMuWbKkuWjRoubDhw9b3WbSpElmPz8/8/z5862W37hxw5wrVy5z8eLFLcsWLVpk9vPzM5cqVcr89OlTq+2//vprs5+fn7ls2bLme/fuWZavXbs2Rv7obU+cOGE2m83mK1eumHPkyGEuU6aM+cqVK1b3v2nTpmY/Pz/zkiVL7N7+ZUJCQsx169a1akslSpQwd+3a1bx06VLz48eP7T6OwcHBVstttbExY8ZY7veL23ft2tXSbm/dumVZPnbsWLOfn595zpw5MY7Xvn17c1RUlNlsNpvDw8PNZcqUMfv5+Znr1atnDgsLi7F9dHu7deuWOXv27OZGjRqZIyIirDK3atXK7OfnZ96xY4dlWfTjsGnTJqtt9+7da2k/9ty7d89ctmxZc758+cynT5+2LC9btqy5YMGClr+j20rBggXNly5dsnoMc+bMaS5durRlWXQbadeunfn58+eW5bNnz7ZkvXr1qt1MZvM/z8OiRYtsrj927Jg5R44c5jx58lja59GjR83+/v7mxo0bW7Xn+/fvmytUqGDOmzevZdvoxyZv3rzmO3fuWO3b1uMWEhJiLly4sLlAgQKW9w2z+e/ntVu3bmY/Pz/zuHHjrB4/Pz8/88yZM632Hd3m/Pz8zBs2bLAs37Fjh2X5i+8v0dvXrVvXsiw2r/Ho+/Lhhx+aDx06ZFn+6NEjc9GiRc25c+e2vJdeuHDBnCNHDnPlypWtHpNLly6Z8+XLZ65evbrZbDabb968ac6VK5e5SpUq5vv371u2Cw0NNderV8+cPXt2q7ZkS+3ata3eg1/myJEjltdNNKPvGaGhoZbXbWwtWbLE7OfnZ/7iiy+sPm+uXLliLl68uDlHjhyW97eXtafevXub/fz8zLt27bJafvTo0Rj3K7rdv9g2bIluF7Y+R54+fWo+duyY5XOuR48elnVRUVHm6tWrm3Pnzm0+fvy41e0GDhwYo/21atXK7O/vb968ebPVtr/++qvZz8/PPGTIEMuy6PeIGTNmvDS72fzP41WjRg3LZ9u//7343P77NXn69Gmzn5+f+auvvrLa75o1a8x+fn7mwYMHW5ZFv7+2atXK6v1oxowZZj8/P3P//v1fmnXr1q1mPz8/c5s2bV55v/4t+vksXbq0+e7du5blf/31l9nf398cGBhoWbZy5Uqzn5+fecSIEVb7CAkJMRcrVsz84YcfWr2v/fs9+sX7Wq9ePfOzZ88sy3/77Tezn5+fuWvXrpZl33zzjdnPz888cuTIGPfX39/fXLFiRcvnj63Pys2bN5v9/PzMo0ePtrr91KlTbX5PAhIaLr98ib59+2rSpEkqWbKkXF1d9fjxY23btk2DBg1S+fLlNXz4cKvL8myJjIxU//79NWDAAHl6elqti/5VMPoyyFu3bungwYMqVqyYKlasaNnOZDKpa9eu6tChQ4xLca5evaoWLVrIyclJM2bMsBrxLiIiQkuXLrX023pRuXLlVKBAAW3YsEGPHz/W8+fPtX79emXLls1qZDJPT0917949Fo/a32bOnKlx48Zp3Lhxmjhxon777Tfdvn1bXl5eun37ttW2JUqU0A8//KBPPvnEanm6dOmUMWNG3b9/P8b+S5curUSJEtk8dtu2bS2X8EhSpUqVVLBgQe3fv1+3bt2yeZvly5crIiJC7du3tzoz4+npqV69eknSaw+NnCRJEs2dO1fff/+95dfVO3fuaOXKlfrqq69Urlw5rVq16rX2/aLatWtbDSwQ3eenWrVqVmeGos+SXr9+PcY+mjZtajnz5uLioty5c0v6+/LMF9te9Ihu0Zckurm56aefftJ3331n+cU8WuHChSXF7CTv4eER68754eHh6tixo65fv64BAwbIz8/vlbepWLGi3n//fcvfGTJkUJYsWXTz5k1Ln6foS+O+/vprq0vZGjRoIF9f31hl3Lhxo8aOHWv5N3LkSHXs2FGNGjVSRESEvvrqK0v7XLhwocxms7766iur9pwiRQq1atVKoaGhWrNmjdX+CxYsKB8fH0M5goOD1bRpU6tf9V1cXPTtt9/Kw8PDZpuuVKmSzf2lT5/eatS/6Pbl6emp+vXrW5ZnyJBBqVKlsmpfr/MaL1y4sPLnz2/5O2nSpMqfP7/CwsJ08+ZNSdLatWsVERGhdu3aWT0m77//vr7++mvVqVNH4eHhWr58uZ4/f66OHTta9Z/y8PBQx44dFRUVZWkD9kRfumdkgCcvLy9Jeq2+btGXXCdOnDjWt42+D3379rX6vMmYMaPatm1r+Ux4ka32VKNGDQ0YMCDGgC558uSRh4fHGw14sX///hiXUEdfFr53717VrVvXarCfo0eP6syZM6pbt65y5cplta9OnTrJ1dXVcmndnTt3tH37dpUuXVply5a12rZx48ZKly6dVbeI13Hq1CnLZ9u//71sipzo7wrnzp2zuvy6fPny2rhxo83P2S+//NLq/Sj6Uv9XXQoeEhIi6fXaULRPP/3UauCuHDlyKE2aNFaXRObIkUM//vhjjEGqkiRJohw5cigyMlLBwcGGjte1a1e5u7tb/q5fv758fX21fv16PX/+XM+fP9eqVauUPn16dezY0eq20SPDXrp0yXKm15bo5+DEiRN69uyZZXnDhg21detWNWzY0FBW4F3F5ZevUKZMGZUpU0ZPnjzRwYMHtWfPHm3evFmXL1/W5MmTFRUV9dKRxxIlSqSqVatK+nu0qfPnz+vKlSs6e/as5dr46Dea06dPS5LVJU/RcubMafNyizZt2uju3bvKnTu3smbNarXu4sWLevr0qSIjI232FQgLC1NkZKROnz6t5MmT6+nTpzE+NCUpV65cMTpZv8qmTZsslxRGRUUpJCRER48e1cCBA9WxY0cNGjTIMkJgjhw5lCNHDj158kRHjx7V5cuXdenSJR0/flyXL1+O0fdJ0ksvKYkuIl6UJ08e/fHHHzp9+rTSpk0bY330XHG2bpstWzYlS5bsjeaTc3V1VaNGjdSoUSPdvXtXe/fu1e7du7V582Y9ePBA3bp1U+LEiVWmTJnXPkamTJms/o4uEv59aWf0B6et4f9fLH4kWb4Y2ttHdH+WFClSKDAwUFFRUTpz5ozOnz+vq1ev6vTp05bL1v79A0jatGljFICv8uOPP+rAgQNq2bKl5XX1Kh988EGMZUmTJpX092Pg7u6uP//8U8mTJ4/xGDo5OSl//vxW/TVeZdOmTVbzWLq6uip58uQqXry4GjVqZHVJXXRfmvXr11sGZ4oW/QPEv78oGh0182Vt2tvbW76+vjp58qRCQkIsj4erq6vlcux/s9c2bD2P7u7uVv1BX+c1/rLnLbrdRd9HW++ZLxaa0QMz7dmzJ0b/2uh+P696fUf/YPLil0F7ovv9vfjjklHRl3+9zrxdp06dUpo0aWxeMlywYEHLNi+y1Z6i+7k+fPhQJ0+e1JUrV3Tx4kUdOXLE8rnxul6c0iA8PFy7du3Sn3/+qRw5cmj8+PExphSIfo1cuXLF5udY4sSJdfr0aZnNZp04cUJms1kPHz60ua2rq6tu3ryp27dvW/3QFRu1atXS4MGDY307f39/5c+fX4cPH1bp0qX10UcfqVSpUipbtqzdS7z//ZqLbhuvGtXxTdpQNFuvv+TJk1v9MOrr6ytfX1+FhYXp6NGjunjxoq5cuaK//vpL+/fvlyRDbcVkMtl8DefJk0cXL17UhQsXZDKZ9OzZMxUoUMDmFB4FCxbUunXrdOrUKRUpUsTmcYoVK6aMGTNqy5YtKl68uIoVK6ZSpUqpTJkySpcu3StzAu86ijqDoucJKl26tL7++mstXLhQvXv31uzZs9WhQwe7Z40k6cCBAxo0aJDlw8nd3V3Zs2dXzpw5dfPmTUsH5ehftGIz1P/jx49VtGhR7d27V3PnzrXq5xD9hn7hwgWNGzfO7j6Cg4MtZ2ds/bLn7Oz8RtMPODk5ycvLS6VKlVLatGkVGBioESNGWIq6sLAwjRgxQr///rvly1CaNGlUuHBhpUiRwuZkvi/+ovdvtj6so39xjP4F89+if4WP/tL4b6lTp46zjtQ+Pj4KDAxUYGCgQkNDNWjQIP3++++aOnXqGxV1/z4THM3eQAu22GvHRvaxfv16DR8+3DJ5r6enp3LlyqXs2bNr9+7dMTriv9i/zojffvtN8+bNU/HixdW1a1fDt7OVPbq9R2d68OCB3TNy9ooce178weJVotvj5MmT7W7z71+6X9b2X/SqM0upU6fWyZMnFRoaamn3L3tO3qRtvM5r3MjzFv0e96r3p+jHed68eXa3edUZhUyZMunYsWO6dOnSSwdKkf4+GyPplXOe2eLm5qY0adLo9u3bunPnzkvb37179+Ts7Gz5Ev/48WO706JE7+ffRamt9hQcHKxBgwZp5cqVCg8Pl8lkUvr06VW0aFHL1Ayv699TGnTt2tXSH7dz586aMWOG1edQ9HO8Y8cOS19DW548eWLZ9siRIzpy5IjdbR8+fPjaRd3rMplMmjZtmqZOnarly5dr+/bt2r59u3788UcVK1bMMrXAi4y+1v8tukg08pl19epVpU6dOsaxjBw7KipKkyZN0owZMyyvn5QpUyp//vxKnz69zp8/H+N93xYvLy+br/fodvBiEfuyz2jp5T+6JEqUSPPnz9fEiRO1Zs0arV+/XuvXr5eTk5MqVKigfv360acOCRpFnQ2PHz9W7dq15evrq0mTJsVYbzKZ9Omnn2rt2rXauXOnbt26ZfcL4fXr19WqVSu5u7urf//+KliwoD744AM5Oztr9erV2rhxo2Xb6C/ltn6Fi4qK0vPnz2N86ZowYYL8/PxUpUoVjRgxQhUqVLB8WEW/IdasWVM//fTTS+/z+fPnJdkuesxms80R516Hn5+fvL29dffuXd2/f1/e3t4aPHiw5s6dq0qVKqlRo0by9/e3vLFWqVLF5he+l3n27FmML6DR98ve0NXRj9WdO3ds/roeHBz8Wm/2e/bs0bfffqt69erZHIghUaJE6tWrl1asWGEphl707w9EI2cJ4sPRo0fVqVMnpU2bViNGjFDu3LmVMWNGmUwmTZ482XK27nUdOHBAAwYMUIYMGTRixIhYn+F7lSRJkliNjPcie8vjgqenp5ydnXX06NFYnw1/lRfbtC3RX4DfxpeYuH6NR3vxPfPfr+1nz57Jzc1NTk5Olu02btz42gPflCtXTitXrtTGjRvtXqIabfPmzZL00kmqX6ZkyZJauHChdu3aFWOi7heNGzdO8+bN0w8//KDPPvtMiRMntvt8R3/pNvJ89+jRQ9u2bVP9+vVVs2ZN+fn5WQrnFStWxP4OGTjeiRMntHfvXvXu3VsjRoywrIt+7gYMGKC6deu+dD/R27Zr106dOnWK85xvKnHixOrUqZM6deqkixcvateuXVqxYoV2796tLl26aMGCBXFynPfff1+ZMmXSpUuXdP369Zee3W/Tpo2uXr2qRYsWKVu2bLE6zvTp0zVq1Ch99NFHatWqlT788EPLpbwtW7a0fK94lZCQEJnNZsuPNtGi23Ly5MktZ+ff9P3M29tb3333nb799ludPn1aO3bs0LJly7Ru3To5OTlp1KhRhjID7yL61NmQJEkShYSEaPfu3QoKCnrptk5OTpY3sX+/IUl/f4kIDQ1Vx44d9dlnnylLliyWL6TRb3jRX9yjf/09duxYjP0cPnxY+fLl08SJE62W58yZUylTplTnzp315MkT9evXz7LO19dXbm5u+uuvv2z+WvbLL79owoQJevDggTJlyqSkSZPanBvo3LlzcVZMhIeHKzQ01OqL1sqVK5UyZUqNHj1aRYoUsbwpP3v2zDKdgpFf+6IdP348xrLDhw/LxcXF7ohh0aNi2roe//Lly7p7967VB56t59oWHx8f3bhxQ+vWrbO7TfS+XvxFPvpXy+hLw6JFj574rlm1apWioqLUp08fVatWTZkyZbLcr+ipHGLzHL7o+vXr6tixo1xcXDR+/HiHFCE5c+bUrVu3bH5hOHr0aJwfL5q/v78iIyNt9sU5fPiwhg0b9tI+Ii8TPbpc9BD1L3r8+LFOnjyp999/P1Zncl9XXL/Go0X3qbT1nvnjjz8qb968unr1quW91dZ7w6VLlzRkyBBLIWZPuXLllD59eq1evdrm8aIdO3ZM69evV+rUqV853Yk90YXclClTYkwNES165ESTyWSZDiV79ux69OiRzal4otvRvy/T/7dHjx5p27ZtypUrl3744QcVKFDAUtBdu3ZNYWFhr/1atsfJyUmDBg1S4sSJtWrVKq1evdqyLvq5szW3aXh4uAYPHqxZs2a9cltJGjNmjCZPnmzz0nNHO3XqlIYMGWI5g+jr66vGjRtr7ty5+uCDD3Ts2LE4zRXdhv79neFFu3bt0rlz55QmTRqr/vhGrVy5Us7Ozpo4caJKlSpl+S5kNptj9b4fGRkZ4wxweHi4/vzzT3l6euqDDz5Q5syZ5e7ubvdxip7CJLp92/qMPnDggH788UdduXJFJpNJ2bNnV6tWrbRgwQJ5enq+9nst8K6gqLOjUaNGlo71tr7obdq0Sbt371aFChUsH3jRk5S/OG9O9CUM/y4OT506pZkzZ0qS5UM7Y8aMyp8/v3bu3Gl1mUn0PGNms1nFixe3mbd+/frKlSuXNm7caDn75+7urqpVq+rcuXOW+aSi7du3Tz/99JMWLVokLy8vubq6qnr16rpy5YrVts+fP9fw4cMNPGLGzJo1S6GhoSpWrJjlrKO7u7vCwsKsrv+PjIzUgAEDLMXkq+boe9HYsWOtzq6sW7dO+/btU7ly5ewWBDVr1pSLi4t+/vlnq47gT58+tRTKLw4fbuu5tiVr1qwqUqSITpw4oX79+llNRiz9/dyOGjVKT58+tbpkL/rM75YtWyzLwsLCNG3atJceL77Ya+d79uzRypUrJcnul9OXefr0qdq1a6cHDx5o4MCBL52S4k3Url1bZrNZP/30k1UfkGXLltksBOJK9BevgQMHWrXZx48fq2/fvpoyZcpr918qX768kiZNqrlz51rNgxUREWF5bf17SHxHievXeLTq1avLyclJP//8s9WgJFeuXNGaNWuUMWNGZcyYUTVq1JCzs7NGjRpldVYwIiJC/fv31/Tp02PMHWjrPkQP896mTRubXwAPHjyoNm3aKCIiQgMHDnzty+cKFSqkqlWr6vz58/rf//4X4wqKO3fuqEOHDnr48KEaNmxoOfsY/R4yYMAAqx+Erl69qvHjx8vV1VXVqlV76bFdXV3l5OSkR48eWX15fvbsmfr37y/p9Z6rV3nvvffUpUsXSX+/HqLbSuHChZUhQwYtXLgwxo+OkydP1owZMyztO2PGjCpcuLC2b98eY/7BpUuXavz48dqxY8db+SHj354/f67p06dbJqeP9vjxYwUHB8vHxydOc33xxRdKnz69FixYoPHjx8d4Hzl+/LhlcJYePXrY7Kf2Ku7u7oqMjIwx0NGECRMsAyW9+L7v6upq93Ng3LhxVhmnTp2qW7duqVatWnJ2dpabm5uqVaumO3fuaMyYMVa33b59u9asWaP333/fMoCTrc/ou3fvatasWZo+fbrV7YOCghQWFma4vzLwruLySzvatm2rM2fOaN26dapYsaJKlCihDz74QBERETp69KgOHTqkzJkzq2/fvpbbpEiRQm5ubtq3b58GDRqkChUqqGzZsho+fLgmTZqkCxcuKFOmTLp8+bK2bNliuTb8xS8TP/zwgxo3bqzWrVurfPnySp8+vfbu3asTJ06oadOmVvO7vcjJyUl9+/bVZ599pn79+qlo0aJKkiSJvv76ax0+fFhDhgzRpk2blCdPHt2+fVvr16+Xi4uLBg4caHkz79Kli/bs2aPBgwdr586dypIli/bs2aOHDx/G+svJr7/+ajUS4/Pnz3XgwAEdPnxYSZMmtZp4NDAwUNOnT1edOnVUvnx5RUREaOfOnbp48aK8vb11//59PXz40HDfpitXruiTTz5RmTJldPv2bW3cuFFp0qSJMdnpizJmzKivv/5aAwYMUK1atVS+fHl5enpq+/btunr1qqpVq2Y1cl/0Ja6DBw9WsWLFbM6lFm348OFq2rSp5syZo3Xr1qlkyZJKkyaNgoODtWfPHl26dEmVK1e2Gnmrbt26mjt3rgYOHKijR48qRYoU2rRpk5ImTWq371x8qlq1qmbMmKEffvhBBw4ckI+Pj06fPq2dO3cqRYoUunfv3iu/NNsycOBAnTp1ynImbfz48TEGXClfvnyMOY9iq1q1alq2bJlWrFihc+fOqUiRIrp8+bK2bt2qFClS6MGDB3F+yackFS1aVE2aNNGsWbNUrVo1lS5dWm5ubtq4caNu3ryp+vXr2+30/ypJkiTRwIED1aVLF9WvX18VKlRQypQptXfvXp05c0aFChVSq1at4vge2RbXr/FoWbJkUYcOHTRmzBjVrFlTZcuWldls1urVqxUWFqZBgwZJ+nvQhx49emjw4MGqXr26AgIC5OXlpe3bt+v8+fMqW7asatSo8crjffzxx5owYYK6deumxo0bq3DhwpbBpY4fP66DBw/K09NTo0aNUsmSJWP/QL1g4MCBCgkJ0ebNmy2jOaZNm1bXr1/X9u3b9eTJE1WoUEFfffWV5TY1a9bU5s2btW7dOtWoUUOlSpWyzFMXEhKi3r17xxgM6N8SJUqkChUqaN26dfr0009VvHhxPX36VFu2bFFQUJC8vLwUEhKiqKio1yoEXqZRo0aWH1KGDRumfv36ydnZWUOGDFGrVq3UuHFjlStXThkzZtSff/6pvXv3KkOGDFZ9bPv166dGjRqpU6dOKlWqlLJly6aLFy9q69atSp48ufr06ROnmY3KkyePKlWqpHXr1qlWrVoqWrSoIiIitHHjRj148MBq7sW44OHhoRkzZuiLL77QmDFjtGjRIhUvXlxJkiTRmTNnLJfEd+vWzWq07dioUaOGjhw5ogYNGqhKlSpydXXVvn379NdffyllypQx3vdTp06tS5cuqXv37ipRooTlM9Xd3V1//fWXPv30UxUtWlSnTp3Srl27lDlzZnXu3Nly+x49eujQoUOaMmWKDhw4oPz58+vq1avavHmzEidOrKFDh1rO0Nn6Pla+fHnlz59fv/32m86cOaN8+fLp8ePHlitpXuzrCSREFHV2ODs7a8yYMdqwYYOWL1+uY8eOafv27XJ1ddX777+vbt26qWnTplZ93Nzc3PT9999rzJgxmjt3rpImTapChQppxowZGjFihPbu3audO3fqvffeU5MmTdS6dWtVrFhRO3bssFxP7u/vrwULFmjs2LHatWuXHj9+rAwZMuibb76xTPhpT+7cuVWvXj399ttvGjlypGWi3fnz52vSpEnasGGDZs2aJW9vbwUEBKhdu3ZWZz68vLz022+/afTo0dq0aZMOHjyoAgUKaNSoUapXr16sHr/os5DR3N3dlS5dOtWrV0+tWrWy6tfSpUsXJU6cWMuXL9fcuXPl7e2tLFmyqFevXjp//rwGDhyobdu26dNPPzV07NGjR2vevHlatGiREiVKpE8++USdO3d+Zcf4pk2b6oMPPtC0adO0fv16mc1mZcmSRa1bt47Rl6Nhw4Y6dOiQDh48qPPnz6t58+Z2h4/28fHRsmXLNG/ePG3YsEHbt2/Xo0ePlCRJEsvk2oGBgVa3yZ49uyZPnqxx48ZpzZo1SpIkicqXL6/u3bu/9iVdjvThhx9q8uTJGjNmjDZu3ChnZ2fL0NN169ZVqVKltG3bNrVu3TpW+43u6P/XX39ZnW16Ufr06d+4qDOZTBo7dqwmTpyo5cuXa86cOXr//ff1008/afPmzVqzZk2sB3YxqlevXsqdO7d+++03LV++XM7OzvL19dX//ve/l/anMqJixYqaO3euJk6cqB07duj58+fKlCmTvvrqKzVt2jTO+/HZE9ev8Re1b99evr6++vXXX7Vs2TKZTCblz59fHTt2tEy9IUnNmzdX5syZNX36dK1fv15RUVHKmDGjevbsqUaNGll+2X+VsmXLat26dfrtt9+0ZcsWSz+oDBkyqF27dqpXr16cDMKRKFEiy/t29FmqO3fuKFGiRMqbN68+/fTTGCPAmkwmjRo1SnPmzNHChQu1cOFCJUqUSPny5VOLFi1UtGhRQ8ceOHCg0qZNq40bN2r27Nny8fFR7ty59eWXX2rlypX69ddftW/fPstln3HFyclJ/fv3V926dTV//nzVqFHDMhLnggULNHHiRO3Zs0dbtmxR2rRp1aRJE7Vp08ZqcJjMmTNr8eLFmjBhgrZt26Y9e/YoderUqlmzZowpa962n376Sbly5dKKFSv0+++/y2QyKWfOnPr+++8d8r7+/vvva9myZVq0aJFWr16tLVu26OHDh0qePLmqVKmizz//3O4PxUY0bNhQZrNZv/32mxYsWKCkSZPK19dXI0aMkLu7u9q3b69t27ZZpibp0aOHvv32W61du1b37t2zFHVubm769ddf1b9/f8vk8PXq1VOXLl2sfhyO/j7z888/a926dZo9e7a8vb31ySefqG3btlY/WNj7PjZp0iRNmTJFGzdu1Jw5c+Tu7q58+fKpdevWlhFigYTKZI7ri+OBeNKzZ08tWbJES5cufeMv+fhvuXnzppImTWpzFMXGjRvrzz//1OHDhw33pQQAAHib6FMH4D9vypQplgnqX3TkyBH98ccf+uijjyjoAADAO4vLLwH859WpU0fz58+3XBKdJk0aXbt2TRs3blTixIn19ddfx3dEAAAAuyjqAPzn5cyZ09L3dO/evbp37568vb1VtWpVtWvX7pWDSwAAAMQn+tQBAAAAQAL2f/pM3d27Ia/e6D8iRQpPPXjw9NUb4j+FdgFbaBewhXYBW2gX//DxSRrfEfAfxkAp/xEuLnE/xxYSPtoFbKFdwBbaBWyhXQDvBoo6AAAAAEjAKOoAAAAAIAGjqAMAAACABIyiDgAAAAASMIo6AAAAAEjAKOoAAAAAIAGjqAMAAACABIyiDgAAAAASMIo6AAAAAEjAKOoAAAAAIAGjqAMAAACABIyiDgAAAAASMIo6AAAAAEjAKOoAAAAAIAGjqAMAAACABIyiDgAAAAASMIo6AAAAAEjAKOoAAAAAIAGjqAMAAACABIyiDgAAAAASMIo6AAAAAEjAKOoAAAAAIAGjqAMAAACABIyiDgAAAAASMIo6AAAAAEjAKOoAAAAAIAGLt6Lu2LFjKlGihOXv4OBgtW/fXgULFlSZMmW0YMECyzqz2azhw4eraNGiKly4sH788UdFRkbGR2wAAAAAeKe89aLObDZr4cKF+uKLLxQeHm5Z3rt3b3l6emr37t0aM2aMhg0bplOnTkmS5syZo61bt2r58uVavXq1Dh06pLlz577t6AAAAADwznnrRd3PP/+smTNnqk2bNpZlT5480caNG9WxY0e5u7srT548ql69uuVs3bJly9SsWTOlTp1aPj4+at26tebPn/+2owMAAADAO+etF3V16tTRsmXLlDt3bsuyy5cvy8XFRRkzZrQs8/X11dmzZyVJFy5cUNasWa3WnTt3Tmaz+e0FBwAAAIB3kMvbPmDq1KljLHv69Kk8PDyslnl4eOjZs2eSpNDQUKv1iRIlUlRUlJ4/fy53d3e7x0qRwlMuLs5xlPz1rciSJb4jvBMCz5+P7wjvDNrEP2gX/6Bd/IN28Q/axT9oF/+gXfyDdgHEQ1FnS6JEiSwFXLRnz57J09NT0t8FXlhYmGVdaGioXFxcXlrQSdKDB0/jPixe2927IfEdAe8g2gVsoV3AFtoFbHlX2oWPT9L4joD/sHdiSoP3339fERERunHjhmXZxYsXLZdcZsmSRRcvXrRalzlz5reeEwAAAADeNe9EUZckSRKVK1dOw4cPV2hoqI4dO6aVK1cqMDBQklSjRg1NmzZNt27dUlBQkCZNmqSaNWvGc2oAAAAAiH/vxOWXktS/f3/16dNHpUuXlqenp3r06KG8efNKkho2bKigoCDVrVtX4eHhCgwMVPPmzeM5MQAAAADEv3gr6ooUKaJ9+/ZZ/k6ePLlGjx5tc1tnZ2d16dJFXbp0eVvxAAAAACBBeCcuvwQAAAAAvB6KOgAAAABIwCjqAAAAACABo6gDAAAAgASMog4AAAAAEjCKOgAAAABIwCjqAAAAACABo6gDAAAAgASMog4AAAAAEjCKOgAAAABIwCjqAAAAACABo6gDAAAAgASMog4AAAAAEjCKOgAAAABIwCjqAAAAACABo6gDAAAAgASMog4AAAAAEjCKOgAAAABIwCjqAAAAACABo6gDAAAAgASMog4AAAAAEjBDRV3Tpk11/vx5m+tOnTqlwMDAOA0FAAAAADDGxd6KgwcPymw2S5L279+vAwcO6P79+zG227Jli65eveq4hAAAAAAAu+wWdfPnz9fy5ctlMplkMpn0ww8/xNgmuuirWrWq4xICAAAAAOyyW9R9++23CgwMlNls1pdffqlvvvlGmTNnttrG2dlZyZIlU44cORweFAAAAAAQk92iLnny5CpZsqQkadCgQSpTpoxSpEhhWR8RESGTySRnZ2fHpwQAAAAA2GRooJRatWpp7ty5at68uWXZH3/8oWLFimnGjBkOCwcAAAAAeDlDRd3UqVM1fvx4ZcuWzbIsU6ZMCgwM1PDhwzV//nyHBQQAAAAA2Gf38ssXLViwQJ06dVLr1q0ty9KlS6devXrJ29tbM2fO1GeffeawkAAAAAAA2wydqbt165by5Mljc13+/PmZ0gAAAAAA4omhoi5t2rT6448/bK47duyYUqVKFaehAAAAAADGGLr8smbNmvr555/l7u6uihUrKmXKlHrw4IE2btyoiRMnqmXLlo7OCQAAAACwwVBR17p1a124cEHDhw/XiBEjLMvNZrOqVaumtm3bOiwgAAAAAMA+Q0Wds7Ozhg0bprZt2+rAgQN6+PChkiZNqkKFCsnf39/RGQEAAAAAdhgq6qJlyZJF77//vh48eKAUKVLIxSVWNwcAAAAAxDFDA6VI0qlTp9SqVSsVKFBApUuX1unTp/XNN99o0qRJjswHAAAAAHgJQ0Xdn3/+qfr16+vq1atq2LChzGazJMnLy0ujRo3SggULHBoSAAAAAGCboaJu2LBhypMnj1atWqXu3btbirqePXuqbt26mjNnjkNDAgAAAABsM1TUHT16VM2aNZOzs7NMJpPVuqpVq+ry5csOCQcAAAAAeDlDRZ2Li4siIiJsrgsJCZGrq2uchgIAAAAAGGOoqCtSpIgmTpyoR48eWZaZTCZFRERo1qxZKlSokMMCAgAAAADsMzQnQdeuXVW/fn1VqFBBhQsXlslk0s8//6xz587p1q1bmjdvnqNzAgAAAABsMHSmLnPmzFq0aJFKly6tI0eOyNnZWQcOHFC2bNk0f/58+fn5OTonAAAAAMAGQ2fqVq9erSJFiuinn35ydB4AAAAAQCwYOlPXv39/7d+/39FZAAAAAACxZKioS5IkiaKiohydBQAAAAAQS4Yuv2zVqpX69u2rEydOKFu2bEqVKlWMbUqUKBHn4QAAAAAAL2eoqPv+++8lSdOmTbNabjKZZDabZTKZdPLkybhPBwAAAAB4KUNF3cyZMx2dAwAAAADwGgwVdZs2bVL16tWVO3duR+cBAAAAAMSCoYFSFi5cqEePHjk6CwAAAAAglgwVddmyZdPhw4cdnQUAAAAAEEuGLr8sUaKEfv75Z23bts3m6Jcmk0ldunRxSEAAAAAAgH2Girpx48ZJko4fP67jx4/HWE9RBwAAAADxw1BRd+rUKUfnAAAAAAC8BkNF3YvOnz+vkJAQeXt7K1OmTI7IBAAAAAAwyHBRt3r1ag0ePFh37961LEudOrV69Oih6tWrOyQcAAAAAODlDBV127dvV7du3ZQ3b161bdtWPj4+un37tlasWKEePXrIy8tLJUuWdHRWAAAAAMC/GCrqJkyYoLJly2rChAlWyxs1aqR27dpp0qRJFHUAAAAAEA8MzVN38uRJ1atXz+a6evXq6cSJE3EaCgAAAABgjKGizsvLS0+fPrW57smTJ3J2do7TUAAAAAAAYwwVdQULFtTEiRP16NEjq+XBwcGaOHGiChUq5JBwAAAAAICXM9SnrmvXrqpdu7bKly+vkiVLKlWqVAoKCtKOHTsUGRmpESNGODonAAAAAMAGQ0VdxowZNW/ePI0bN0579+5VcHCwvLy8VKJECbVv315ZsmRxdE4AAAAAgA2G56nLkiWLRo4cafk7PDxcTk5O9KcDAAAAgHhkqE+dJI0fP17Nmze3/H3o0CEVK1ZMM2bMcEgwAAAAAMCrGSrqpk6dqvHjxytbtmyWZZkyZVJgYKCGDx+u+fPnOywgAAAAAMA+Q5dfLliwQJ06dVLr1q0ty9KlS6devXrJ29tbM2fO1GeffeawkAAAAAAA2wydqbt165by5Mljc13+/Pl19erVOA0FAAAAADDGUFGXNm1a/fHHHzbXHTt2TKlSpYrTUAAAAAAAYwxdflmzZk39/PPPcnd3V8WKFZUyZUo9ePBAGzdu1MSJE9WyZUtH5wQAAAAA2GCoqGvdurUuXLig4cOHW000bjabVa1aNbVt29ZhAQEAAAAA9hkq6pydnTVs2DC1bdtWBw4c0MOHD5U0aVIVKlRI/v7+js4IAAAAALDD8OTj0t8TkGfJksVRWQAAAAAAsWS4qNu6das2b96sp0+fymw2x1g/fPjwOA0GAAAAAHg1Q0Xd1KlTNWzYMLm7u8vb21smk8lq/b//BgAAAAC8HYaKurlz56patWoaNGiQ3NzcHJ0JAAAAAGCQoXnqgoKC9Nlnn1HQAQAAAMA7xlBRlzVrVl2+fNnRWQAAAAAAsWTo8svu3burV69eSpMmjfLnzy8PD48Y23AWDwAAAADePkNFXa9evXT//n21adPG5nqTyaQTJ07EaTAAAAAAwKsZKupq167t6BwAAAAAgNdgqKjr0KGDo3MAAAAAAF6DoYFSAAAAAADvJrtn6urXrx+rHc2bN++NwwAAAAAAYsduUefq6vo2cwAAAAAAXoPdom7WrFlvMwcAAAAA4DXQpw4AAAAAEjCKOgAAAABIwCjqAAAAACABo6gDAAAAgASMog4AAAAAEjCKOgAAAABIwOxOadCtW7dY7Wj48OFvHAYAAAAAEDt2i7rDhw9b/X3nzh1FRETovffek4+Pjx48eKBr167J3d1d/v7+Dg8KAAAAAIjJblG3efNmy/9Xr16tQYMGacyYMcqfP79l+enTp9W+fXtVq1bNsSkBAAAAADYZ6lM3YsQIdevWzaqgkyR/f3917txZU6dOdUg4AAAAAMDLGSrq7t27p+TJk9tc5+HhoZCQkLjMBAAAAAAwyFBRlyNHDs2YMUPPnz+3Wv748WP9/PPPMc7gAQAAAADeDrt96l7UtWtXNW/eXAEBASpWrJi8vb119+5d7dy5U1FRUZozZ46jcwIAAAAAbDBU1BUsWFDz58/X5MmTtXv3bj18+FDe3t4KCAhQu3btlDFjRkfnBAAAAADYYKiok6Ts2bNrxIgRjswCAAAAAIglw0Wd9PdcdaGhoYqKioqxztfXN85CAQAAAACMMVTUXbx4Ud27d9eJEyfsbnPy5Mk4CwUAAAAAMMZQUTdgwABdu3ZNHTp0UNq0aeXkZGjQTAAAAACAgxkq6g4ePKh+/fqpRo0ajs4DAAAAAIgFQ6fcEiVKpJQpUzo6CwAAAAAglgwVdVWqVNHixYsdnQUAAAAAEEuGLr/MkiWLRo8erU8//VT58uVTokSJrNabTCZ16dLFIQEBAAAAAPYZKur69+8vSTp+/LiOHz8eYz1FHQAAAADED0NF3alTpxydAwAAAADwGuJkboKIiIi42A0AAAAAIJYMnakzm81atmyZ9u3bp+fPn1uWR0VFKTQ0VEeOHNHevXsdFhIAAAAAYJuhom7cuHEaP368kiZNqoiICLm6usrFxUX379+Xk5OT6tWr5+icAAAAAAAbDF1+uWzZMtWsWVP79+9Xs2bNFBAQoN27d2vBggVKliyZsmbNGidhDh06pNq1a6tAgQKqVKmSVqxYIUkKDg5W+/btVbBgQZUpU0YLFiyIk+MBAAAAQEJnqKi7deuWAgMDZTKZlCNHDh0+fFiSlDt3brVp00YLFy584yCRkZFq3769vvzySx06dEgDBgxQz549de3aNfXu3Vuenp7avXu3xowZo2HDhjF4CwAAAADIYFHn4eEhZ2dnSVKmTJl07do1S9+6nDlz6urVq28c5NGjR7p//74iIyNlNptlMpnk6uoqZ2dnbdy4UR07dpS7u7vy5Mmj6tWrc7YOAAAAAGSwqPvwww+1fv16SdIHH3wgk8mkgwcPSpKuXbtmKfjeRIoUKdSwYUN17dpVOXPmVKNGjdS7d289ePBALi4uypgxo2VbX19fnT179o2PCQAAAAAJnaGBUpo3b6727dsrJCREw4YNU/ny5dWzZ0+VK1dOa9asUeHChd84SFRUlDw8PDR69GhLn71u3bpp4sSJ8vDwsNrWw8NDz549e+U+U6TwlIvLmxeciBs+PknjOwLeQbQL2EK7gC20i39k7x8V3xHeGbQLwGBRFxAQoEmTJun8+fOSpB9++EHdunXTkiVLlDdvXvXq1euNg6xfv17Hjh3T119/LUkqU6aMypQpo7Fjx8Yo4J49eyZPT89X7vPBg6dvnAtx5+7dkPiOgHcQ7QK20C5gC+0Ctrwr7YLiEvHJUFEnSaVKlVKpUqUkSV5eXpo6dWqcBrl586bVHHiS5OLiopw5c+qPP/7QjRs39N5770mSLl68GGcjbgIAAABAQmaoT93bUKxYMZ08eVKLFi2S2WzW/v37tWHDBlWrVk3lypXT8OHDFRoaqmPHjmnlypUKDAyM78gAAAAAEO/emaLO399fY8aM0cyZM1WwYEH169dPQ4YMUe7cudW/f39FRESodOnS6tixo3r06KG8efPGd2QAAAAAiHeGL798GwICAhQQEBBjefLkyTV69Oh4SAQAAAAA77Z35kwdAAAAACD2KOoAAAAAIAF746IuPDxcN27c0L179+IiDwAAAAAgFt64T92JEydUv359ZcuWTR4eHpoxY4YSJ04cF9kAAAAAAK/wxmfqvL299cknn2j58uVq3ry5goKC4iIXAAAAAMCANz5TlzFjRg0aNEiSVKVKlTcOBAAAAAAwztCZunHjxun27ds21127dk39+vWL01AAAAAAAGMMFXXjx4+3W9QdPXpUCxYsiNNQAAAAAABj7F5+Wa9ePR07dkySZDabVa9ePbs7yZkzZ9wnAwAAAAC8kt2irl+/flq5cqXMZrOmTp2qGjVqKHXq1FbbODk5ycvLS9WqVXN4UAAAAABATHaLOn9/f/n7+0uS7t27p3bt2iljxoxvLRgAAAAA4NUM9akbNGiQbty4oZEjR1qWHT9+XG3atNGRI0cclQ0AAAAA8AqGirotW7boiy++0L59+yzLnJ2ddfPmTTVp0kQHDhxwWEAAAAAAgH2GR7+sWrWqfvvtN8uyHDlyaNmyZapUqZLVGTwAAAAAwNtjqKg7f/68ateuLZPJFGNdnTp1dOrUqTgPBgAAAAB4NUNFXeLEiXXt2jWb627evCl3d/c4DQUAAAAAMMZQUVe6dGmNGTPGMm9dtL/++ktjx45VmTJlHJENAAAAAPAKdqc0eFG3bt108OBB1atXTz4+PkqVKpXu37+v27dvK1OmTOrevbujcwIAAAAAbDBU1Hl7e2vZsmVavHix/vjjDz148EAZM2ZUoUKFVKdOHXl6ejo6JwAAAADABkNFnSR5eHioYcOGatiwoSPzAAAAAABiwXBR9/TpU82ZM0c7d+7UnTt3NGbMGO3cuVM5c+bURx995MiMAAAAAAA7DA2UEhQUpDp16mj06NF6/PixLl26pOfPn2vfvn1q0aIFk48DAAAAQDwxVNQNHTpUYWFhWrNmjX7//XeZzWZJ0pgxY5QvXz6NHz/eoSEBAAAAALYZKuq2bt2qjh07KmPGjFYTkLu5uenzzz/XyZMnHRYQAAAAAGCfoaLu2bNn8vb2trnOzc1NYWFhcRoKAAAAAGCMoaLuww8/1OLFi22u27Bhg7Jnzx6noQAAAAAAxhga/bJdu3Zq3bq1mjZtqnLlyslkMmnXrl2aM2eOli5dqjFjxjg6JwAAAADABkNn6kqVKqWRI0fq2rVrGjRokMxms0aMGKHt27drwIABKl++vKNzAgAAAABsMHSm7urVq6pcubIqV66sixcv6sGDB0qWLJmyZMliNXAKAAAAAODtMnSmrlmzZlq6dKkkydfXVwUKFFDWrFkp6AAAAAAgnhkq6kJDQ5UqVSpHZwEAAAAAxJKhou6LL77QwIEDtW3bNt28eVPPnz+P8Q8AAAAA8PYZ6lP322+/6c6dO2rTpo3N9SaTSSdOnIjTYAAAAACAVzNU1NWuXdvROQAAAAAAr8FQUZc5c2YVKVJEKVOmdHQeAAAAAEAsGOpT179/f+3fv9/RWQAAAAAAsWSoqEuSJImioqIcnQUAAAAAEEuGLr9s1aqV+vbtqxMnTihbtmw2pzcoUaJEnIcDAAAAALycoaLu+++/lyRNmzbNarnJZJLZbJbJZNLJkyfjPh0AAAAA4KUMFXUzZ850dA4AAAAAwGswVNR99NFHjs4BAAAAAHgNhoo6Sbp8+bJGjx6tffv26dGjR0qRIoU++ugjtW/fXr6+vo7MCAAAAACww1BRd+HCBdWrV09ms1klS5aUj4+P7ty5oy1btmjLli1auHAhhR0AAAAAxANDRd2IESPk4+Oj2bNny9vb27L8/v37atasmUaNGqXRo0c7LCQAAAAAwDZD89Tt27dPHTp0sCroJMnb21tt2rTRvn37HBIOAAAAAPByhoo6k8mkxIkT21yXJEkShYaGxmkoAAAAAIAxhoq67Nmza9GiRTbXLViwQNmzZ4/TUAAAAAAAYwz1qWvXrp0+//xzNWnSRNWrV1eqVKkUFBSklStX6uDBgxo/fryjcwIAAAAAbDBU1BUtWlRDhw7VTz/9pD59+liW+/j4aPDgwQoICHBYQAAAAACAfYbnqQsMDFT16tV14cIFBQcHy8vLS5kzZ5bJZHJkPgAAAADAS7yyT53ZbFZISIikvwdMyZIliwoUKKA7d+7IbDY7PCAAAAAAwL6XFnXHjh1TlSpV9Ouvv1otf/jwob744gtVqFBBp06dcmhAAAAAAIB9dou6K1euqEWLFnr+/HmM0S09PDz0/fffy2w2q3Hjxrpx44bDgwIAAAAAYrJb1E2ePFne3t5avHixypcvb7XOw8NDDRo00IIFC5Q0aVJNnjzZ4UEBAAAAADHZLer27dunli1bKnny5HZvnDJlSn3++efas2ePI7IBAAAAAF7BblF3584dffDBB6/cgb+/v27duhWXmQAAAAAABtkt6lKkSKF79+69cgePHj2Sl5dXnIYCAAAAABhjt6grUKCAVq9e/codrF69WtmyZYvTUAAAAAAAY+wWdQ0bNtSGDRs0Y8YMuzeeMWOG1q1bp08//dQh4QAAAAAAL+dib0WhQoXUrl07DRkyRIsXL1aZMmWUIUMGRUZG6tq1a9q+fbvOnz+vBg0aqHLlym8zMwAAAADg/7Nb1EnS//73P/n5+ennn3/WlClTLMtNJpPy5MmjMWPGqEKFCg4PCQAAAACw7aVFnSRVqlRJlSpVUlBQkG7evCkXFxe99957DI4CAAAAAO+AVxZ10VKlSqVUqVI5MgsAAAAAIJbsDpQCAAAAAHj3UdQBAAAAQAJGUQcAAAAACRhFHQAAAAAkYIaKunr16mnBggV68uSJo/MAAAAAAGLBUFHn5eWlvn37qkSJEvrmm2/0xx9/ODoXAAAAAMAAQ1MaTJ48WXfu3NGSJUss/z744APVqVNHtWrVYqoDAAAAAIgnhvvUpU6dWq1bt9batWs1Z84cFS9eXHPmzFGZMmXUvn177dixw5E5AQAAAAA2vNZAKUmSJFGSJEnk7u6uiIgInT9/Xl9++aVq166tCxcuxHVGAAAAAIAdhi6/lKT79+9rxYoVWrp0qU6dOiVvb2/VrFlTn376qXx9fXXx4kW1bdtW3bp105IlSxyZGQAAAADw/xkq6tq2basdO3YoKipKxYoV06hRo1SuXDm5uPxzc19fX1WrVk2//PKLo7ICAAAAAP7FUFF38uRJtW7dWnXq1NF7771nd7uPP/5YOXPmjLNwAAAAAICXM1TUbd68WU5Or+5+V6hQoTcOBAAAAAAwzm5R9/vvv8dqR/Xq1XvjMAAAAACA2LFb1PXp08fwTkwmE0UdAAAAAMQDu0Xdpk2b3mYOAAAAAMBrsFvUpU+f/m3mAAAAAAC8BrtF3YgRIwzvxGQyqUuXLnESCAAAAABgnN2ibvLkyYZ3QlEHAAAAAPHDblF36tSpt5kDAAAAAPAaXj35nAERERFxsRsAAAAAQCwZmnzcbDZr2bJl2rdvn54/f25ZHhUVpdDQUB05ckR79+51WEgAAAAAgG2Girpx48Zp/PjxSpo0qSIiIuTq6ioXFxfdv39fTk5OzFEHAAAAAPHE0OWXy5YtU82aNbV//341a9ZMAQEB2r17txYsWKBkyZIpa9asjs4JAAAAALDBUFF369YtBQYGymQyKUeOHDp8+LAkKXfu3GrTpo0WLlzo0JAAAAAAANsMFXUeHh5ydnaWJGXKlEnXrl2z9K3LmTOnrl696riEAAAAAAC7DBV1H374odavXy9J+uCDD2QymXTw4EFJ0rVr1ywFHwAAAADg7TI0UErz5s3Vvn17hYSEaNiwYSpfvrx69uypcuXKac2aNSpcuLCjcwIAAAAAbDB0pi4gIECTJk1Szpw5JUk//PCD/Pz8tGTJEvn7+6tXr14ODQkAAAAAsM3QmTpJKlWqlEqVKiVJ8vLy0tSpUx0WCgAAAABgjN2i7uLFi0qfPr3c3Nx08eLFV+7I19c3ToMBAAAAAF7NblFXtWpV/f7778qTJ4+qVKkik8lkczuz2SyTyaSTJ086LCQAAAAAwDa7Rd3AgQOVMWNGy//tFXUAAAAAgPhjt6irVauW5f9FixaVj4+PXF1dY2wXFhamv/76yzHpAAAAAAAvZWj0y3Llytm9vPLYsWNq3rx5nIYCAAAAABhj90zdkCFD9PDhQ0l/95ubMGGCUqRIEWO7kydPKmnSpA4LCAAAAACwz25RlylTJq1YsUKSZDKZdPjw4RiXXzo5OcnLy0tfffWVY1MCAAAAAGyyW9Q1aNBADRo0kCRlz55dU6ZMUZ48ed5aMAAAAADAqxnqU1exYkU9ffrU0VkAAAAAALFkqKjbuXOno3MAAAAAAF6DoaKuYMGCWrNmjaKiohydBwAAAAAQC3b71L3ogw8+0G+//aZNmzYpS5YsSpUqVYxthg8fHufhAAAAAAAvZ6io27Rpk1KnTi1Junr1qq5evWq13mQyxX0yAAAAAMArGSrqNm/e7OgcAAAAAIDXYKhP3avcu3cvLnYDAAAAAIglQ2fqwsLCNGXKFO3bt0/h4eGW5VFRUQoNDdXFixf1559/OiwkAAAAAMA2Q0Xd0KFDNXv2bPn5+enevXvy8PCQt7e3zpw5o/DwcHXq1MnROQEAAAAANhi6/HLDhg1q3ry5li9frsaNGyt37txasGCB1q1bp7Rp0yoyMtLROQEAAAAANhgq6u7du6dSpUpJkvz8/HTs2DFJUtq0adW6dWutXr3acQkBAAAAAHYZKuoSJ05sORuXKVMm3bx5U0+fPpUkZc6cWTdu3HBcQgAAAACAXYaKurx582rBggUym816//335ebmph07dkiSzpw5o0SJEjk0JAAAAADANkNFXevWrbVp0ya1atVKbm5uqlmzpr799lt9+eWX+umnnyyXZr6pW7duqXXr1ipQoIBKlSqlmTNnSpKCg4PVvn17FSxYUGXKlNGCBQvi5HgAAAAAkNAZGv2yYMGCWrRokU6fPi1J6tWrl0wmkw4ePKhq1aqpZ8+ebxzEbDarXbt2KlKkiMaNG6dLly6pUaNGypUrl3755Rd5enpq9+7dOn36tFq1aqXcuXMre/bsb3xcAAAAAEjIDBV1kuTv7y9/f39Jkpubm3744Yc4DXL06FHduXNH3bt3l7Ozs7Jly6Z58+bJ3d1dGzdu1Lp16+Tu7q48efKoevXqWrBggXr37h2nGQAAAAAgoXlpUXf+/HnNmTNH169fV6ZMmVS/fn1lyZLFIUH++usvZcuWTUOHDtWKFSuUJEkStWnTRv7+/nJxcVHGjBkt2/r6+mr9+vUOyQEAAAAACYndou7IkSNq2rSpIiIilCJFCu3YsUPz5s3TyJEjVb58+TgPEhwcrH379qlo0aLasmWL/vzzT7Vs2VKTJ0+Wh4eH1bYeHh569uzZK/eZIoWnXFyc4zwrXo+PT9L4joB3EO0CttAuYAvt4h9FbxgaFuE/4TztArBf1I0dO1a+vr6aMGGC0qdPr/v376tLly766aefHFLUubm5ycvLS61bt5YkFShQQJUqVdKYMWNiFHDPnj2Tp6fnK/f54MHTOM+J13f3bkh8R8A7iHYBW2gXsIV2AVvelXbBjw6IT3Z/5vnzzz/VoUMHpU+fXpLk7e2tHj166OrVqwoKCorzIL6+vgoNDVVERIRlWWRkpHLkyKGIiAirufAuXryorFmzxnkGAAAAAEho7BZ1jx8/lo+Pj9WyzJkzy2w26969e3EepHjx4kqWLJmGDx+uiIgIHTp0SBs2bFDlypVVrlw5DR8+XKGhoTp27JhWrlypwMDAOM8AAAAAAAmN3aIuMjJSTk7Wq93d3SXJ6mxaXPHw8NCsWbN05swZFStWTN27d1evXr2UL18+9e/fXxERESpdurQ6duyoHj16KG/evHGeAQAAAAASGsNTGrwN77//vqZNmxZjefLkyTV69Oh4SAQAAAAA77aXFnXh4eF6/vy55e/IyEhJf5+pe3G59PdAJwAAAACAt+ulRV3jxo1tLq9fv77V3yaTSSdOnIi7VAAAAAAAQ+wWdR06dHibOQAAAAAAr4GiDgAAAAASMLujXwIAAAAA3n0UdQAAAACQgFHUAQAAAEACRlEHAAAAAAkYRR0AAAAAJGAUdQAAAACQgL1xUXf06FF9+OGHKlGihDp37qzw8PC4yAUAAAAAMOCNi7okSZKoUKFC2rFjh3Lnzq2LFy/GRS4AAAAAgAF2Jx83KkuWLJo1a5YkqUWLFm8cCAAAAABgnKGibunSpSpdurRSpEgRY93du3e1dOlStWrVKs7DAQAAAP8lWYZleSvHOd/9/Fs5jqOFhobqyZMnSpUqVXxHiVeGLr/85ptvdPXqVZvrTp48qTFjxsRpKAAAAADvlu3bt6tZs2YqUqSIPvroI7Vo0ULHjx+P10yNGjWK9wzvArtn6lq1aqULFy5Iksxms9q3by83N7cY2927d08ZM2Z0XEIAAAAA8Wr+/PkaPXq0fvzxR5UoUUJRUVGaM2eOmjVrpt9//13ZsmWLl1wPHz6Ml+O+a+wWdV9++aV+++03SdL169eVLVs2JU+e3GobJycneXl56dNPP3VoSAAAAADx4+nTpxo8eLCGDx+usmXLWpZ/8cUXun//vs6fP68UKVJo0KBB2rlzpzw8PFStWjV17txZbm5u6tmzp8LCwnTkyBElSZJE3377rfr166cMGTLo6NGjGjt2rPz9/TVgwADt3LlTiRIlUv369dWqVSuZTCaFhYVp6NChWrlypcxmswICAtS3b1917dpVN27cUKdOndS9e3c1bdo0Hh+l+GW3qCtcuLAKFy4s6e9+c999952yZHk71/gCAAAAeDccOnRIkZGRKlmyZIx13bt3lyTVr19f6dOn16ZNm/TkyRO1b99eY8aMsaw/cOCAFi1aJE9PT504cUIXLlxQy5YtNWbMGLm6uqpdu3ZKnjy5Nm3apPv376tNmzZKmTKl6tSpo7Fjx+rIkSNatmyZEidOrHbt2mn8+PEaP368AgIC1Lt3b6ti87/IUJ+66NEto8/cSdLZs2f1448/2u1rBwAAACDhe/jwoZIlSyYXF9vng65cuaLDhw/ru+++U5IkSZQmTRp16tRJS5YssWxTpEgRpUmTRkmTJpUkmUwmBQYGKlGiRHrw4IG2b9+ub775Rp6ensqQIYNatGihBQsWSJJWrVqlNm3aKE2aNEqSJIl++ukn1a1b1/F3PAExNPrloUOH1KJFC6VJk0YNGjSQJIWEhGjNmjVavny5Zs6cqezZszs0KAAAAIC3L1WqVAoODlZ4eLhcXV2t1gUHB+vOnTvy9PSUt7e3Zfl7772noKAghYeHS5J8fHysbufl5WUZr+PmzZsym82qUKGCZX1UVJSl61dQUJDSpk1rWffi//E3Q2fqRo4cqQIFCmjp0qWWZQUKFNCmTZuUO3duDRs2zFH5AAAAAMSj/Pnzy9XVVdu3b4+x7rvvvtP48eP19OlT3b9/37L82rVrSp48uaUINJlMdvfv4+MjFxcX7d69WwcPHtTBgwe1ZcsWzZ49W5KUJk0a3b5927L98ePHLVcS4m+GiroTJ06oRYsW8vDwsFru4eGhzz//XMeOHXNIOAAAAADxy93dXV27dtX333+vrVu3KiIiQo8fP9a4ceO0e/duffPNN/r44481YMAAPXnyRLdv39aYMWMUGBhoaP/p0qVTwYIFNXToUD179kwPHz5Ux44dNXLkSElSYGCgJk+erKCgIIWEhGj48OEKCgqSJLm6uurx48cOu+8JhaHLL11dXa0q7xeFhITIbDbHaSgAAADgv+hdnRS8UaNGSpYsmcaNG6cePXrIyclJefLk0axZs+Tn56dhw4ZpwIABKleunCSpRo0a6tatm+H9jxgxQgMHDlRAQIAiIyNVqlQp9enTR5LUtm1bhYaG6pNPPlFERIQqV66s9u3bS5Jq1aql3r176+rVq2rXrl3c3/EEwmQ2UJF17txZp06d0i+//GJ1DeudO3fUokUL+fr6vpMTkN+9GxLfESRJe4vmi+8I74Sie4/Ed4R3Bm3iH7SLf9Au/kG7+Aft4h+0i38U/TVffEd4Z+xtdiS+I0iSfHySxncE/IcZOlPXrVs3ffrpp6pYsaJy5sypVKlS6f79+/rzzz+VOHFijR8/3tE5AQAAAAA2GCrqMmbMqJUrV2rGjBn6448/dObMGSVNmlQNGjRQ8+bNlSZNGkfnBADgPyl7/6j4jgAAeMcZKuqkv4cy7dGjhyOzAAAAAABiyXBRZzabtWbNGu3cuVN37txRr169dPToUeXKlUtZsmRxZEYAAAAAgB2GironT56odevWOnjwoFKkSKGHDx/qyZMnWrZsmfr37685c+bI39/f0VkBAAAAAP9iePLxs2fPavbs2dqxY4dlCoOhQ4cqffr07+TIlwAAAADwX2CoqFu7dq26dOmiQoUKWc0GnzJlSrVu3VqHDx92WEAAAAAAgH2GirpHjx4pY8aMNtelSJFCT548idNQAAAAAABjDPWpy5w5szZs2KDixYvHWLdz5075+vrGeTAAAADgv+bs3LfzvTpbw4tv5Tgvc/XqVbsnjv6rXvcxMXSmrnnz5po3b56++eYbbdmyRSaTSWfPntX48eM1c+ZMNWrUKNYHBgAAAJAw+Pv7K2/evMqfP7/y58+vAgUKqEWLFjpz5sxr7W/27NkaOnSo5e/8+fPr/Pnzr7xdQECAtmzZEuP/sXH79m317t1bpUqVUoECBVS1alXNnj071vuJa/9+TGLD0Jm6mjVr6v79+xozZoyWLl0qs9msnj17ys3NTa1bt9ann376WgcHAAAAkDAsWLBAfn5+kqTw8HCNGDFCrVq10ubNm+Xs7ByrfT148MDq77c1Rsft27dVu3Zt1apVS0uXLlWKFCl07Ngxde7cWQ8fPlSHDh3eSg5b/v2YxIahM3VPnjxR8+bNtWPHDk2ZMkVDhw7VpEmTtGPHjni94wAAAADePldXV9WuXVu3bt1ScHCwoqKiNGrUKFWuXFn58+dX6dKlNW/ePEnStWvXVLBgQfXs2VOFChXSkiVLNGnSJG3cuFF169aV9PeZwOizfqtWrVLt2rVVuHBhffTRR/r+++8to+/bsmTJElWqVMlq2f/+9z9NmTIlxrajRo1SwYIF1b17d3l7e8tkMilv3rwaMGCA7ty5Y9nu119/Vbly5VS4cGF98cUXunDhgiRp3759qlKlilq1aqWPPvpI+/btU0BAgHr37q0iRYqoT58+kqS5c+eqYsWKKlKkiNq3b6+7d+9a9r1u3TpVq1ZN+fPnV926dfXnn39q3bp1MR6T2DBU1NWpU0dr1qxRkiRJVKJECQUGBqp06dLy8vKK9QEBAAAAJGzBwcGaNWuW/Pz85O3treXLl2v9+vWaNWuWDh06pG7dumngwIGWARUfP36s9OnTa/fu3apcubJat26t8uXLa+HChVb7vXbtmnr16qW+ffvqwIEDmjt3rlauXKm9e/fazVKhQgXdunVLJ06csBxr+/btql69eoxtd+zYoQoVKsRYXqxYMfXr10+S9Pvvv2vatGkaP368du3apQIFCqhVq1Z69uyZJOnChQuqXLmytm3bpoIFC0qSbty4oW3btqlHjx5as2aNJk+erPHjx2v79u3KmDGjunTpIkk6e/asevTooa+//lp//PGHatWqpQ4dOqh8+fJ2HxMjDF1+ef/+fSVPnjzWOwcAAADwf0P9+vXl5PT3OSE3NzflyZPHMl91+fLlVbx4caVKlUq3b9+Wu7u7wsLCFBwcbLl9YGCg3NzcXnqM1KlTa8WKFcqQIYMePHighw8fysvLS7dv37Z7myRJkiggIECrV69Wjhw5tH79euXJk0fp0qWLse3Dhw/l7e390gzLli3T559/ruzZs0uS2rVrp99//1379++Xu7u7TCZTjPtSqVIleXh4SJIWLlyozz//XNmyZZMkde3aVQULFtTFixe1Zs0alSxZUqVKlZIkNWjQQDly5HjpmUgjDBV1n3zyicaOHavUqVPL19fX8mQCAAAA+G+YN2+epU/dv4WHh+vHH3/Unj17lC5dOn344YeSpKioKMs2qVKleuUxXFxctGDBAi1cuFCenp7KkSOHwsPDrfZjS40aNdS/f391795dK1euVGBgoM3tfHx8FBQUFGN5ZGSkQkJClDx5ct27d0/vvfeeZZ2Tk5PSpUun27dvK1OmTPLy8opRnL54327evKlRo0Zp3LhxlmUmk0k3btxQUFCQ0qZNa7Xv/Pnzv/xBMcBQUXfy5EkdO3ZM1atXl7Ozc4yzdiaTSTt27HjjMAAAAAASnhEjRshsNmvHjh1yd3fXjRs3tGTJEqttTCbTK/ezatUqrV69WkuXLpWPj48kqVy5cq+8XYkSJfT06VPt2bNHhw4d0siRI21uV7JkSW3YsEE1a9a0Wr5161Z1795dO3bs0Hvvvafr169b1kVFRenGjRtKmTKl3eO/eN98fHz0xRdfWPWNO3/+vDJmzKgjR47o5MmTluVms1lDhw5Vy5YtX3kfX8bQKbcMGTIoMDBQn3zyiQIDA1WyZEmrfyVKlHijEAAAAAASrsePH8vNzU3Ozs568OCBhgwZIkmKiIiwub2bm5seP35scz8uLi5yc3PT8+fPNWXKFF27ds3ufqK5urqqSpUqGjx4sIoXL2537I927drpwIEDGjFihB4+fKjIyEjt3btXffr0UYsWLZQkSRJ98skn+vXXX3X69Gk9f/5cEyZMkCQVLVrU0GNRq1YtzZgxQ5cvX1ZUVJRmzZqlzz77TKGhoapSpYp27dqlPXv2KCoqSnPnztXatWstZ/9sPSZGGDpTV6dOHeXJk+eV18ACAAAAeH3vwqTgr6Njx476+uuvVbhwYSVLlkw1a9ZUpkyZdP78efn7+8fYvkyZMpo1a5YqVaqkdevWWZbXqlVLe/bsUdmyZeXh4aHChQurQoUKhuawCwwM1Ny5c9W2bVu726RNm1a///67Ro4cqapVqyo0NFTp06dXu3bt1LBhQ0l/T+f24MEDtW/fXvfu3VPu3Lk1Y8YMeXp6GnosatasqYcPH6pVq1YKCgpS5syZNWnSJHl5ecnLy0sjRozQwIEDdf36dfn7++vnn3+Ws7Oz3cfECJPZQK+8kiVLqlu3bvrkk09itfP4dvduSHxHkCTtLZovviO8E4ruPRLfEd4ZtIl/0C7+Qbv4B+3iHw835InvCO+M5BWOxXeEd0bRX/PFd4R3xt5mR+I7giTJxydpfEf4z7t9+7aqVaumXbt2yd3dPb7jvFWGztSZTCYlS5bM0VkAAAAAIFaioqJ07tw5zZgxQzVq1PjPFXSSwaKua9eu6tevn27duiU/Pz+bnQR9fX3jPBwAAAAAvIzJZFLTpk2VNm1aTZs2Lb7jxAtDRV3Pnj0lSf369bM7as2Lo7gAAAAAwNtgMpleOjn5f4Ghom7QoEGOzgEAAAAAeA2GirpatWo5OgcAAAAA4DUYKuok6cGDB5o+fbr27dunR48eKUWKFProo4/UrFkzeXt7OzIjAAAAAMAOQ5OP37lzR7Vr19b06dMlSVmyZFFERISmTp2q2rVr6+7duw4NCQAAAACwzdCZuuHDhysyMlLLli1T1qxZLcvPnTunli1bauTIkRo4cKDDQgIAAAAAbDNU1G3fvl3du3e3KugkKWvWrPrf//6nkSNHOiQcAAAA8F+yIkuWt3KcwPPn38px4ltoaKiePHmiVKlSxXcUhzJ0+WVYWJjSpEljc12aNGn06NGjOA0FAAAA4N3RpEkTzZ49O75jxFqjRo10/Pjx+I7hcIaKuqxZs2r9+vU2161bt04ffPBBXGYCAAAAgDf28OHD+I7wVhi6/LJFixbq1KmTnj9/rurVqytVqlQKCgrSihUrtHz5cvXv39/ROQEAAADEs7Fjx+ry5csKCQnR/v37lS5dOn377bcqUaKEpL9P+IwZM0Y3btxQlixZ1LdvX+XKlUtBQUEaNGiQdu7cKQ8PD1WrVk2dO3eWm5ubevbsqbCwMB05ckRJkiTRt99+q379+ilDhgw6evSoxo4dK39/fw0YMEA7d+5UokSJVL9+fbVq1Uomk0lhYWEaOnSoVq5cKbPZrICAAPXt21ddu3bVjRs31KlTJ3Xv3l1NmzaN50fPcQydqatUqZI6d+6sNWvWqFWrVqpVq5ZatmyptWvXqmPHjqpbt66jcwIAAAB4B6xdu1aff/659u3bp9KlS1tO8Jw9e1Y9evTQ119/rT/++EO1atVShw4dFBkZqQ4dOkiSNm3apPnz52v//v0aM2aMZZ8HDhzQvHnzNHfuXDk5OenChQuqXLmytm3bpoIFC+qrr76SyWTSpk2bNHPmTC1fvlyLFy+W9HeheeTIES1btkybNm3S9evXNX78eI0fP17vvfeeRo8e/X+6oJNiMU9dmzZt1LBhQx05ckTBwcHy8vJSvnz5lCxZMkfmA4D/jOz9o+I7At5BlW8Y+v31P2FvfAcAIEnKly+fPv74Y0lSYGCgZsyYIUlas2aNSpYsqVKlSkmSGjRooBw5cujy5cs6fPiwJkyYoCRJkihJkiTq1KmTevbsqe7du0uSihQpYjWGh8lkUmBgoNzc3HT37l1t375de/bskaenpzw9PdWiRQv9/vvvqlOnjlatWqXvvvvOcvuffvpJz58/f5sPSbwzVNRFRkbK2dlZyZIlszxJly5doqADAAAA/mO8vb0t/3dxcZHZbJYkBQUFKW3atJZ1Tk5Oyp8/vw4fPixPT0+r27333nsKCgpSeHi4JMnHx8fqGF5eXnJzc5Mk3bx5U2azWRUqVLCsj4qKUvLkyW0e98X//1e89Oe/q1evqnnz5po2bZrV8idPnqhatWpq3Lixbt686dCAAAAAAN59adKk0e3bty1/m81m/fTTT0qdOrWePn2q+/fvW9Zdu3ZNyZMnl6urq6S/z8zZ4+PjIxcXF+3evVsHDx7UwYMHtWXLFstonP8+7vHjxzVr1qy4vnvvNLtFXVBQkBo3bqzjx49bVdXS35Vx8+bNdebMGTVo0MDqCQIAAADw31OlShXt2rVLe/bsUVRUlObOnau1a9cqbdq0+vjjjzVgwAA9efJEt2/f1pgxYxQYGGhov+nSpVPBggU1dOhQPXv2TA8fPlTHjh0tc2UHBgZq8uTJCgoKUkhIiIYPH66goCBJkqurqx4/fuyw+/yusHv55bRp0xQVFaUlS5YoY8aMVuuSJk2q7t27q3bt2mrYsKGmT59uuR4WAAAAwOtJyJOCZ86cWSNGjNDAgQN1/fp1+fv76+eff5azs7OGDRumAQMGqFy5cpKkGjVqqFu3bob3Hb3fgIAARUZGqlSpUurTp48kqW3btgoNDdUnn3yiiIgIVa5cWe3bt5ck1apVS71799bVq1fVrl27uL/T7wiTOfoi2H+pXLmyGjRooGbNmr10BxMnTtTKlSu1atUqhwR8E3fvhsR3BEnS3qL54jvCO6Ho3iPxHeGdQZv4B+3iHw835InvCO+M5BWOxXeEd0bRX/PFd4R3xt5mR+I7wjuDdvGPd6Vd+Pgkje8I+A+ze/nlrVu3lD179lfuIG/evLpx40achgIAAAAAGGO3qEuaNKlCQl59puvZs2fy9PSM01AAAAAAAGPsFnU5c+bU5s2bX7mDrVu36oMPPojLTAAAAAAAg+wWdZ999pmWL1+u9evX273x+vXrtXjxYn3yySeOyAYAAAAAeAW7o18GBASoRo0a6tSpk0qVKqWyZcsqQ4YMioyM1LVr17R161bt3LlTZcuWVd26dd9mZgAAAADA/2e3qJOkgQMHKmvWrJo2bZq2bdtmmRTQbDYrderU+vrrr9WkSZOXThYIAAAAAHCclxZ1kvTFF1+oWbNm+vPPP3Xz5k25uLgoffr0+vDDD99GPgAAAADAS7yyqJMkZ2dn5c2bV3nz5nV0HgAAAABALNgdKAUAAAAA8O6jqAMAAACABIyiDgAAAAASMIo6AAAAAEjAYl3U3bx5U0eOHNHTp0/17NkzR2QCAAAAABhkaPRLSdq+fbsGDx6sixcvymQyacGCBZo4caK8vb31ww8/MFcdAAAAAMQDQ2fqdu3apbZt2yp16tT65ptvZDabJUn58uXTwoULNW3aNIeGBAAAAADYZqioGz16tMqXL69ffvlFjRo1shR1LVu2VIsWLbR48WKHhgQAAAAA2GaoqDt9+rRq165tc12JEiV048aNOA0FAAAAADDGUFHn6emphw8f2lx3584dJUqUKC4zAQAAAAAMMlTUlSpVSmPGjNGVK1csy0wmkx49eqSpU6eqRIkSDgsIAAAAALDP0OiX3bp1U/369VWtWjVlzZpVJpNJ/fr10+XLl+Xi4qIuXbo4OicAAAAAwAZDZ+pSp06tJUuWqGXLlnJ3d1emTJkUERGhWrVqacmSJXrvvfccnRMAAAAAYIOhM3UzZsxQmTJl1KlTJ3Xq1MnRmQAAAAAABhk6UzdhwgRdunTJwVEAAAAAALFlqKhLmzatbt686egsAAAAAIBYMnT5ZZ06dTR48GDt379f2bJlU6pUqWJsU69evTgPBwAAAAB4OUNF3eDBgyVJa9eu1dq1a2OsN5lMFHUAAAAAEA8MFXWbNm1ydA4AAAAAwGswVNSlT5/e7rqbN29q3rx5zFUHAAAAAPHAUFFny86dOzV37lxt27ZNUVFRFHUAAAAAEA9iVdQ9evRIixYt0rx583TlyhW5urqqQoUKql27tqPyAQAAAABewlBRd/z4cc2dO1dr1qzRs2fPZDKZ1LJlS7Vs2VJeXl6OzggAAAAAsMNuUff8+XOtXLlSc+fO1V9//aVkyZKpbt26qlixopo2bapSpUpR0AEAAABAPLNb1JUsWVJPnjzRxx9/rOHDh6t8+fJyc3NTSEjI28wHAAAAAHgJJ3srgoOD5evrqwIFCihLlixyc3N7m7kAAAAAAAbYLepWrVqlYsWKaebMmfrkk09Uu3Zt/fbbb5ypAwAAAIB3iN2iLkuWLPrmm2+0fft2DR8+XF5eXurXr58qV64sk8mkkydPKjIy8m1mBQAAAAD8i92iLpqrq6uqVq2qGTNmaOPGjfriiy+UJk0aDRw4UCVKlFC/fv106NCht5EVAAAAAPAvryzqXpQ+fXp17txZW7Zs0c8//6wCBQpo/vz5atSokaPyAQAAAABeIlaTj0czmUwqU6aMypQpo6CgIC1dujSOYwEAAAAAjIjVmTpbUqVKpZYtW8ZFFgAAAABALL1xUQcAAAAAiD8UdQAAAACQgBkq6m7cuKHw8HCb68LCwhj9EgAAAADiiaGirly5cjp58qTNdceOHVPz5s3jNBQAAAAAwBi7o18OGTJEDx8+lCSZzWZNmDBBKVKkiLHdyZMnlTRpUocFBAAAAADYZ7eoy5Qpk1asWCHp7ykMDh8+LFdXV6ttnJyc5OXlpa+++sqxKQEAAAAANtkt6ho0aKAGDRpIkrJnz64pU6YoT548by0YAAAAAODVDE0+furUKUfnAAAAAAC8BkNFnSQdOHBA+/btU3h4uMxmsyQpKipKoaGhOnDggJYvX+6wkAAAAAAA2wwVdbNnz9aAAQMsxdyLnJycVKpUqTgPBgAAAAB4NUNTGsydO1clS5bUvn379MUXX+izzz7TkSNHNGrUKLm7u6tGjRqOzgkAAAAAsMFQUXf16lU1bNhQXl5eypUrlw4fPiwPDw9VrlxZLVq00K+//uronAAAAAAAGwwVdS4uLvL09JT091QHFy9eVEREhCSpcOHCunTpksMCAgAAAADsM1TUZcuWTXv37pUkffDBB4qMjNRff/0lSbp//74iIyPjNFRQUJA+/vhjbdmyRZIUHBys9u3bq2DBgipTpowWLFgQp8cDAAAAgITK0EAp9evX13fffafQ0FB9/fXXKlasmL799lvVqlVL8+bNU+7cueM01HfffaeHDx9a/u7du7c8PT21e/dunT59Wq1atVLu3LmVPXv2OD0uAAAAACQ0hs7U1a5dW3369JHJZJIk/fDDD5KkYcOGSfq7CIsrv/32mxIlSqR06dJJkp48eaKNGzeqY8eOcnd3V548eVS9enXO1gEAAACAYjFPXf369S3/z5Ahg1atWqX79+/L29s7zsJcunRJM2bM0Pz581W7dm1J0uXLl+Xi4qKMGTNatvP19dX69etfub8UKTzl4uIcZ/leV/b+UfEd4Z3g45M0viPgHUS7+EfRG4Z+Z/tPOE+7gA28X8AW2gUQi6IuWkREhKKi/i5SkiRJoufPn0uS3Nzc3ihIRESEevTooe+++07Jkye3LH/69Kk8PDystvXw8NCzZ89euc8HD56+USbErbt3Q+I7At5BtAvYQruALbQL2PKutAuKS8QnQ0VdUFCQ+vTpo927d9sspkwmk06cOPFGQSZMmKAPP/xQpUuXtlqeKFGiGMd89uyZZTROAAAAAPgvM1TU9e/fX9u2bVOVKlWUMWNGOTnF/SVCq1ev1t27d7V69WpJ0uPHj9W1a1e1bNlSERERunHjht577z1J0sWLF5U1a9Y4zwAAAAAACY2hom7nzp36+uuv1aRJE4cFWbt2rdXfAQEB6t27t8qWLatTp05p+PDh+vHHH3X27FmtXLlSkydPdlgWAAAAAEgoDJ1yc3Jykp+fn6Oz2NW/f39FRESodOnS6tixo3r06KG8efPGWx4AAAAAeFcYOlNXunRprVu3TkWKFHF0HovNmzdb/p88eXKNHj36rR0bAAAAABIKu0Xd77//bvm/r6+vJk6cqLt376pgwYJKlChRjO3r1avnmIQAAAAAALvsFnV9+vSJsWzDhg3asGFDjOUmk4miDgAAAADigd2ibtOmTW8zBwAAAADgNdgt6g4cOKDSpUsrRYoUbzMPAAAAACAW7I5++c033+jq1atvMwsAAAAAIJbsFnVms/lt5gAAAAAAvAZD89QBAAAAAN5NL52nbtu2bbpw4YKhHX3yySdxkQcAAAAAEAsvLerGjx9vaCcmk4miDgAAAADiwUuLupEjR8rf3/9tZQEAAAAAxNJLi7r06dMrc+bMbysLAAAAACCWGCgFAAAAABIwijoAAAAASMDsFnUzZ85UlixZ3mYWAAAAAEAs2e1T99FHH73NHAAAAACA18DllwAAAACQgFHUAQAAAEACRlEHAAAAAAnYaxd1YWFhun37dlxmAQAAAADEkqGiLjw8XKNGjdLSpUslSbt27VKxYsVUpkwZNW7cWA8fPnRgRAAAAACAPYaKurFjx2rKlCl68uSJJGnQoEFKmTKlevbsqevXr2vEiBEODQkAAAAAsM1QUbd69Wp17dpVjRo10rlz53Tu3Dm1adNGzZo1U+fOnbV582ZH5wQAAAAA2GCoqLt9+7by5s0rSdq6datMJpNKliwpSUqXLp1CQkIclxAAAAAAYJehoi5VqlS6du2aJGnz5s3KmjWrfHx8JElHjhxR2rRpHZcQAAAAAGCXi5GNypUrp0GDBmnFihU6dOiQunXrJkkaMmSIZs+erZYtWzo0ZEJX+QYzR0jS3vgOAAAAAPwfZKio++qrr/T8+XMdPHhQjRo1UvPmzSVJ+/btU7169dS+fXuHhgQAAAAA2GaoqHNzc1O/fv1iLF+0aJFMJlOchwIAAAAAGGOoqIt27Ngx7dixQ7dv31abNm104cIF5ciRQ97e3o7KBwAAAAB4CUNFXUREhL7++mutWrXKcmauXr16mjZtmi5cuKA5c+YoQ4YMDg0KAAAAAIjJ0Age48eP18aNGzVkyBDt3btXZrNZkvTtt9/K2dlZY8aMcWhIAAAAAIBthoq6ZcuWqWPHjqpZs6aSJEliWZ4tWzb973//0549exwWEAAAAABgn6Gi7u7du8qRI4fNdenSpdPDhw/jMhMAAAAAwCBDRV2GDBm0d6/tWcYOHz5MfzoAAAAAiCeGBkqpV6+ehg0bJldXV5UrV06SFBwcrKVLl2rq1Klq06aNQ0MCAAAAAGwzVNR9/vnnunbtmsaPH6/x48dLklq0aCGz2axatWqpZcuWDg0JAAAAALDN8Dx1vXr1UtOmTbVnzx49ePBASZMmVZEiRZQ1a1ZH5gMAAAAAvESsJh/PlCmTMmXKJEkKCwtjgBQAAAAAiGeGBkoJDw/XqFGjtHTpUknSrl27VKxYMZUpU0aNGzemuAMAAACAeGKoqBs7dqymTJmiJ0+eSJIGDRqklClTqmfPnrp+/bpGjBjh0JAAAAAAANsMFXWrV69W165d1ahRI507d07nzp1TmzZt1KxZM3Xu3FmbN292dE4AAAAAgA2Girrbt28rb968kqStW7fKZDKpZMmSkv6efDwkJMRxCQEAAAAAdhkq6lKlSqVr165JkjZv3qysWbPKx8dHknTkyBGlTZvWcQkBAAAAAHYZKurKlSunQYMGqUWLFjp06JBq1KghSRoyZIjGjh2rqlWrOjQkAAAAAMA2Q1MafPXVV3r+/LkOHjyoRo0aqXnz5pKkffv2qV69emrfvr1DQwIAAAAAbDNU1Lm5ualfv34xli9atEgmkynOQwEAAAAAjInV5ON37txRaGiooqKiYqzz9fWNs1AAAAAAAGMMFXUXL15U9+7ddeLEiRjrzGazTCaTTp48GefhAAAAAAAvZ6ioGzBggK5du6YOHToobdq0cnIyNL4KAAAAAMDBDBV1Bw8eVL9+/SyjXgIAAAAA3g2GTrklSpRIKVOmdHQWAAAAAEAsGSrqqlSposWLFzs6CwAAAAAglgxdfpklSxaNHj1an376qfLly6dEiRJZrTeZTOrSpYtDAgIAAAAA7DNU1PXv31+SdPz4cR0/fjzGeoo6AAAAAIgfhoq6U6dOOToHAAAAAOA1xGrycUk6f/68QkJC5O3trUyZMjkiEwAAAADAIMNF3erVqzV48GDdvXvXsix16tTq0aOHqlev7pBwAAAAAICXM1TUbd++Xd26dVPevHnVtm1b+fj46Pbt21qxYoV69OghLy8vlSxZ0tFZAQAAAAD/YqiomzBhgsqWLasJEyZYLW/UqJHatWunSZMmUdQBAAAAQDwwNE/dyZMnVa9ePZvr6tWrpxMnTsRpKAAAAACAMYaKOi8vLz19+tTmuidPnsjZ2TlOQwEAAAAAjDFU1BUsWFATJ07Uo0ePrJYHBwdr4sSJKlSokEPCAQAAAABezlCfuq5du6p27doqX768SpYsqVSpUikoKEg7duxQZGSkRowY4eicAAAAAAAbDBV1GTNm1Lx58zRu3Djt3btXwcHB8vLyUokSJdS+fXtlyZLF0TkBAAAAADYYnqcuS5YsGjlypCOzAAAAAABiyXBRJ0mbNm3SgQMHFBwcrJQpU6p48eL6+OOPHZUNAAAAAPAKhoq64OBgtWzZUsePH5eLi4uSJ0+uBw8eaNq0aSpevLgmTJggNzc3R2cFAAAAAPyLodEvBw0apMuXL2vMmDE6fvy4du7cqePHj2vEiBE6evQol2UCAAAAQDwxVNRt3bpV3bp1U8WKFWUymf6+oZOTqlSpos6dO2vlypUODQkAAAAAsM1QURcREaE0adLYXJcpUyY9fvw4TkMBAAAAAIwxVNRVrVpV06dPV3h4eIx1CxYsUOXKleM8GAAAAADg1QwNlJI5c2atXbtWVapUUbVq1ZQmTRrdv39fmzZt0unTp9WwYUPLBOQmk0ldunRxaGgAAAAAwN8MFXWDBw+WJD169EiTJk2KsX727NmW/1PUAQAAAMDbY6ioO3XqlKNzAAAAAABeg6E+dbaEhYXp9u3bcZkFAAAAABBLhoq68PBwjRo1SkuXLpUk7dq1S8WKFVOZMmXUuHFjPXz40IERAQAAAAD2GCrqxo4dqylTpujJkyeS/p6MPGXKlOrZs6euX79uGSQFAAAAAPB2GSrqVq9era5du6pRo0Y6d+6czp07pzZt2uj/tXfvUVXWiRrHn61yEa+gNJKKGXrEFAXFcUyNCrQcVFJBMkMlTRmY02ReMS0mm1LTNJTsQlpeBnPMS4k5iWRppg2ZMRgZeZnwiiSYqYDAPn903Edig6/KdrNP389aruV+b/vZl8Xi4fe+72/06NF68sknlZ6ebuucAAAAAAArDJW606dPq2vXrpKkHTt2yGQyqW/fvpIkLy8vnT9/3nYJAQAAAABVMlTqmjdvrmPHjkmS0tPT1a5dO3l6ekqS9u/frxYtWtguIQAAAACgSoZKXXBwsF588UWNHTtW+/bt0+DBgyVJc+fO1eLFi/XHP/7RpiEBAAAAANYZmqdu6tSpKikpUUZGhkaOHKno6GhJ0t69exUZGam4uDibhgQAAAAAWGeo1Dk7O+u5556rtPy9996TyWSq8VAAAAAAAGMMlborMjMztXPnTp0+fVoxMTE6fPiw7rrrLnl4eNgqHwAAAACgGoZKXWlpqaZNm6bU1FTLyFxkZKTeeustHT58WKtXr1arVq1sGhQAAAAAUJmhG6UkJSUpLS1Nc+fO1Z49e2Q2myVJM2bMUN26dZWYmGjTkAAAAAAA6wyVuk2bNumJJ55QWFiYGjZsaFnevn17/fd//7c+//xzmwUEAAAAAFTNUKk7c+aM7rrrLqvrvLy8VFhYWJOZAAAAAAAGGSp1rVq10p49e6yu++qrr7ieDgAAAADsxNCNUiIjIzV//nw5OTkpODhYknTu3Dlt3LhRycnJiomJsWlIAAAAAIB1hkrdmDFjdOzYMSUlJSkpKUmSNHbsWJnNZg0ZMkTjxo2zaUgAAAAAgHWG56mbOXOmRo0apc8//1wFBQVq1KiRevbsqXbt2tkyHwAAAACgGtc1+bi3t7e8vb0rLU9LS1NISEiNhQIAAAAAGFNtqfv++++1ceNGmUwmDRw4UB06dKiw/ocfftDs2bO1a9cuZWdn2zQoAAAAAKCyKkvd559/rgkTJqikpESS9Pbbb+vtt99W9+7dVVpaqqVLlyo5OVnFxcXq37//LQsMAAAAAPg/VU5psHTpUnl5eSk1NVU7d+5U9+7dtXDhQhUUFOiRRx5RUlKSWrRooeTkZCUmJt7KzAAAAACA/1VlqTt48KDGjx8vHx8feXp6avLkydq/f7+efPJJffPNN/rTn/6kDz74QH369LmVeQEAAAAAV6ny9Muff/5Zbdq0sTz28fFRaWmpvv32W61atUr+/v63Ih8AAAAAoBpVjtSVlZXJ2dnZ8vjK/ydPnkyhAwAAAIBaospSV5WOHTvaIgcAAAAA4AZcd6kzmUy2yAEAAAAAuAHVzlOXlpZmmX+uvLxcJpNJ27ZtU1ZWVqVtIyMjbZMQAAAAAFClakvdG2+8UWnZa6+9VmmZyWSi1AEAAACAHVRZ6rZv334rcwAAAAAAbkCVpa5ly5a3MgcAAAAA4AZc941SAAAAAAC1B6UOAAAAABwYpQ4AAAAAHFiVpe6HH35QeXn5rcwCAAAAALhOVZa6iIgI7du3T5IUHx+v3NzcWxYKAAAAAGBMlaWuqKhIeXl5kqQNGzaooKDgloUCAAAAABhT5ZQGfn5+mjp1qubPny9JiouLk7Ozs9VtTSaT0tLSbJMQAAAAAFClKkvdvHnz9NZbb6mwsFAnT55U+/bt1bRp01sYDQAAAABwLVWWuttvv12zZs2SJH311VeaOnWqfH19b1kwAAAAAMC1VVnqrpaeni5J+umnn7R//36dP39e7u7u6tq1qxo0aGDTgAAAAACAqhkqdZKUnJyspKQkFRUVyWw2S5JcXFwUFxen8ePH10iYjIwMzZ07V4cPH5a7u7vGjRunhx9+WOfOndOMGTO0Z88eNWrUSHFxcYqIiKiR5wQAAAAAR2ao1G3atEnz589XaGiowsLCdNttt+n06dPatGmTFi5cqBYtWmjw4ME3FeTcuXOKjY3VzJkzNXDgQGVnZys6Olre3t5as2aN3NzctHv3bh08eFCPP/64/Pz8OB0UAAAAwG+eoVK3fPlyDR06VC+88IJlma+vr4KCglS/fn298847N13qTpw4oaCgIMtxOnXqpJ49e2rfvn1KS0vTP//5T7m4uKhLly4aOHCg/vGPf1iu+QMAAACA36oq56m72uHDh/XHP/7R6roBAwbo0KFDNx2kY8eOeumllyyPz507p4yMDElSvXr11Lp1a8u6tm3bKicn56afEwAAAAAcnaGRuubNmys/P9/qury8PLm6utZoqPPnzysmJsYyWrdixYoK611dXVVUVHTN47i7u6levbo1mg03ztOzkb0j1Bq+s8vtHaHW4HsBa/hewBq+F7CG7wVgsNT17t1biYmJCggIUJs2bSzLjx49qiVLlqhPnz41Fig3N1cxMTFq3bq1Fi1apEOHDlUqcEVFRXJzc7vmsQoKLtZYLty8M2fO2zsCaiG+F7CG7wWs4XsBa2rL94JyCXsyVOqefPJJffrppwoNDVXnzp0tI3dZWVlq1qyZJk2aVCNhDhw4oHHjxmnw4MGaNm2a6tSpozZt2qi0tFQnTpzQ7bffLkk6cuSI2rVrVyPPCQAAAACOzNA1dc2aNdOGDRs0ZswYlZeXKycnR+Xl5YqOjtb69evl5eV100Hy8/M1btw4RUdHKz4+XnXq/BKtYcOGCg4O1oIFC3Tp0iVlZmZq8+bNGjRo0E0/JwAAAAA4OsPz1Hl4eGjy5Mk2C7Ju3TqdPXtWS5cu1dKlSy3LR40apdmzZ+vZZ59VUFCQ3NzcNGXKFHXt2tVmWQAAAADAURgudbYWExOjmJiYKte/8sortzANAAAAADgGQ6dfAgAAAABqJ0odAAAAADgwSh0AAAAAODBDpW7jxo0qKCiwuu7MmTN68803azQUAAAAAMAYQ6UuPj5eubm5VtdlZ2crMTGxRkMBAAAAAIyp8u6Xjz/+uA4fPixJMpvNiouLk7Ozc6XtfvzxR7Vu3dp2CQEAAAAAVaqy1I0fP14pKSmSpOPHj6t9+/Zq2rRphW3q1KmjJk2aKCIiwqYhAQAAAADWVVnqevTooR49ekj65bq5p59+Wj4+PrcsGAAAAADg2gxNPr5y5Upb5wAAAAAA3ABDpa68vFwpKSlKT0/XxYsXZTabK22zZs2aGg8HAAAAAKieoVK3YMECvfXWW2rVqpVatGghk8lk61wAAAAAAAMMlbpNmzZp1KhRmjFjhq3zAAAAAACug6F56s6fP6+QkBBbZwEAAAAAXCdDpc7Pz09ZWVm2zgIAAAAAuE6GTr+cMWOG4uLi5OLiom7dusnV1bXSNm3btq3xcAAAAACA6hkqdUOHDpUkzZ49u8qbpGRnZ9dcKgAAAACAIYZK3QsvvMAdLwEAAACgFrqukToAAAAAQO1iqNRJktls1ocffqhdu3YpLy9PM2fO1Ndff63OnTvLx8fHlhkBAAAAAFUwVOouXLigCRMmKCMjQ+7u7iosLNSFCxe0adMmzZ49W6tWrZKvr6+tswIAAAAAfsXQlAYLFy5UTk6OVq1apZ07d8psNkuSXnrpJbVs2VKLFy+2aUgAAAAAgHWGSt3WrVs1ceJEBQYGVrhhSrNmzTRhwgR99dVXNgsIAAAAAKiaoVL3008/qXXr1lbXubu768KFCzUaCgAAAABgjKFSd+edd2rbtm1W1+3atYuJxwEAAADATgzdKCU6OlrTpk1TcXGxgoODZTKZlJOTox07dmjFihV65plnbJ0TAAAAAGCFoVIXFhams2fPKjExURs3bpTZbNb06dPl7OysCRMmKCIiwtY5AQAAAABWGJ6nLjo6WhEREdq/f78KCgrUuHFj+fv7q0mTJrbMBwAAAACohqFr6iTp0KFD+uCDD9SnTx8NGjRIt99+uxYvXqzc3Fxb5gMAAAAAVMNQqdu3b5/Cw8P1zjvvWJadP39eH374oYYNG6Zvv/3WZgEBAAAAAFUzPPl4t27dtHHjRsuybt26afv27fLz89P8+fNtlQ8AAAAAUA1Dpe6bb77R2LFj5erqWmG5q6urxowZo8zMTJuEAwAAAABUz1Cpc3Jy0tmzZ62uO3/+vMxmc42GAgAAAAAYY6jU/eEPf9CSJUt06tSpCsvz8vK0dOlS9erVyybhAAAAAADVMzSlwaRJkxQREaH+/furU6dOat68uc6ePausrCw1aNBASUlJts4JAAAAALDC0Ehd69attXnzZkVFRclsNuu7775TcXGxRowYoQ0bNsjb29vWOQEAAAAAVhgaqVu+fLnuvfdeTZkyxdZ5AAAAAADXwdBI3auvvqqjR4/aOAoAAAAA4HoZKnUtWrTQyZMnbZ0FAAAAAHCdDJ1+OWzYMM2ZM0dffPGF2rdvr+bNm1faJjIyssbDAQAAAACqZ6jUzZkzR5K0detWbd26tdJ6k8lEqQMAAAAAOzBU6rZv327rHAAAAACAG2Co1LVs2dLWOQAAAAAAN8BQqZOk06dPa+nSpdq1a5fy8vKUkpKiLVu2yNfXV4MGDbJlRgAAAABAFQyVuv/85z8aMWKEysrK1LNnTx0/flySlJeXp2XLlql+/foKCQmxaVAAAAAAQGWGSt28efPk6emp1atXy9XVVZ07d5YkvfTSS7p06ZKSk5MpdQAAAABgB4bmqduzZ49iYmLUsGFDmUymCuuGDx+unJwcm4QDAAAAAFTPUKkrLy+Xi4uL1XVlZWUym801GgoAAAAAYIyhUufv76933nlHZWVllmVXRuw2bNigrl272iYdAAAAAKBahq6pmzhxoh599FGFhobqnnvukclk0vr16zV37lx9+eWXevvtt20cEwAAAABgjaGRui5duuidd95Rs2bNtHr1apnNZq1evVoXLlzQm2++qcDAQFvnBAAAAABYYXieuoCAAK1evVrFxcUqLCxUo0aN5ObmZstsAAAAAIBrqLbUlZSUKD09XcePH5e3t7eCgoLk4uKi3/3ud7cqHwAAAACgGlWWutOnT2vUqFH64YcfLHe3bNOmjZKSktSuXbtbFhAAAAAAULUqr6lbuHChCgsLNWfOHKWmpioxMVGlpaV69tlnb2U+AAAAAEA1qhyp++yzzzRp0iSFhYVJknx8fOTi4qI//elP+vnnn9WwYcNbFhIAAAAAYF2VI3UFBQXy8fGpsKxr164qLy/XqVOnbB4MAAAAAHBtVZa60tJSOTk5VVjWqFEjSb/cQAUAAAAAYH+G5qn7tSs3TgEAAAAA2NcNlTqTyVTTOQAAAAAAN6DaeeqefvppNWjQoNLy6dOnV5p4fM2aNTWbDAAAAABwTVWWuh49elzXcgAAAADArVdlqVu5cuWtzAEAAAAAuAE3dE0dAAAAAKB2oNQBAAAAgAOj1AEAAACAA6PUAQAAAIADo9QBAAAAgAOj1AEAAACAA6PUAQAAAIADo9QBAAAAgAOj1AEAAACAA6PUAQAAAIADo9QBAAAAgAOj1AEAAACAA6PUAQAAAIADo9QBAAAAgAOj1AEAAACAA6PUAQAAAIADo9QBAAAAgAOj1AEAAACAA6PUAQAAAIADo9QBAAAAgAOj1AEAAACAA6PUAQAAAIADo9QBAAAAgAOj1AEAAACAA6PUAQAAAIADo9QBAAAAgAOj1AEAAACAA6PUAQAAAIADo9QBAAAAgAOj1AEAAACAA6PUAQAAAIADo9QBAAAAgAOj1AEAAACAA6PUAQAAAIADo9QBAAAAgAOj1AEAAACAA6PUAQAAAIADo9QBAAAAgAOj1AEAAACAA6PUAQAAAIADo9QBAAAAgAOj1AEAAACAA6PUAQAAAIADo9QBAAAAgAOj1AEAAACAA6PUAQAAAIADo9QBAAAAgAOj1AEAAACAA6PUAQAAAIADo9QBAAAAgAOj1AEAAACAA6PUAQAAAIADc5hS98033yg8PFz+/v4KCwvT/v377R0JAAAAAOzOIUpdcXGxYmJiNHToUP3rX/9SVFSU/vznP6ukpMTe0QAAAADArhyi1O3Zs0d16tTRI488IicnJ4WHh8vd3V0ff/yxvaMBAAAAgF05RKk7cuSIfHx8Kixr27atcnJy7JQIAAAAAGqHevYOYMTFixdVv379CstcXV1VVFRU7X6eno1sGcuwQ5MP2TsCahnPR47YOwJqIX5WwBq+F7CG7wWAqznESF39+vUrFbiioiK5ubnZKREAAAAA1A4OUeruvPNOHTlScWTjyJEjateunZ0SAQAAAEDt4BClrlevXiopKdHKlSt1+fJlrVu3Tvn5+erTp4+9owEAAACAXZnMZrPZ3iGM+Pbbb5WQkKCDBw+qTZs2SkhIkL+/v71jAQAAAIBdOUypAwAAAABU5hCnXwIAAAAArKPUAQAAAIADo9T9RmRmZnJjGVhkZGQoIiJC3bt3V0hIiNasWWPvSKgFtmzZogEDBiggIEChoaFKS0uzdyTUEvn5+erVq5c+/vhje0dBLZGcnKzOnTsrICDA8i8jI8PesYDfLIeYfBw3zmw267333tOcOXNUt25de8dBLXDu3DnFxsZq5syZGjhwoLKzsxUdHS1vb2/dfffd9o4HOzly5IhmzJihZcuWqVu3btq9e7fGjx+vTz/9VB4eHvaOBzt7+umnVVhYaO8YqEWys7M1ceJEjR071t5RAIiRuv/3XnvtNa1YsUIxMTH2joJa4sSJEwoKCtLgwYNVp04dderUST179tS+ffvsHQ121LZtW3322Wfq1q2bLly4oLy8PDVo0EDOzs72jgY7S0lJUf369eXl5WXvKKhFsrOz1bFjR3vHAPC/KHX/zw0bNkybNm2Sn5+fvaOglujYsaNeeukly+Nz584pIyNDvr6+dkyF2qBBgwbKzc1VYGCgpk+frokTJ6phw4b2jgU7Onr0qJYvX66EhAR7R0EtcunSJR09elQrVqxQ7969NWDAAK1bt87esYDfNE6//H/utttus3cE1GLnz59XTEyMOnXqpPvvv9/ecVALeHl5KTMzUxkZGYqNjVWbNm3Uq1cve8eCHZSWlmrKlCl6+umn1bRpU3vHQS2Sn5+vbt26acSIEUpMTFRmZqZiYmLk6empoKAge8cDfpMYqQN+o3Jzc/Xwww+rSZMmWrJkierU4ccBpHr16snJyUm9evVS//79tX37dntHgp28+uqr6tixI7+ko5LWrVtr1apVCgoKkrOzswIDAxUWFsbPC8CO+C0O+A06cOCAhg8frj59+ujVV1+Vq6urvSPBzj755BONGTOmwrLLly+rUaNG9gkEu9uyZYtSU1MVGBiowMBAnThxQk899ZTeeOMNe0eDnR04cKDS96C4uJhrcAE74vRL4DcmPz9f48aNU3R0tMaPH2/vOKgl7rrrLmVlZWnjxo0aPHiwdu7cqU8++URr1661dzTYydatWys8vv/++zVr1izdd999dkqE2sLNzU1LliyRt7e3+vfvr7179yo1NVWrVq2ydzTgN4uROuA3Zt26dTp79qyWLl1aYX6hhQsX2jsa7MjT09Nyt9zAwEC98sorSkpKko+Pj72jAahl2rZtq0WLFikpKUndunVTQkKCXnzxRXXq1Mne0YDfLJPZbDbbOwQAAAAA4MYwUgcAAAAADoxSBwAAAAAOjFIHAAAAAA6MUgcAAAAADoxSBwAAAAAOjFIHAAAAAA6MUgfAYfz8889atmyZhg4dqu7du8vf31/h4eF69913VV5eXmHb+++/X1FRUTX6/D/++KMuXrxoeRwVFaX777+/Rp/j559/1tmzZ6vdZv369erQoYM6dOigjz76qMrtnn/+eXXo0KFGM06fPl0dOnSwyX5XXtdf/vKXKrexxed6Lbb4nAEAqEmUOgAO4fDhwxo2bJhefvlldejQQU899ZSeeOIJubi46JlnntHUqVNly2k3P/nkEz344IPXLFw3IysrSwMGDFBOTo7hfbZv317luvT09JqIdctt3bpVn376qb1jAADgMOrZOwAAXEtxcbFiY2NVWFiodevWydfX17Luscce01//+lf9/e9/V5cuXTRq1CibZMjMzNRPP/1kk2Nf8d133ykvL8/w9q1atdKOHTtUVlamunXrVlh34MABHT9+XB4eHjUd85Z47rnnlJqaKhcXF3tHAQCg1mOkDkCt9/e//11HjhxRfHx8hUJ3xbRp09SkSROtWbPGDunsJzg4WIWFhfryyy8rrdu2bZu8vb3Vrl07OyS7Offdd59yc3O1dOlSe0cBAMAhUOoA1Hqpqalyc3NTaGio1fWurq5au3atNm7cWGndBx98oNDQUHXu3FkPPPCAUlJSKqw3m81KSUlReHi4AgIC5OfnpwcffFBvvPGG5XTO6dOna8mSJZJ+KVK/vqYrPT1doaGh8vPz06BBg/T+++9XynHw4EHFxsYqMDBQXbp00fDhw5WWlmZZv3jxYsXHx0uSRo0aZegart69e6t+/fpWT7NMS0tTv379rO53/PhxTZkyRX/4wx/k5+enwYMHa+3atZW2y8rK0mOPPaaAgAD17dtXK1assHq8U6dOaerUqZbjPfTQQ1bfA6NGjx4tX19fJScn6/Dhw9VuW9W1er9ePn36dA0cOFBffvmlIiMj1aVLFwUHB2vDhg26fPmyFixYoN69e+v3v/+9nnzySRUUFFQ6ppHP+fvvv1dcXJwCAwPVtWtXPfzww9q5c2eFbaKiojR27FgtXLhQAQEB6tWrlw4ePGj07QEAoBJKHYBazWw2Kzs7W507d5aTk1OV291xxx1ydnausOzf//63nn/+eT344IOKj4+Xs7OzEhISKpSpRYsWKSEhQe3atVN8fLyeeuopubi4aMGCBZaSGBkZaSlI8fHxiomJsex/5swZPfHEE+rZs6emTp0qFxcXTZkyRevXr7dsk5mZqcjISGVmZio6OlpPPfWULl++rLi4OK1evVqS1K9fP0VGRkqSYmJiNGPGjGu+N66ururdu3el6+qOHj2qnJwcq6UuNzdX4eHh2r59u4YPH66pU6eqSZMmmjVrlubNm2fZLicnR1FRUTp06JBiY2M1YsQIJSUlVXjvJOn06dOKiIjQ7t27FRUVpWnTpsnd3V1TpkxRcnLyNV+DNXXq1NFf//pXlZaWKiEh4YaOYc2ZM2cUExOj7t27a9q0aapXr55mzJihCRMmaM+ePYqNjdXAgQP14YcfVngvrux7rc/54MGDioyM1Pfff68JEyZo4sSJKi0t1fjx47Vly5YKx9u3b59SU1M1ZcoUDRkyxCFHVAEAtQfX1AGo1QoKClRaWipPT8/r3reoqEirV69Wp06dJEn33nuvgoOD9dFHHykkJESXL1/WqlWrFBoaqjlz5lj2i4iIUK9evfTPf/5TQ4YMUUBAgDp06KBt27YpJCRErVq1smxbUlKiZ555RiNHjpT0SwEMCwvTggULNHjwYNWrV0/PP/+8TCaT1q1bpxYtWkiSRowYoREjRmjevHkaMGCAfH195e/vr3fffVd33323evbsaeg1hoSEKC0tTTk5OWrfvr2kX0699PT0lL+/f6XtX375Zcu1iVfel5EjRyo2NlbLli3TkCFD1L59ey1evFiStGbNGnl5eUmSHnjgAT300EMVjrdw4UKVlJTogw8+0G233SZJevTRRzVp0iS98sorGjJkiJo1a2botVzN399fw4cP17vvvqtNmzYpLCzsuo/xa4WFhZo1a5YeffRRSb9ckzh+/HgdPXpUW7dutfxRIDs7W7t27aqwr9HP2cPDQxs2bJCbm5ukX96L0aNH629/+5tCQkIsz3Hx4kW99tprhj9nAACqw0gdgFqtTp1ffkyVlZVd97533HGHpbhIUsuWLeXh4aH8/HxJkpOTk3bv3q3nnnuuwn4FBQVq2LBhhekLqtK4cWPLCJskOTs7KzIyUvn5+crKylJ+fr6+/vprhYWFWQqdJLm4uGjs2LEqKirS7t27r/u1XXHvvfeqbt26FUbr0tLSFBISIpPJVGHbsrIy7dixQ3369KnwvtSpU0cxMTEym81KT09XeXm5du7cqaCgIEuhkyQfHx/16dPH8ri8vFxpaWkKDAxUvXr1dPbsWcu//v37q6SkRJ999tkNv7ZJkybJw8NDc+fOrbGb1Fw9ennHHXdIkvr27VthlLdVq1Y6c+ZMhf2u9TkXFBToiy++UFBQkIqKiizvw08//aR+/fopPz9f//73vy37u7q6qkePHjXymgAAYKQOQK3WpEkTOTk53dBUAtZGiFxdXXX58mXLYycnJ+3YsUPbt2/XkSNH9J///Efnzp2TJENTJLRu3Vr16tWrtEz65dq1K8Wqbdu2lfb18fGRJJ04ccLgK6rM3d1d3bt3V3p6umJiYpSXl6evv/7a6lxvBQUFunjxYrVZjh8/rsLCQl28eFHe3t6Vtrvzzjst1/AVFBTo/PnzSktLq3Ra5hUnT5684dfWpEkTTZs2TdOmTdP8+fMrle8bcfV34sodQ3/9Palbt26lz/5an/OVPz6sXLlSK1eutPrcV78XTZs2tewDAMDNotQBqNVMJpMCAgKUlZWl0tLSSr9YX7Fw4ULl5uYqPj7ecqrmtX5pNpvNmjJlijZv3qzu3bsrICBAkZGR6tGjh0aPHm04n7XjXnn+6orhlQnTq7tW0Ijg4GDNmTNHeXl5SktLU+PGjfX73/++ylzVZbl6xKq4uLjK7aT/Gz194IEH9PDDD1s97pXic6Meeughvffee/rHP/6hYcOGGd6vqpFda98fa5+hkW2u/pyvPN/IkSMVEhJi9RhXXzf36ykoAAC4GZQ6ALVev3799MUXX2jLli0aPHhwpfVFRUVat26dysrK1LRpU8PHzcjI0ObNmxUbG1thZKu0tFSFhYWGCsnJkydlNpsr/NJ/9OhRSZK3t7flOjNrd3E8cuSIJFU4LfNGhISE6MUXX7SMON53331Wy4uHh4fc3NyumcXd3V0NGza0vI6rHTt2rMLx6tevr9LSUt19990Vtjtx4oS++eYb1a9f/6ZemyQlJCQoLCxMzz77bKWydqW4l5SUVCikV06xrSnX+pyv/CGhbt26ld6L77//XseOHauR9wIAAGs49wNArRcZGamWLVtq7ty5+u677yqsKysrU0JCgvLz8/X4449f16hXYWGhJFW68+DatWt16dIllZaWWpZdKQ+/Hu368ccfK1zPdunSJaWkpKhly5bq2LGjPD091blzZ73//vs6deqUZbuSkhItX75czs7O6t27d4XnuHo0zIhWrVrJ19dXmzdv1t69e6ucyqBu3brq27evPvvsMx04cMCy3Gw2680335TJZNK9994rk8mkfv36aefOnRXe72PHjmnHjh2Wx/Xq1dM999yjTz75RN9++22F55ozZ47i4uKsTg1wvXx8fPTYY48pOzu7wnsoyVKmsrOzLctOnTqlr7766qaf92rX+pxvu+02de7cWRs2bNDp06ct212+fFkzZszQE088UeH7BABATWKkDkCt5+LioiVLluixxx5TeHi4Bg0aJD8/PxUWFmrr1q3Kzs7Wgw8+qOjo6Os6bkBAgBo2bKgXX3xRJ06cUOPGjbV3715t2bJFLi4uunDhgmVbDw8PSVJycrLuueceBQcHS/rluq+pU6dq9OjRatq0qd577z2dPHlSSUlJlpI2c+ZMjR49WuHh4RoxYoQaNGig999/XwcOHNDMmTPVuHHjCs+RkpKi/Px8DRo0yPBrCQkJ0ZIlS+Tm5lbhZia/NnnyZO3du1dRUVGKioqSp6entm3bpj179ig6OtpScP/yl79ox44dioqK0pgxY1S3bl2tXLlSDRo0UElJSaXjjRw5UiNHjtTtt9+uHTt26OOPP1ZkZKTljpw3KzY2VqmpqRVGCiVpwIABev311zVx4kSNGTNGxcXFWr16tX73u99ZHWm8UdfzOQ8bNkwjRoxQ06ZNlZqaqq+//lqTJk2Su7t7jeUBAOBqlDoADuGuu+7Spk2b9Pbbb+vTTz/Vli1bZDab1aFDB73wwgsaOnSooWujrta8eXO98cYbmj9/vl599VU5Ozurbdu2evnll5WZmakVK1YoPz9fzZs3V2hoqD766COtX79eX3zxhaXU+fj46NFHH9Urr7yikydP6r/+67/0+uuvq2/fvpbnCQgIUEpKihITE7Vs2TKVl5fL19dXSUlJFa6/6tWrlwYMGKCPP/5Ye/bsUf/+/eXi4mLotVwpdX379pWrq2uV23l7e2vt2rVatGiR1qxZo6KiIvn4+Ohvf/ubwsPDLdt5eXkpJSVF8+bNU3JyspydnRURESFJev311ysdLzExUWvXrtXFixfVunVrxcfHV5qk/Wa4urpq1qxZmjBhQoXlvr6+WrRokZKSkjRv3jx5eXnp8ccfV1FRUaW55m7G9XzOixcv1vLly1VaWqq2bdtqzpw5GjJkSI1lAQDg10xmI7d3AwAAAADUSlxTBwAAAAAOjFIHAAAAAA6MUgcAAAAADoxSBwAAAAAOjFIHAAAAAA6MUgcAAAAADoxSBwAAAAAOjFIHAAAAAA6MUgcAAAAADux/ALiDFq5NYAErAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 864x864 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib import rcParams\n",
    "\n",
    "plt.style.use('seaborn')\n",
    "\n",
    "ax = chatbot_performance_df.plot(kind = 'bar', stacked = True, figsize = (12, 12), fontsize = 13, color = [\"forestgreen\", \"goldenrod\", 'firebrick'])\n",
    "\n",
    "ax.set_xticklabels(labels = [\"1\", \"2\", \"3\", \"4\", \"5\"], rotation = 0)\n",
    "ax.set_xlabel(\"Chatbot Model Number\", fontsize=18)\n",
    "ax.set_ylabel(\"Percent of Responses That Are Correct, Partially Correct, and Incorrect\", fontsize=17)\n",
    "ax.set_title('Stacked Barplot Summarizing Performance Of Coral Reef Fish Chatbots', fontsize = 20)\n",
    "\n",
    "plt.legend(bbox_to_anchor=(1.02, 0.55), loc='upper left', borderaxespad=0, fontsize = 13)\n",
    "\n",
    "plt.show();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a3a024",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
