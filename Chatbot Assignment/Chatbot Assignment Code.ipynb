{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33d6e4ba",
   "metadata": {},
   "source": [
    "# Assignment 4 - Chatbots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad11a284",
   "metadata": {},
   "source": [
    "#### Steve Desilets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa137ac",
   "metadata": {},
   "source": [
    "#### August 26, 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c5a10a",
   "metadata": {},
   "source": [
    "## 1) Chatbot 1 - Sentence-Based Transformer Chatbot That Leverages Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d8d37fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence-transformers in c:\\users\\steve\\anaconda3\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in c:\\users\\steve\\anaconda3\\lib\\site-packages (from sentence-transformers) (4.31.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\steve\\anaconda3\\lib\\site-packages (from sentence-transformers) (4.64.0)\n",
      "Requirement already satisfied: torch>=1.6.0 in c:\\users\\steve\\anaconda3\\lib\\site-packages (from sentence-transformers) (2.0.1)\n",
      "Requirement already satisfied: torchvision in c:\\users\\steve\\anaconda3\\lib\\site-packages (from sentence-transformers) (0.15.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\steve\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.22.4)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\steve\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.0.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\steve\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.7.3)\n",
      "Requirement already satisfied: nltk in c:\\users\\steve\\anaconda3\\lib\\site-packages (from sentence-transformers) (3.7)\n",
      "Requirement already satisfied: sentencepiece in c:\\users\\steve\\anaconda3\\lib\\site-packages (from sentence-transformers) (0.1.99)\n",
      "Requirement already satisfied: huggingface-hub>=0.4.0 in c:\\users\\steve\\anaconda3\\lib\\site-packages (from sentence-transformers) (0.16.4)\n",
      "Requirement already satisfied: filelock in c:\\users\\steve\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (3.6.0)\n",
      "Requirement already satisfied: fsspec in c:\\users\\steve\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2022.2.0)\n",
      "Requirement already satisfied: requests in c:\\users\\steve\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2.27.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\steve\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\steve\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (4.7.1)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\steve\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (21.3)\n",
      "Requirement already satisfied: sympy in c:\\users\\steve\\anaconda3\\lib\\site-packages (from torch>=1.6.0->sentence-transformers) (1.10.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\steve\\anaconda3\\lib\\site-packages (from torch>=1.6.0->sentence-transformers) (2.7.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\steve\\anaconda3\\lib\\site-packages (from torch>=1.6.0->sentence-transformers) (2.11.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\steve\\anaconda3\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\steve\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2022.3.15)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\users\\steve\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.13.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\steve\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.3.2)\n",
      "Requirement already satisfied: click in c:\\users\\steve\\anaconda3\\lib\\site-packages (from nltk->sentence-transformers) (8.0.4)\n",
      "Requirement already satisfied: joblib in c:\\users\\steve\\anaconda3\\lib\\site-packages (from nltk->sentence-transformers) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\steve\\anaconda3\\lib\\site-packages (from scikit-learn->sentence-transformers) (2.2.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\steve\\anaconda3\\lib\\site-packages (from torchvision->sentence-transformers) (9.0.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\steve\\anaconda3\\lib\\site-packages (from packaging>=20.9->huggingface-hub>=0.4.0->sentence-transformers) (3.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\steve\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.6.0->sentence-transformers) (2.0.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\steve\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\steve\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\steve\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\steve\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\steve\\anaconda3\\lib\\site-packages (from sympy->torch>=1.6.0->sentence-transformers) (1.2.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\steve\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\steve\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from collections import Counter\n",
    "from dataclasses import dataclass\n",
    "from timeit import default_timer as timer\n",
    "import random\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize \n",
    "\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "\n",
    "from spacy.matcher import Matcher \n",
    "from spacy.tokens import Span \n",
    "\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "!pip install sentence-transformers\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "from typing import List, Callable, Dict, Tuple, Set\n",
    "\n",
    "pd.set_option('max_colwidth', 600)\n",
    "pd.set_option('display.max_rows', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb05f650",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Sentence Transformer model optimized for  sentence cosine similarity calculations\n",
    "\n",
    "#The models below fully downloaded in Google Colab. This is the version of the google colab notebook but \n",
    "#it was open in anoconda to be saved as pdf and the download graphics did not transfer properly so \n",
    "#it seems like it didn't download. However, it did in the orignal google colab notebook, where all the\n",
    "#analysis was run.\n",
    "\n",
    "model = SentenceTransformer('multi-qa-MiniLM-L6-cos-v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e4dd4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "041fbf54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Only run this once, they will be downloaded.\n",
    "nltk.download('stopwords',quiet=True)\n",
    "nltk.download('wordnet',quiet=True)\n",
    "nltk.download('punkt',quiet=True)\n",
    "nltk.download('omw-1.4',quiet=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e144aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in data\n",
    "CORPUS_PATH = 'C:/Users/steve/OneDrive/Desktop/Github/Natural_Language_Processing/Chatbot Assignment/coral_reef_fish.txt'\n",
    "f=open(CORPUS_PATH,'r',errors = 'ignore')\n",
    "raw=f.read()\n",
    "raw=raw.lower()# converts to lowercase\n",
    "\n",
    "#create list of sentences and words\n",
    "sent_tokens = nltk.sent_tokenize(raw)# converts to list of sentences \n",
    "word_tokens = nltk.word_tokenize(raw)# converts to list of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d75ac3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create greetings and greetings function\n",
    "\n",
    "GREETING_INPUTS = (\"hello\", \"hi\", \"greetings\", \"sup\", \"what's up\",\"hey\",)\n",
    "GREETING_RESPONSES = [\"Hello\"]\n",
    "\n",
    "\n",
    "# Checking for greetings\n",
    "def greeting(sentence):\n",
    "    \"\"\"If user's input is a greeting, return a greeting response\"\"\"\n",
    "    for word in sentence.split():\n",
    "        if word.lower() in GREETING_INPUTS:\n",
    "            return random.choice(GREETING_RESPONSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d016209c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Generating response function \n",
    "def response(user_response):\n",
    "    chatbot_response=''\n",
    "    sentence_encodings=model.encode(sent_tokens, convert_to_tensor=True)# generate sentence transformer embeddings\n",
    "    sentence_encodings=sentence_encodings.cpu()\n",
    "    vals = cosine_similarity(sentence_encodings[-1].reshape(1, -1), sentence_encodings) #the chatbot conversation code \n",
    "    #in the next cell adds the question as the last sentence of the sentence tokens, before calling this response function.\n",
    "    #The code takes the last sentence (which is the question) and gets cosine similarities vs all the sentences in the corpus,\n",
    "    #including itself\n",
    "    idx=vals.argsort()[0][-2] #gets the index of the second highest similarity (the first highest would be the question itself)\n",
    "    flat = vals.flatten()#reduces dimension of cosine similarity array to be able to sort\n",
    "    flat.sort() #sort the cosine similarity values\n",
    "    second_cos_sim_val = flat[-2] #get the second highest cosine similarity value.\n",
    "    if(second_cos_sim_val==0): #check the second highest cosine similarity value. If it's zero return the no match response,\n",
    "        #else return highest cosine similarity sentence.\n",
    "        chatbot_response=chatbot_response+\"Sorry, I do not have an answer to your question in my database\"\n",
    "        return chatbot_response\n",
    "    else:\n",
    "        chatbot_response = chatbot_response+sent_tokens[idx] #use index of highest cosine similarity to get original sentence\n",
    "        return chatbot_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1846b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to the Informational Chatbot About Coral Reef Fish. To end session please type exit.\n",
      "\n",
      "\n",
      "How many species of fish live in coral reefs?\n",
      "Answer: the fish that inhabit coral reefs are numerous and diverse.\n",
      "\n",
      "\n",
      "What is the most venomous fish?\n",
      "Answer: the most venomous known fish is the reef stonefish.\n",
      "\n",
      "\n",
      "What sharks live in coral reefs?\n",
      "Answer: the whitetip reef shark almost exclusively inhabits coral reefs.\n",
      "\n",
      "\n",
      "What fish are poisonous?\n",
      "Answer: there is a distinction between poisonous fish and venomous fish.\n",
      "\n",
      "\n",
      "What fish can electrocute you?\n",
      "Answer: some unmistakable contrasting patterns are used to warn predators that the fish has venomous spines or poisonous flesh.\n",
      "\n",
      "\n",
      "What species can sting you?\n",
      "Answer: the most venomous known fish is the reef stonefish.\n",
      "\n",
      "\n",
      "What species are parasitic?\n",
      "Answer: monogenean parasites of the genus pseudorhabdosynochus (arrows) on the gill filament of a grouper.\n",
      "\n",
      "\n",
      "What species are venomous?\n",
      "Answer: few of these venoms have been studied.\n",
      "\n",
      "\n",
      "What species are known for attacking scuba divers?\n",
      "Answer: they are swift predators who patrol the reef in hunting packs.\n",
      "\n",
      "\n",
      "What are common herbivorous fish?\n",
      "Answer: herbivores feed on plants.\n",
      "\n",
      "\n",
      "Why do fish camouflage themselves?\n",
      "Answer: sometimes they camouflage the fish when the fish rests in places with the right background.\n",
      "\n",
      "\n",
      "How do fish get rid of their parasites?\n",
      "Answer: some fish specialise as cleaner fish, and establish cleaning stations where other fish can come to have their parasites nibbled away.\n",
      "\n",
      "\n",
      "What species have mutualistic relationships?\n",
      "Answer: the relationship can be mutualistic, when both species benefit from the relationship, commensalistic, when one species benefits and the other is unaffected, and parasitistic, when one species benefits, and the other is harmed.\n",
      "\n",
      "\n",
      "What species have commensalistic relationships?\n",
      "Answer: the relationship can be mutualistic, when both species benefit from the relationship, commensalistic, when one species benefits and the other is unaffected, and parasitistic, when one species benefits, and the other is harmed.\n",
      "\n",
      "\n",
      "Where in the world are coral reefs found?\n",
      "Answer: they are frequently found near the drop-offs at the outer edges of the reef, and less commonly within lagoons.\n",
      "\n",
      "\n",
      "What species engage in schooling?\n",
      "Answer: schooling fish have developed remarkable displays of precise choreography which confuse and evade predators.\n",
      "\n",
      "\n",
      "Which species are ambush predators?\n",
      "Answer: another ambush predator is the striated frogfish (right).\n",
      "\n",
      "\n",
      "What species can inflate themselves?\n",
      "Answer: they inflate their body by swallowing water, reducing potential predators to those with much bigger mouths.\n",
      "\n",
      "\n",
      "Why are some coral reef fish colorful?\n",
      "Answer: coral reef fishes exhibit a huge variety of dazzling and sometimes bizarre colours and patterns.\n",
      "\n",
      "\n",
      "What species is known to eat birds?\n",
      "Answer: they are active predators of small bony fishes, cephalopods, and crustaceans, and also feed on sea snakes and seabirds.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Chatbot interaction code\n",
    "\n",
    "flag=True\n",
    "print(\"Welcome to the Informational Chatbot About Coral Reef Fish. To end session please type exit.\")\n",
    "print(\"\\n\")\n",
    "\n",
    "while(flag==True):\n",
    "    user_response = input()\n",
    "    user_response=user_response.lower()\n",
    "    if user_response!='exit':\n",
    "        if(user_response=='thanks' or user_response=='thank you' ):\n",
    "            flag=False\n",
    "            print(\"Answer: You are welcome!\")\n",
    "        else:\n",
    "            if(greeting(user_response)!=None):\n",
    "                print(\"Answer: \"+greeting(user_response))\n",
    "            else:\n",
    "                sent_tokens.append(user_response)\n",
    "                word_tokens=word_tokens+nltk.word_tokenize(user_response)\n",
    "                final_words=list(set(word_tokens))\n",
    "                print(\"Answer: \",end=\"\")\n",
    "                print(response(user_response))\n",
    "                print(\"\\n\")\n",
    "                sent_tokens.remove(user_response)\n",
    "    else:\n",
    "        flag=False\n",
    "        print(\"Thank you for using the Informational Chatbot About Coral Reef Fish. Goodbye.\")    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4dbe7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d00b4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5700a77d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e07b84f3",
   "metadata": {},
   "source": [
    "## 2) Chatbot 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb5a5402",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac86aca8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661a2ae4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1e9bfa08",
   "metadata": {},
   "source": [
    "## 3) Chatbot 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1c01a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9801e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9b5cd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d8bb7a50",
   "metadata": {},
   "source": [
    "## 4) Chatbot 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f976acd3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa9fb3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2659f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8011713d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "30f01dcb",
   "metadata": {},
   "source": [
    "## 5) Evaluation of Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b026702",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
